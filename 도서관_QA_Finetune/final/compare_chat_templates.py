"""
ëª¨ë¸ë³„ chat_template ë¹„êµ ìŠ¤í¬ë¦½íŠ¸
ì‚¬ìš©ë²•: python compare_chat_templates.py
"""

import os
from transformers import AutoTokenizer

# ==============================
# ë¹„êµí•  ëª¨ë¸ ëª©ë¡ (ê²½ë¡œ ë˜ëŠ” HuggingFace ID)
# ==============================
MODEL_BASE_DIR = os.getenv("MODEL_BASE_DIR", "/models")

MODELS = [
    "LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct",
    "LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct",
    "LGAI-EXAONE/EXAONE-3.5-32B-Instruct",
    # ë¡œì»¬ ê²½ë¡œë„ ê°€ëŠ¥:
    # "exaone-2.4b",
    # "exaone-7.8b",
]

# í…ŒìŠ¤íŠ¸ìš© ë©”ì‹œì§€
TEST_MESSAGES = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”, ë„ì„œê´€ ìš´ì˜ ì‹œê°„ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"},
]

SEPARATOR = "=" * 80


def resolve_model_path(model_id: str) -> str:
    local_path = os.path.join(MODEL_BASE_DIR, model_id)
    if os.path.exists(local_path):
        return local_path
    return model_id


def analyze_model(model_id: str):
    path = resolve_model_path(model_id)
    print(f"\n{SEPARATOR}")
    print(f"ğŸ” ëª¨ë¸: {model_id}")
    print(f"   ê²½ë¡œ: {path}")
    print(SEPARATOR)

    try:
        tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True)
    except Exception as e:
        print(f"âŒ í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 1. íŠ¹ìˆ˜ í† í° ì •ë³´
    print("\nğŸ“Œ [íŠ¹ìˆ˜ í† í°]")
    print(f"  eos_token      : {repr(tokenizer.eos_token)} (id={tokenizer.eos_token_id})")
    print(f"  bos_token      : {repr(tokenizer.bos_token)} (id={tokenizer.bos_token_id})")
    print(f"  pad_token      : {repr(tokenizer.pad_token)} (id={tokenizer.pad_token_id})")
    print(f"  unk_token      : {repr(tokenizer.unk_token)} (id={tokenizer.unk_token_id})")

    # 2. additional_special_tokens
    print(f"\nğŸ“Œ [additional_special_tokens]")
    for tok in tokenizer.additional_special_tokens:
        tid = tokenizer.convert_tokens_to_ids(tok)
        print(f"  {repr(tok):30s} -> id={tid}")

    # 3. chat_template ì›ë¬¸
    print(f"\nğŸ“Œ [chat_template ì›ë¬¸]")
    if tokenizer.chat_template:
        # ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ
        template = tokenizer.chat_template
        if len(template) > 800:
            print(template[:800])
            print(f"  ... (ì´ {len(template)}ì, ìƒëµë¨)")
        else:
            print(template)
    else:
        print("  âš ï¸  chat_template ì—†ìŒ!")

    # 4. ì‹¤ì œ í¬ë§· ê²°ê³¼
    print(f"\nğŸ“Œ [apply_chat_template ê²°ê³¼]")
    try:
        formatted = tokenizer.apply_chat_template(
            TEST_MESSAGES,
            tokenize=False,
            add_generation_prompt=True
        )
        print(repr(formatted))
    except Exception as e:
        print(f"  âŒ í¬ë§· ì‹¤íŒ¨: {e}")
        return

    # 5. í† í°í™” ê²°ê³¼ (ì²˜ìŒ/ë í† í° ID í™•ì¸)
    print(f"\nğŸ“Œ [í† í° ID ë¶„ì„]")
    try:
        token_ids = tokenizer.apply_chat_template(
            TEST_MESSAGES,
            tokenize=True,
            add_generation_prompt=True
        )
        print(f"  ì´ í† í° ìˆ˜: {len(token_ids)}")
        print(f"  ì²˜ìŒ 10ê°œ ID: {token_ids[:10]}")
        print(f"  ë§ˆì§€ë§‰ 10ê°œ ID: {token_ids[-10:]}")

        # ë§ˆì§€ë§‰ í† í°ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ì—­ë³€í™˜
        last_tokens = tokenizer.convert_ids_to_tokens(token_ids[-10:])
        print(f"  ë§ˆì§€ë§‰ 10ê°œ í† í°: {last_tokens}")
    except Exception as e:
        print(f"  âŒ í† í°í™” ì‹¤íŒ¨: {e}")

    # 6. stop token í›„ë³´ ì •ë¦¬
    print(f"\nğŸ“Œ [ê¶Œì¥ stop_token_ids]")
    stop_ids = []
    if tokenizer.eos_token_id is not None:
        stop_ids.append((tokenizer.eos_token, tokenizer.eos_token_id))

    candidates = ["[|endofturn|]", "[|assistant|]", "[|user|]", "[|system|]",
                  "<|im_end|>", "<|endoftext|>", "<|EOT|>", "<|eot_id|>"]
    for tok in candidates:
        tid = tokenizer.convert_tokens_to_ids(tok)
        if tid != tokenizer.unk_token_id:
            stop_ids.append((tok, tid))

    for name, tid in stop_ids:
        print(f"  {repr(name):30s} -> id={tid}")

    print()


if __name__ == "__main__":
    print("ğŸš€ ëª¨ë¸ë³„ Chat Template ë¹„êµ ì‹œì‘")
    for model_id in MODELS:
        analyze_model(model_id)

    print(f"\n{SEPARATOR}")
    print("âœ… ì™„ë£Œ!")
