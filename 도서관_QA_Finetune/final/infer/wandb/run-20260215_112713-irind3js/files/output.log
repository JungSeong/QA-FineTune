[34m[1mwandb[0m: Initializing weave.
[36m[1mweave[0m: Logged in as Weights & Biases user: jungseonglian.
[36m[1mweave[0m: View Weave data at https://wandb.ai/uailab-unist_/library-qa-finetune/weave
2026-02-15 11:27:16 - INFO - [main.py:33] - Dataset({
    features: ['FAQ', 'TITLE', 'DES'],
    num_rows: 110
})
2026-02-15 11:27:16 - INFO - [model_utils.py:29] - üìÇ Î°úÏª¨ Î™®Îç∏ÏùÑ Î∞úÍ≤¨ÌñàÏäµÎãàÎã§: /home/vsc/LLM/model/Exaone-3.5-2.4B-Instruct
2026-02-15 11:27:16 - INFO - [model_utils.py:32] - üöÄ Î™®Îç∏ Î°úÎî© Ï§ë...
`torch_dtype` is deprecated! Use `dtype` instead!
/home/vsc/LLM_TUNE/QA-FineTune/ÎèÑÏÑúÍ¥Ä_QA_Finetune/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning:
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)

  queued_call()
Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 272/272 [00:00<00:00, 562.81it/s, Materializing param=transformer.wte.weight]
ExaoneForCausalLM(
  (transformer): ExaoneModel(
    (wte): Embedding(102400, 2560, padding_idx=0)
    (drop): Dropout(p=0.0, inplace=False)
    (h): ModuleList(
      (0-29): 30 x ExaoneDecoderLayer(
        (ln_1): ExaoneRMSNorm((2560,), eps=1e-05)
        (attn): ExaoneAttentionBlock(
          (attention): ExaoneAttention(
            (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)
            (k_proj): Linear4bit(in_features=2560, out_features=640, bias=False)
            (v_proj): Linear4bit(in_features=2560, out_features=640, bias=False)
            (out_proj): Linear4bit(in_features=2560, out_features=2560, bias=False)
          )
        )
        (ln_2): ExaoneRMSNorm((2560,), eps=1e-05)
        (mlp): ExaoneMLP(
          (c_fc_0): Linear4bit(in_features=2560, out_features=7168, bias=False)
          (c_fc_1): Linear4bit(in_features=2560, out_features=7168, bias=False)
          (c_proj): Linear4bit(in_features=7168, out_features=2560, bias=False)
          (act): SiLUActivation()
        )
      )
    )
    (ln_f): ExaoneRMSNorm((2560,), eps=1e-05)
    (rotary): ExaoneRotaryEmbedding()
  )
  (lm_head): Linear(in_features=2560, out_features=102400, bias=False)
)
2026-02-15 11:27:21 - INFO - [data_augmentor.py:106] - üöÄ Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ï ÏãúÏûë
Data Augmentation:   0%|                                                                                                                                                                                                                                  | 0/110 [00:00<?, ?it/s][36m[1mweave[0m: üç© https://wandb.ai/uailab-unist_/library-qa-finetune/r/call/019c5f1f-be04-71b0-8635-2734ab0dff45
ÌöåÏõêÏ¶ù ÎåÄÎ¶¨Î∞úÍ∏âÏùÄ Îßå14ÏÑ∏ ÎØ∏Îßå ÏïÑÎèô, Îßå65ÏÑ∏ Ïù¥ÏÉÅ Ïñ¥Î•¥Ïã†, Ïû•Ïï†Ïù∏, ÏûÑÏÇ∞Î∂ÄÎßå Í∞ÄÎä•ÌïòÎ©∞ ÏïÑÎûò Íµ¨ÎπÑÏÑúÎ•òÎ•º ÏßÄÏ∞∏ÌïòÏó¨ ÎåÄÎ¶¨Ïù∏Ïù¥ Î∞©Î¨∏ Ïãú ÎåÄÎ¶¨Î∞úÍ∏âÏù¥ Í∞ÄÎä•Ìï©ÎãàÎã§.

¬∑ ÎåÄÏÉÅ : Îßå14ÏÑ∏ ÎØ∏Îßå ÏïÑÎèô, Îßå65ÏÑ∏ Ïù¥ÏÉÅ Ïñ¥Î•¥Ïã†, Ïû•Ïï†Ïù∏, ÏûÑÏÇ∞Î∂Ä
¬∑ Íµ¨ÎπÑÏÑúÎ•ò
¬† - Í≥µÌÜµ : ‚ë†ÏúÑÏûÑÏûê Ïã†Î∂ÑÏ¶ù, ‚ë°ÌîºÏúÑÏûÑÏûê(ÎåÄÎ¶¨Ïù∏) Ïã†Î∂ÑÏ¶ù
¬† - Ïû•Ïï†Ïù∏ : Ïû•Ïï†Ïù∏ Î≥µÏßÄÏπ¥Îìú ÎòêÎäî Ïû•Ïï†Ïù∏ Ï¶ùÎ™ÖÏÑú
¬† - ÏûÑÏã†Î∂Ä : ÏÇ∞Î™®ÏàòÏ≤© / ÏÇ∞Î™® : Ï£ºÎØºÎì±Î°ùÎì±Î≥∏(Ï∂úÏÇ∞ ÌõÑ 12Í∞úÏõîÍπåÏßÄ)
¬∑ Î∞©Î≤ï : ÌôàÌéòÏù¥ÏßÄ ÌöåÏõêÍ∞ÄÏûÖ ÌõÑ ÏúÑ Ìï≠Î™©Ïùò Ìï¥ÎãπÌïòÎäî Íµ¨ÎπÑÏÑúÎ•òÎ•º ÏßÄÏ∞∏ÌïòÏó¨ ÌîºÏúÑÏûÑÏûê(ÎåÄÎ¶¨Ïù∏)Ïù¥ ÎèÑÏÑúÍ¥Ä Î∞©Î¨∏
Type: <class 'transformers.tokenization_utils_base.BatchEncoding'>
tensor([[  420,   453, 47982,  ...,   560,  5232,   361],
        [  420,   453, 47982,  ...,     0,     0,     0],
        [  420,   453, 47982,  ...,     0,     0,     0]], device='cuda:0')
Data Augmentation:   1%|‚ñà‚ñâ                                                                                                                                                                                                                        | 1/110 [00:24<45:06, 24.83s/it][36m[1mweave[0m: üç© https://wandb.ai/uailab-unist_/library-qa-finetune/r/call/019c5f20-1f01-74a8-bd4c-5b0a2955eb2c
Í∞ÄÏ°±ÌöåÏõêÏù¥ÎûÄ, Í≥†ÏñëÏãú ÎèÑÏÑúÍ¥Ä Ï†ïÌöåÏõêÏúºÎ°ú Í∞ÄÏûÖ ÌõÑ Í∞ÄÏ°±ÌöåÏõêÏúºÎ°ú Îì±Î°ù Ïãú Í∞ÄÏ°±Î™ÖÏùòÎ°ú ÎèÑÏÑúÎåÄÏ∂ú¬∑ÎèÑÏÑúÏòàÏïΩ¬∑ÏÉÅÌò∏ÎåÄÏ∞® ÎèôÏùºÌïòÍ≤å Ïù¥Ïö©Í∞ÄÎä•Ìïú ÏÑúÎπÑÏä§ÏûÖÎãàÎã§.
‚Äª Í∞ÄÏ°±Î™ÖÏùò Ïù¥Ïö© Ïãú ÏûêÎ£åÏã§ ÏïàÎÇ¥Îç∞Ïä§ÌÅ¨Ïóê Î∞òÎìúÏãú Î≥∏Ïù∏ ÌöåÏõêÏ¶ùÏùÑ Ï†úÏãúÌïòÏó¨Ïïº Ìï®(Í∞ÄÏ°± ÌöåÏõêÏ¶ùÏúºÎ°ú ÎåÄÏ∂ú Î∂àÍ∞Ä)
Í∞ÄÏ°±ÌöåÏõê Îì±Î°ùÎ∞©Î≤ï
Í∞ÄÏ°±Íµ¨ÏÑ±Ïõê Î™®Îëê Ï†ïÌöåÏõê Í∞ÄÏûÖ ÌõÑ Í∞ÄÏ°±ÏûÑÏùÑ Ï¶ùÎ™ÖÌï† Ïàò ÏûàÎäî ÏÑúÎ•ò(Ï£ºÎØºÎì±Î°ùÎì±Î≥∏ ÎòêÎäî Í∞ÄÏ°±Í¥ÄÍ≥ÑÏ¶ùÎ™ÖÏÑú) ÏßÄÏ∞∏ÌïòÏó¨ ÎèÑÏÑúÍ¥Ä Î∞©Î¨∏
Type: <class 'transformers.tokenization_utils_base.BatchEncoding'>
Data Augmentation:   1%|‚ñà‚ñâ                                                                                                                                                                                                                      | 1/110 [00:42<1:16:55, 42.34s/it]
Traceback (most recent call last):
  File "/home/vsc/LLM_TUNE/QA-FineTune/ÎèÑÏÑúÍ¥Ä_QA_Finetune/final/infer/main.py", line 49, in <module>
    main()
  File "/home/vsc/LLM_TUNE/QA-FineTune/ÎèÑÏÑúÍ¥Ä_QA_Finetune/final/infer/main.py", line 39, in main
    output_file = augmentor.run_augmentation(dataset)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vsc/LLM_TUNE/QA-FineTune/ÎèÑÏÑúÍ¥Ä_QA_Finetune/final/infer/data_augmentor.py", line 118, in run_augmentation
    result = self.generate_samples(idx, faq_context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vsc/LLM_TUNE/QA-FineTune/ÎèÑÏÑúÍ¥Ä_QA_Finetune/.venv/lib/python3.12/site-packages/weave/trace/op.py", line 1278, in wrapper
    res, _ = _call_sync_func(
             ^^^^^^^^^^^^^^^^
  File "/home/vsc/LLM_TUNE/QA-FineTune/ÎèÑÏÑúÍ¥Ä_QA_Finetune/.venv/lib/python3.12/site-packages/weave/trace/op.py", line 543, in _call_sync_func
    res = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vsc/LLM_TUNE/QA-FineTune/ÎèÑÏÑúÍ¥Ä_QA_Finetune/final/infer/data_augmentor.py", line 75, in generate_samples
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/vsc/LLM_TUNE/QA-FineTune/ÎèÑÏÑúÍ¥Ä_QA_Finetune/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 124, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vsc/LLM_TUNE/QA-FineTune/ÎèÑÏÑúÍ¥Ä_QA_Finetune/.venv/lib/python3.12/site-packages/transformers/generation/utils.py", line 2638, in generate
    result = decoding_method(
             ^^^^^^^^^^^^^^^^
  File "/home/vsc/LLM_TUNE/QA-FineTune/ÎèÑÏÑúÍ¥Ä_QA_Finetune/.venv/lib/python3.12/site-packages/transformers/generation/utils.py", line 2839, in _sample
    while self._has_unfinished_sequences(this_peer_finished, synced_gpus, device=input_ids.device):
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Exception ignored in atexit callback: <bound method AsyncBatchProcessor.stop_accepting_new_work_and_flush_queue of <weave.trace_server_bindings.async_batch_processor.AsyncBatchProcessor object at 0xff658c4ef830>>
Traceback (most recent call last):
  File "/home/vsc/LLM_TUNE/QA-FineTune/ÎèÑÏÑúÍ¥Ä_QA_Finetune/.venv/lib/python3.12/site-packages/weave/trace_server_bindings/async_batch_processor.py", line 146, in stop_accepting_new_work_and_flush_queue
    self.processing_thread.join()
  File "/usr/lib/python3.12/threading.py", line 1147, in join
    self._wait_for_tstate_lock()
  File "/usr/lib/python3.12/threading.py", line 1167, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt:
