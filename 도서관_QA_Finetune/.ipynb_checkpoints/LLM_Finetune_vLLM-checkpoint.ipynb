{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63df3b4",
   "metadata": {},
   "source": [
    "ì°¸ê³  : https://zero-ai.tistory.com/62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc8bdf6-460a-4caa-8038-0056231c83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€: True\n",
      "GPU ì´ë¦„: NVIDIA GB10\n",
      "CUDA ë²„ì „: 13.0\n",
      "PyTorch ë²„ì „: <module 'torch.version' from '/home/vsc/LLM_TUNE/.venv_vLLM/lib/python3.12/site-packages/torch/version.py'>\n",
      "bf16 ì§€ì› ì—¬ë¶€: True\n",
      "í˜„ì¬ GPU : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsc/LLM_TUNE/.venv_vLLM/lib/python3.12/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU ì´ë¦„: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"CUDA ë²„ì „: {torch.version.cuda}\")\n",
    "print(f\"PyTorch ë²„ì „: {torch.version}\")\n",
    "print(f\"bf16 ì§€ì› ì—¬ë¶€: {torch.cuda.is_bf16_supported()}\")\n",
    "print(f\"í˜„ì¬ GPU : {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b03ed4-45a4-4772-850c-ea53128ebdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GPU Memory Status ---\n",
      "Allocated: 0.00 GB\n",
      "Reserved:  0.00 GB\n",
      "Total:     119.70 GB\n",
      "Free (in Reserved): 0.00 GB\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_vram_torch():\n",
    "    # 1. í˜„ì¬ í…ì„œë“¤ì´ ì‹¤ì œë¡œ ì ìœ í•˜ê³  ìˆëŠ” ë©”ëª¨ë¦¬\n",
    "    allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "    # 2. PyTorchê°€ OSë¡œë¶€í„° í• ë‹¹ë°›ì•„ ìºì‹±í•˜ê³  ìˆëŠ” ì „ì²´ ë©”ëª¨ë¦¬\n",
    "    reserved = torch.cuda.memory_reserved() / (1024**3)\n",
    "    # 3. í•´ë‹¹ GPUì˜ ì „ì²´ ìš©ëŸ‰\n",
    "    total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "\n",
    "    print(f\"--- GPU Memory Status ---\")\n",
    "    print(f\"Allocated: {allocated:.2f} GB\")\n",
    "    print(f\"Reserved:  {reserved:.2f} GB\")\n",
    "    print(f\"Total:     {total:.2f} GB\")\n",
    "    print(f\"Free (in Reserved): {reserved - allocated:.2f} GB\")\n",
    "    print(f\"--------------------------\")\n",
    "\n",
    "check_vram_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a7e77c-c1d1-4035-9c18-bb4e8226a148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['FAQ', 'TITLE', 'DES'],\n",
      "    num_rows: 110\n",
      "})\n",
      "{'FAQ': 1, 'TITLE': 'íšŒì›ì¦ì„ ëŒ€ë¦¬ë°œê¸‰ í•  ìˆ˜ ìˆë‚˜ìš”?', 'DES': 'íšŒì›ì¦ ëŒ€ë¦¬ë°œê¸‰ì€ ë§Œ14ì„¸ ë¯¸ë§Œ ì•„ë™, ë§Œ65ì„¸ ì´ìƒ ì–´ë¥´ì‹ , ì¥ì• ì¸, ì„ì‚°ë¶€ë§Œ ê°€ëŠ¥í•˜ë©° ì•„ë˜ êµ¬ë¹„ì„œë¥˜ë¥¼ ì§€ì°¸í•˜ì—¬ ëŒ€ë¦¬ì¸ì´ ë°©ë¬¸ ì‹œ ëŒ€ë¦¬ë°œê¸‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\\n\\nÂ· ëŒ€ìƒ : ë§Œ14ì„¸ ë¯¸ë§Œ ì•„ë™, ë§Œ65ì„¸ ì´ìƒ ì–´ë¥´ì‹ , ì¥ì• ì¸, ì„ì‚°ë¶€\\nÂ· êµ¬ë¹„ì„œë¥˜\\n\\xa0 - ê³µí†µ : â‘ ìœ„ì„ì ì‹ ë¶„ì¦, â‘¡í”¼ìœ„ì„ì(ëŒ€ë¦¬ì¸) ì‹ ë¶„ì¦\\n\\xa0 - ì¥ì• ì¸ : ì¥ì• ì¸ ë³µì§€ì¹´ë“œ ë˜ëŠ” ì¥ì• ì¸ ì¦ëª…ì„œ\\n\\xa0 - ì„ì‹ ë¶€ : ì‚°ëª¨ìˆ˜ì²© / ì‚°ëª¨ : ì£¼ë¯¼ë“±ë¡ë“±ë³¸(ì¶œì‚° í›„ 12ê°œì›”ê¹Œì§€)\\nÂ· ë°©ë²• : í™ˆí˜ì´ì§€ íšŒì›ê°€ì… í›„ ìœ„ í•­ëª©ì˜ í•´ë‹¹í•˜ëŠ” êµ¬ë¹„ì„œë¥˜ë¥¼ ì§€ì°¸í•˜ì—¬ í”¼ìœ„ì„ì(ëŒ€ë¦¬ì¸)ì´ ë„ì„œê´€ ë°©ë¬¸'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "file_path = glob.glob(\"./data/*.xlsx\")\n",
    "df = pd.read_excel(file_path[0])\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0c5ff4-5b60-4a2e-9606-15e6b139993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì¦ê°•ì„ ìœ„í•´ ë¡œì»¬ EXAONE-3.5-7.8B-Instruct ëª¨ë¸ ì‚¬ìš©\n",
    "# Instruct ëª¨ë¸ : ëª…ë ¹ / ì§€ì‹œë¥¼ ë‚´ë¦¬ëŠ” ëª¨ë¸\n",
    "# ì¼ë°˜ LLM ëª¨ë¸ : í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ëŠ” ë° ì´ˆì ì„ ë‘” ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e4ba03d-f6f1-40f9-8c57-35f262834778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import os, torch, json, wandb, subprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5279e11-19b4-4210-8453-5baa012d5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"EMPTY\"\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"/home/vsc/LLM/model/Exaone-3.5-32B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f4fb5c-8564-45c3-b86a-ea513a0c31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vLLMì˜ ê²½ìš° pipeline ë°©ì‹ì— ë¹„í•´ ì¶”ë¡  ì†ë„ê°€ ë¹ ë¥´ë©°, ë©”ëª¨ë¦¬ ì•ˆì •ì„±ì´ ë” ë†’ìŒ + continuous batchingìœ¼ë¡œ í•œ ë²ˆì— ì—¬ëŸ¬ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ìˆ ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f301929-fd87-4cee-a008-f5e6b6f9ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmented_data(faq_content):\n",
    "    system_message = (\n",
    "        \"ë‹¹ì‹ ì€ ë„ì„œê´€ FAQ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n\"\n",
    "        \"ì œê³µëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ 4ê°€ì§€ ìœ í˜•ì˜ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”. ê° ìœ í˜•ë³„ë¡œ ìµœì†Œ 3ê°œì”©, ì´ 12ê°œì˜ ì˜ˆì‹œë¥¼ ë§Œë“œì„¸ìš”.\\n\\n\"\n",
    "        \"ì´ë•Œ íŒë‹¨ì´ ì‰¬ìš´ ì˜ˆì‹œì™€ ë³´í†µ, ì–´ë ¤ìš´ ì˜ˆì‹œ ì´ 3ê°€ì§€ ìƒí™©ì„ ê°€ì •í•˜ì„¸ìš”.\"\n",
    "        \n",
    "        \"### [ë‹µë³€ ê°€ì´ë“œë¼ì¸]\\n\"\n",
    "        \"1. **label: 'yes' (ê¸ì • í™•ì¸)**\\n\"\n",
    "        \"   - ì§ˆë¬¸ì´ '~í•  ìˆ˜ ìˆë‚˜ìš”?', '~ì¸ê°€ìš”?'ì²˜ëŸ¼ 'ê°€ë¶€'ë¥¼ ë¬¼ì„ ë•Œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\\n\"\n",
    "        \"   - ë¬¸êµ¬: 'ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤! ë„ì„œê´€ ê·œì •ì— ë”°ë¥´ë©´...'\\n\"\n",
    "        \"   - í™œìš©: ì§ˆë¬¸ì˜ ì¡°ê±´ì´ FAQì™€ ì¼ì¹˜í•  ë•Œ ì‚¬ìš©.\\n\"\n",
    "        \"2. **label: 'no' (ë¶€ì •/ì œí•œ)**\\n\"\n",
    "        \"   - ì§ˆë¬¸ì´ '~í•  ìˆ˜ ìˆë‚˜ìš”?', '~ì¸ê°€ìš”?'ì²˜ëŸ¼ 'ê°€ë¶€'ë¥¼ ë¬¼ì„ ë•Œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\\n\"\n",
    "        \"   - ë¬¸êµ¬: 'ì£„ì†¡í•˜ì§€ë§Œ ì–´ë µìŠµë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ”...'\\n\"\n",
    "        \"   - í™œìš©: ì§ˆë¬¸ì˜ ì¡°ê±´ì´ FAQ ê·œì •ì— ì–´ê¸‹ë‚  ë•Œ ì‚¬ìš©. 'ì‚¬ì‹¤ê³¼ ë‹¤ë¥´ë‹¤'ëŠ” í‘œí˜„ ëŒ€ì‹  'ê·œì •ìƒ ì–´ë µë‹¤'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\\n\"\n",
    "        \"3. **label: 'info' (ë‹¨ìˆœ ì •ë³´ ì œê³µ)**\\n\"\n",
    "        \"   - ì§ˆë¬¸ì´ '~ì€ ë¬´ì—‡ì¸ê°€ìš”?', '~ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?', '~ì€ ì–¸ì œì¸ê°€ìš”?'ì²˜ëŸ¼ ì ˆì°¨/ì‹œê°„/ë°©ë²•ì„ ë¬¼ì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.\\n\"\n",
    "        \"   - ë¬¸êµ¬: 'ë¬¸ì˜í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ê´€ë ¨ ì„œë¥˜ëŠ”...'\\n\"\n",
    "        \"   - í™œìš©: ë„¤/ì•„ë‹ˆì˜¤ íŒë‹¨ì´ ì•„ë‹Œ ì •ë³´ ì§ˆë¬¸ì— ì‚¬ìš©.\\n\"\n",
    "        \"4. **label: 'false' (íŒë‹¨ ë¶ˆê°€)**\\n\"\n",
    "        \"   - ë¬¸êµ¬: 'ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” í•´ë‹¹ ë‚´ìš©ì„ í™•ì¸í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.'\\n\"\n",
    "        \"   - í™œìš©: FAQì— ì—†ëŠ” ë‚´ìš©ì´ê±°ë‚˜ ì§ˆë¬¸ì´ ëª¨í˜¸í•  ë•Œ ì‚¬ìš©.\\n\\n\"\n",
    "        \n",
    "        \"ëª¨ë“  ë‹µë³€ì€ ì‹¤ì œ ë„ì„œê´€ ì‚¬ì„œê°€ ë°©ë¬¸ê°ì—ê²Œ ì„¤ëª…í•˜ë“¯ ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\"\n",
    "        \"íŒë‹¨ ë¶ˆê°€ì˜ ê²½ìš° ë¬¸êµ¬ ì™¸ì— ë‹¤ë¥¸ ë¬¸ì¥ì€ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.\"\n",
    "        \"JSON ë‹µë³€ ì™¸ì— ë‹¤ë¥¸ ë¬¸ì¥ì€ ì¼ì²´ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.\"\n",
    "    )\n",
    "\n",
    "    # ì‚¬ìš©ìê°€ ì •ì˜í•œ user_content\n",
    "    user_content = f\"\"\"\n",
    "    [ë„ì„œê´€ FAQ ì •ë³´]\n",
    "    {faq_content}\n",
    "    \n",
    "    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ë…¼ë¦¬ì ìœ¼ë¡œ ì™„ë²½í•˜ê²Œ ì´ì–´ì§€ëŠ” JSON ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "    \n",
    "    [ì¶œë ¥ ì˜ˆì‹œ]:\n",
    "    [\n",
    "      {{\"question\": \"ì„ì‚°ë¶€ì¸ë° ë‚¨í¸ì´ ëŒ€ì‹  ë°œê¸‰ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\", \"answer\": \"ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤! ë„ì„œê´€ ê·œì •ì— ë”°ë¥´ë©´ ì„ì‚°ë¶€ì˜ ê²½ìš° ëŒ€ë¦¬ ë°œê¸‰ ëŒ€ìƒì— í¬í•¨ë©ë‹ˆë‹¤.\", \"label\": \"yes\"}},\n",
    "      {{\"question\": \"ì„±ì¸ ì§ì¥ì¸ì¸ë° ì¹œêµ¬ê°€ ëŒ€ì‹  ê°€ë„ ë˜ë‚˜ìš”?\", \"answer\": \"ì£„ì†¡í•˜ì§€ë§Œ, í•´ë‹¹ ì¡°ê±´ìœ¼ë¡œëŠ” ëŒ€ë¦¬ ë°œê¸‰ì´ ì–´ë µìŠµë‹ˆë‹¤. ëŒ€ë¦¬ ë°œê¸‰ì€ ì•„ë™, ì–´ë¥´ì‹ , ì¥ì• ì¸, ì„ì‚°ë¶€ë¡œ ëŒ€ìƒì´ ì œí•œë˜ì–´ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\", \"label\": \"no\"}},\n",
    "      {{\"question\": \"ì¥ì• ì¸ ëŒ€ë¦¬ ë°œê¸‰ ì‹œ ì–´ë–¤ ì„œë¥˜ê°€ í•„ìš”í•œê°€ìš”?\", \"answer\": \"ë¬¸ì˜í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì¥ì• ì¸ ë³µì§€ì¹´ë“œ ë˜ëŠ” ì¥ì• ì¸ ì¦ëª…ì„œë¥¼ ì§€ì°¸í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\", \"label\": \"info\"}},\n",
    "      {{\"question\": \"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” í•´ë‹¹ ë‚´ìš©ì„ í™•ì¸í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.\", \"label\": \"false\"}}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "        ],\n",
    "        temperature=0.7,   # ì°½ì˜ì„± ì¡°ì ˆ (0.0 ~ 2.0)\n",
    "        max_tokens=2048,   # ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜\n",
    "        top_p=0.9,         # ë‹µë³€ì˜ ë‹¤ì–‘ì„± ì¡°ì ˆ\n",
    "    )\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33de8dde-cbf3-4dbd-989c-650c254d993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_generated_json(response_text):\n",
    "    try:\n",
    "        # 1. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° (```json ... ``` ì‚¬ì´ì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ)\n",
    "        json_pattern = re.compile(r\"```json\\s*(.*?)\\s*```\", re.DOTALL)\n",
    "        match = json_pattern.search(response_text)\n",
    "        \n",
    "        if match:\n",
    "            json_str = match.group(1)\n",
    "        else:\n",
    "            json_str = response_text.strip()\n",
    "            \n",
    "        # 2. JSON ë¬¸ìì—´ì„ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        data_list = json.loads(json_str)\n",
    "        return data_list\n",
    "    except Exception as e:\n",
    "        print(f\"íŒŒì‹± ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73de580c-58c9-4ee4-b1e7-ee6920124a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data Augmentation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [02:15<00:00, 67.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì´ 110ê°œì˜ í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "output_file = \"augmented_library_faq_quant_EXAONE_32B_vLLM.jsonl\"\n",
    "\n",
    "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "    for i, row in enumerate(tqdm(dataset.select(range(108, len(dataset))), desc=\"Data Augmentation\")):\n",
    "        # 1. ëª¨ë¸ë¡œë¶€í„° í…ìŠ¤íŠ¸ ìƒì„±\n",
    "        raw_output = generate_augmented_data(row[\"DES\"])\n",
    "        \n",
    "        # 2. íŒŒì‹±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        parsed_list = parse_generated_json(raw_output)\n",
    "        \n",
    "        for item in parsed_list:\n",
    "            item['faq'] = row['FAQ'] \n",
    "            item['title'] = row['TITLE'] \n",
    "            item['DES'] = row['DES']\n",
    "            \n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "            \n",
    "print(f\"âœ… ì´ {len(df)}ê°œì˜ í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c3d6571-cf27-4977-ae65-4dbfcb38fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wanDB & weave + W&B artifact ì…‹ì—…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9daf6da-37d0-4dc6-a205-90b11759457e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'aiofiles'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01maiofiles\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwandb\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01masyncio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'aiofiles'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import asyncio, aiofiles\n",
    "import wandb\n",
    "from tqdm.asyncio import tqdm\n",
    "from openai import AsyncOpenAI\n",
    "import weave\n",
    "\n",
    "PROJECT_NAME=\"library-faq-augmentation\"\n",
    "\n",
    "config = {\n",
    "    \"model\": \"Exaone-3.5-32B-Instruct\",\n",
    "    \"quantization\": \"bitsandbytes\",\n",
    "    \"engine\": \"vLLM-v1\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_model_len\": 16384,\n",
    "}\n",
    "\n",
    "wandb.init(project=PROJECT_NAME, name=\"EXAONE-32B-vLLM-Run\")\n",
    "weave.init(PROJECT_NAME)\n",
    "sample_table = wandb.Table(columns=[\"FAQ_ID\", \"Question\", \"Answer\", \"Context\"])\n",
    "client = AsyncOpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"EMPTY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a4d2b1-51d7-4f5e-9328-97d080fabc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async ì…‹ì—…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "473a75b7-5601-42e3-8d9e-8ec4fe9d544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "async def generate_augmented_data_async(faq_content, row_id) :\n",
    "    system_message = (\n",
    "    \"ë‹¹ì‹ ì€ ë„ì„œê´€ FAQ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n\"\n",
    "    \"ì œê³µëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ 4ê°€ì§€ ìœ í˜•ì˜ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”. ê° ìœ í˜•ë³„ë¡œ ìµœì†Œ 3ê°œì”©, ì´ 12ê°œì˜ ì˜ˆì‹œë¥¼ ë§Œë“œì„¸ìš”.\\n\\n\"\n",
    "    \"ì´ë•Œ íŒë‹¨ì´ ì‰¬ìš´ ì˜ˆì‹œì™€ ë³´í†µ, ì–´ë ¤ìš´ ì˜ˆì‹œ ì´ 3ê°€ì§€ ìƒí™©ì„ ê°€ì •í•˜ì„¸ìš”.\"\n",
    "    \n",
    "    \"### [ë‹µë³€ ê°€ì´ë“œë¼ì¸]\\n\"\n",
    "    \"1. **label: 'yes' (ê¸ì • í™•ì¸)**\\n\"\n",
    "    \"   - ì§ˆë¬¸ì´ '~í•  ìˆ˜ ìˆë‚˜ìš”?', '~ì¸ê°€ìš”?'ì²˜ëŸ¼ 'ê°€ë¶€'ë¥¼ ë¬¼ì„ ë•Œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\\n\"\n",
    "    \"   - ë¬¸êµ¬: 'ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤! ë„ì„œê´€ ê·œì •ì— ë”°ë¥´ë©´...'\\n\"\n",
    "    \"   - í™œìš©: ì§ˆë¬¸ì˜ ì¡°ê±´ì´ FAQì™€ ì¼ì¹˜í•  ë•Œ ì‚¬ìš©.\\n\"\n",
    "    \"2. **label: 'no' (ë¶€ì •/ì œí•œ)**\\n\"\n",
    "    \"   - ì§ˆë¬¸ì´ '~í•  ìˆ˜ ìˆë‚˜ìš”?', '~ì¸ê°€ìš”?'ì²˜ëŸ¼ 'ê°€ë¶€'ë¥¼ ë¬¼ì„ ë•Œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\\n\"\n",
    "    \"   - ë¬¸êµ¬: 'ì£„ì†¡í•˜ì§€ë§Œ ì–´ë µìŠµë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ”...'\\n\"\n",
    "    \"   - í™œìš©: ì§ˆë¬¸ì˜ ì¡°ê±´ì´ FAQ ê·œì •ì— ì–´ê¸‹ë‚  ë•Œ ì‚¬ìš©. 'ì‚¬ì‹¤ê³¼ ë‹¤ë¥´ë‹¤'ëŠ” í‘œí˜„ ëŒ€ì‹  'ê·œì •ìƒ ì–´ë µë‹¤'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\\n\"\n",
    "    \"3. **label: 'info' (ë‹¨ìˆœ ì •ë³´ ì œê³µ)**\\n\"\n",
    "    \"   - ì§ˆë¬¸ì´ '~ì€ ë¬´ì—‡ì¸ê°€ìš”?', '~ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?', '~ì€ ì–¸ì œì¸ê°€ìš”?'ì²˜ëŸ¼ ì ˆì°¨/ì‹œê°„/ë°©ë²•ì„ ë¬¼ì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.\\n\"\n",
    "    \"   - ë¬¸êµ¬: 'ë¬¸ì˜í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ê´€ë ¨ ì„œë¥˜ëŠ”...'\\n\"\n",
    "    \"   - í™œìš©: ë„¤/ì•„ë‹ˆì˜¤ íŒë‹¨ì´ ì•„ë‹Œ ì •ë³´ ì§ˆë¬¸ì— ì‚¬ìš©.\\n\"\n",
    "    \"4. **label: 'false' (íŒë‹¨ ë¶ˆê°€)**\\n\"\n",
    "    \"   - ë¬¸êµ¬: 'ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” í•´ë‹¹ ë‚´ìš©ì„ í™•ì¸í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.'\\n\"\n",
    "    \"   - í™œìš©: FAQì— ì—†ëŠ” ë‚´ìš©ì´ê±°ë‚˜ ì§ˆë¬¸ì´ ëª¨í˜¸í•  ë•Œ ì‚¬ìš©.\\n\\n\"\n",
    "    \n",
    "    \"ëª¨ë“  ë‹µë³€ì€ ì‹¤ì œ ë„ì„œê´€ ì‚¬ì„œê°€ ë°©ë¬¸ê°ì—ê²Œ ì„¤ëª…í•˜ë“¯ ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\"\n",
    "    \"íŒë‹¨ ë¶ˆê°€ì˜ ê²½ìš° ë¬¸êµ¬ ì™¸ì— ë‹¤ë¥¸ ë¬¸ì¥ì€ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.\"\n",
    "    \"JSON ë‹µë³€ ì™¸ì— ë‹¤ë¥¸ ë¬¸ì¥ì€ ì¼ì²´ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.\"\n",
    "    )\n",
    "\n",
    "    # ì‚¬ìš©ìê°€ ì •ì˜í•œ user_content\n",
    "    user_content = f\"\"\"\n",
    "        [ë„ì„œê´€ FAQ ì •ë³´]\n",
    "        {faq_content}\n",
    "        \n",
    "        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ë…¼ë¦¬ì ìœ¼ë¡œ ì™„ë²½í•˜ê²Œ ì´ì–´ì§€ëŠ” JSON ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "        \n",
    "        [ì¶œë ¥ ì˜ˆì‹œ]:\n",
    "        [\n",
    "          {{\"question\": \"ì„ì‚°ë¶€ì¸ë° ë‚¨í¸ì´ ëŒ€ì‹  ë°œê¸‰ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\", \"answer\": \"ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤! ë„ì„œê´€ ê·œì •ì— ë”°ë¥´ë©´ ì„ì‚°ë¶€ì˜ ê²½ìš° ëŒ€ë¦¬ ë°œê¸‰ ëŒ€ìƒì— í¬í•¨ë©ë‹ˆë‹¤.\", \"label\": \"yes\"}},\n",
    "          {{\"question\": \"ì„±ì¸ ì§ì¥ì¸ì¸ë° ì¹œêµ¬ê°€ ëŒ€ì‹  ê°€ë„ ë˜ë‚˜ìš”?\", \"answer\": \"ì£„ì†¡í•˜ì§€ë§Œ, í•´ë‹¹ ì¡°ê±´ìœ¼ë¡œëŠ” ëŒ€ë¦¬ ë°œê¸‰ì´ ì–´ë µìŠµë‹ˆë‹¤. ëŒ€ë¦¬ ë°œê¸‰ì€ ì•„ë™, ì–´ë¥´ì‹ , ì¥ì• ì¸, ì„ì‚°ë¶€ë¡œ ëŒ€ìƒì´ ì œí•œë˜ì–´ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\", \"label\": \"no\"}},\n",
    "          {{\"question\": \"ì¥ì• ì¸ ëŒ€ë¦¬ ë°œê¸‰ ì‹œ ì–´ë–¤ ì„œë¥˜ê°€ í•„ìš”í•œê°€ìš”?\", \"answer\": \"ë¬¸ì˜í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì¥ì• ì¸ ë³µì§€ì¹´ë“œ ë˜ëŠ” ì¥ì• ì¸ ì¦ëª…ì„œë¥¼ ì§€ì°¸í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\", \"label\": \"info\"}},\n",
    "          {{\"question\": \"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” í•´ë‹¹ ë‚´ìš©ì„ í™•ì¸í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.\", \"label\": \"false\"}}\n",
    "        ]\n",
    "    \"\"\"\n",
    "    \n",
    "    try :\n",
    "        chat_completion = await client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_content},\n",
    "            ],\n",
    "            temperature=0.7,   # ì°½ì˜ì„± ì¡°ì ˆ (0.0 ~ 2.0)\n",
    "            max_tokens=2048,   # ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜\n",
    "            top_p=0.9,         # ë‹µë³€ì˜ ë‹¤ì–‘ì„± ì¡°ì ˆ\n",
    "        )\n",
    "\n",
    "        raw_output = chat_completion.choices[0].message.content\n",
    "\n",
    "        if \"```json\" in raw_output:\n",
    "            raw_output = raw_output.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "        parsed_list = json.loads(raw_output)\n",
    "\n",
    "        if row_id < 5:\n",
    "            for item in parsed_list[:2]:\n",
    "                sample_table.add_data(row_id, item.get(\"question\"), item.get(\"answer\"), item.get(\"label\"))\n",
    "        \n",
    "        return parsed_list\n",
    "\n",
    "    except Exception as e :\n",
    "        print(f\"Error at {row_id} : {e}\")\n",
    "        return []\n",
    "    \n",
    "async def process_dataset(dataset) :\n",
    "    output_file = \"async_library_faq_quant_EXAONE_32B_vLLM_async.jsonl\"\n",
    "    async with aiofiles.open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        semaphore = asyncio.Semaphore(2)\n",
    "\n",
    "        async def semaphore_task(row, idx) :\n",
    "            async with semaphore :\n",
    "                results = await generate_augmented_data_async(row[\"DES\"], idx)\n",
    "                for item in results:\n",
    "                    item.update({'faq': row['FAQ'], 'title': row['TITLE'], 'DES': row['DES']})\n",
    "                    f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "                return len(results)\n",
    "\n",
    "        tasks = [semaphore_task(row, i) for i, row in enumerate(dataset)]\n",
    "\n",
    "        total_created = 0\n",
    "        for f_task in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"ë°ì´í„°ì…‹ ìƒì„±\"):\n",
    "            total_created += await f_task\n",
    "\n",
    "    wandb.log({\"augmented_samples\": sample_table})\n",
    "    wandb.finish()\n",
    "    print(f\"âœ… ìƒì„± ì™„ë£Œ! ì´ {total_created}ê°œì˜ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09f8c4-bd7a-4e77-9221-b945b2c4d7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ì…‹ ìƒì„±:   0%|                                                                                          | 0/110 [00:00<?, ?it/s]\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/uailab-unist_/library-faq-augmentation/r/call/019c3c72-931b-7aed-b763-e5bee187269c\n",
      "[2026-02-08 17:51:07] INFO weave_client.py:168: ğŸ© https://wandb.ai/uailab-unist_/library-faq-augmentation/r/call/019c3c72-931b-7aed-b763-e5bee187269c\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ğŸ© https://wandb.ai/uailab-unist_/library-faq-augmentation/r/call/019c3c72-9315-7f36-ba9f-93b61fc7cd96\n",
      "[2026-02-08 17:51:07] INFO weave_client.py:168: ğŸ© https://wandb.ai/uailab-unist_/library-faq-augmentation/r/call/019c3c72-9315-7f36-ba9f-93b61fc7cd96\n"
     ]
    }
   ],
   "source": [
    "await process_dataset(dataset)\n",
    "artifact = wandb.Artifact('augmented_dataset', type='dataset')\n",
    "artifact.add_file(\"augmented_library_faq_vLLM.jsonl\")\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5093550b-b22f-46fa-ac29-290b417922ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "\n",
    "data = []\n",
    "with open(\"augmented_library_faq.jsonl\", \"r\", encoding=\"utf-8\") as f :\n",
    "    for line in f :\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6ebcae-b100-4cbf-be03-31d84ea7d43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "info     593\n",
      "yes      533\n",
      "false    435\n",
      "no       388\n",
      "Name: count, dtype: int64\n",
      "-----\n",
      "question        2\n",
      "answer         16\n",
      "label           1\n",
      "faq             0\n",
      "title         678\n",
      "ë‹µë³€           1943\n",
      "augmented    1272\n",
      "dtype: int64\n",
      "-----\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1950 entries, 0 to 1949\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   question   1948 non-null   str   \n",
      " 1   answer     1934 non-null   str   \n",
      " 2   label      1949 non-null   str   \n",
      " 3   faq        1950 non-null   object\n",
      " 4   title      1272 non-null   str   \n",
      " 5   ë‹µë³€         7 non-null      str   \n",
      " 6   augmented  678 non-null    object\n",
      "dtypes: object(2), str(5)\n",
      "memory usage: 701.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ìƒì„±ëœ ë°ì´í„° í™•ì¸ (ê²°ì¸¡ì¹˜ í™•ì¸ ë° ë°ì´í„° ë³´ê°•ì„ ìœ„í•¨)\n",
    "\n",
    "print(df[\"label\"].value_counts())\n",
    "print(\"-----\")\n",
    "print(df.isnull().sum())\n",
    "print(\"-----\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680d627a-6814-4fca-9188-52678aa673df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1950 entries, 0 to 1949\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   question   1948 non-null   str   \n",
      " 1   answer     1941 non-null   str   \n",
      " 2   label      1949 non-null   str   \n",
      " 3   faq        1950 non-null   object\n",
      " 4   title      1272 non-null   str   \n",
      " 5   augmented  678 non-null    object\n",
      "dtypes: object(2), str(4)\n",
      "memory usage: 686.1+ KB\n",
      "None\n",
      "question        2\n",
      "answer          9\n",
      "label           1\n",
      "faq             0\n",
      "title         678\n",
      "augmented    1272\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if \"ë‹µë³€\" in df.columns :\n",
    "    df[\"answer\"] = df[\"answer\"].fillna(df[\"ë‹µë³€\"])\n",
    "    df = df.drop(columns=[\"ë‹µë³€\"])\n",
    "\n",
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7225930c-9c3c-47ef-b7a0-2aca30774724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1939 entries, 0 to 1938\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   question   1939 non-null   str   \n",
      " 1   answer     1939 non-null   str   \n",
      " 2   label      1939 non-null   str   \n",
      " 3   faq        1939 non-null   object\n",
      " 4   title      1262 non-null   str   \n",
      " 5   augmented  677 non-null    object\n",
      "dtypes: object(2), str(4)\n",
      "memory usage: 683.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"question\", \"answer\", \"label\"])\n",
    "df = df.reset_index(drop=True) # dropëœ í–‰ì˜ ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ë§¤ê¸°ê¸°\n",
    "\n",
    "print(df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b6dfec-9a4a-45b6-878a-cad0b4418854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1. Label Distribution] ---\n",
      "label\n",
      "info     586\n",
      "yes      533\n",
      "false    433\n",
      "no       387\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "\n",
    "# 2. ë¼ë²¨ ë¶„í¬ í™•ì¸ (ê· í˜•ì„±)\n",
    "print(\"--- [1. Label Distribution] ---\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='label', order=['yes', 'no', 'info', 'false'])\n",
    "plt.title(\"Label Distribution\")\n",
    "plt.savefig(\"label_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d68c7ba-f8df-4143-9ec5-8098d8a5eaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label                                               false  info  no  yes\n",
      "title                                                                   \n",
      "E-BOOK ë¦¬ë”ê¸°(í¬ë ˆë§ˆ)ì—ì„œ YES24 ì„œë¹„ìŠ¤ê°€ ì•ˆë˜ëŠ” ê²½ìš°                     1     7   4    0\n",
      "ê°€ì¡±íšŒì›ì´ ë¬´ì—‡ì¸ê°€ìš”?                                            2     3   3    4\n",
      "ê°€ì¢Œë„ì„œê´€ ìœ„ì¹˜ ë° ì „í™”ë²ˆí˜¸ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?                               2     5   0    5\n",
      "ê°€ì¢Œë„ì„œê´€ ì´ìš©ì‹œê°„ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?                                    1     3   3    3\n",
      "ê°€ì¢Œë„ì„œê´€ íœ´ê´€ì¼ì€ ì–¸ì œì¸ê°€ìš”?                                       2     7   2    1\n",
      "...                                                   ...   ...  ..  ...\n",
      "í™”ì •ì–´ë¦°ì´ë„ì„œê´€ ì´ìš©ì‹œê°„ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?                                 1     3   3    5\n",
      "í™”ì •ì–´ë¦°ì´ë„ì„œê´€ íœ´ê´€ì¼ì€ ì–¸ì œì¸ê°€ìš”?                                    1     6   2    3\n",
      "íšŒì›ì¦ì€ ë„ì„œê´€ë§ˆë‹¤ ê°ê° ë§Œë“¤ì–´ì•¼ í•˜ë‚˜ìš”? ë˜, íšŒì›ì¦ì„ ë¶„ì‹¤í•œ ê²½ìš°ì—ëŠ” ì–´ë–»ê²Œ í•´ì•¼...      3     4   1    4\n",
      "íšŒì›ì¦ì„ ëŒ€ë¦¬ë°œê¸‰ í•  ìˆ˜ ìˆë‚˜ìš”?                                      1     5   4    3\n",
      "í¬ë§ë„ì„œ ì‹ ì²­ì€ ì–´ë–»ê²Œ í•˜ë©°, ë„ì„œêµ¬ì…ì€ ì–¼ë§ˆë‚˜ ìì£¼í•˜ë‚˜ìš”?                       1     3   4    4\n",
      "\n",
      "[106 rows x 4 columns]\n",
      "106\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "pivot = df.groupby([\"title\", \"label\"]).size().unstack(fill_value=0)\n",
    "print(pivot)\n",
    "need_aug_idx = pivot[(pivot[\"yes\"]<=1) | (pivot[\"no\"]<=1) | (pivot[\"false\"] <=1)]\n",
    "\n",
    "print(len(pivot))\n",
    "print(len(need_aug_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf9ede0-43d8-48ac-9293-de241dd9db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_targeted_data(faq_content, target_labels):\n",
    "    # í•„ìš”í•œ ë¼ë²¨ì— ëŒ€í•œ ê°€ì´ë“œë¼ì¸ / ì˜ˆì‹œë§Œ í”„ë¡¬í”„íŠ¸ë¡œ ë„£ì–´ì„œ, ë‹¤ë¥¸ ì˜ˆì‹œê°€ ìƒì„±ë˜ì§€ ì•Šë„ë¡ í•˜ê¸°\n",
    "    all_guidelines = {\n",
    "        \"yes\" : \"ì§ˆë¬¸ì´ '~í•  ìˆ˜ ìˆë‚˜ìš”?', '~ì¸ê°€ìš”?'ì²˜ëŸ¼ 'ê°€ë¶€'ë¥¼ ë¬¼ì„ ë•Œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\\n - ë¬¸êµ¬: 'ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤! ë„ì„œê´€ ê·œì •ì— ë”°ë¥´ë©´...'\\n - í™œìš©: ì§ˆë¬¸ì˜ ì¡°ê±´ì´ FAQì™€ ì¼ì¹˜í•  ë•Œ ì‚¬ìš©.\\n\",\n",
    "        \"no\" : \"ì§ˆë¬¸ì´ '~í•  ìˆ˜ ìˆë‚˜ìš”?', '~ì¸ê°€ìš”?'ì²˜ëŸ¼ 'ê°€ë¶€'ë¥¼ ë¬¼ì„ ë•Œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\\n - ë¬¸êµ¬: 'ì£„ì†¡í•˜ì§€ë§Œ ì–´ë µìŠµë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ”...'\\n - í™œìš©: ì§ˆë¬¸ì˜ ì¡°ê±´ì´ FAQ ê·œì •ì— ì–´ê¸‹ë‚  ë•Œ ì‚¬ìš©. 'ì‚¬ì‹¤ê³¼ ë‹¤ë¥´ë‹¤'ëŠ” í‘œí˜„ ëŒ€ì‹  'ê·œì •ìƒ ì–´ë µë‹¤'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\\n\",\n",
    "        \"info\" : \"ì§ˆë¬¸ì´ '~ì€ ë¬´ì—‡ì¸ê°€ìš”?', '~ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?', '~ì€ ì–¸ì œì¸ê°€ìš”?'ì²˜ëŸ¼ ì ˆì°¨/ì‹œê°„/ë°©ë²•ì„ ë¬¼ì„ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”.\\n ë¬¸êµ¬: 'ë¬¸ì˜í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ê´€ë ¨ ì„œë¥˜ëŠ”...'\\n - í™œìš©: ë„¤/ì•„ë‹ˆì˜¤ íŒë‹¨ì´ ì•„ë‹Œ ì •ë³´ ì§ˆë¬¸ì— ì‚¬ìš©.\\n\",\n",
    "        \"false\" : \"ë¬¸êµ¬: 'ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” í•´ë‹¹ ë‚´ìš©ì„ í™•ì¸í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.'\\n - í™œìš©: FAQì— ì—†ëŠ” ë‚´ìš©ì´ê±°ë‚˜ ì§ˆë¬¸ì´ ëª¨í˜¸í•  ë•Œ ì‚¬ìš©.\\n\\n\"\n",
    "    }\n",
    "    selected_guidelines = \"\\n\".join([all_guidelines[l] for l in target_labels if l in all_guidelines])\n",
    "\n",
    "    all_examples = {\n",
    "        \"yes\": '{\"question\": \"ì„ì‚°ë¶€ì¸ë° ë‚¨í¸ì´ ëŒ€ì‹  ë°œê¸‰ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?\", \"answer\": \"ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤! ë„ì„œê´€ ê·œì •ì— ë”°ë¥´ë©´ ì„ì‚°ë¶€ì˜ ê²½ìš° ëŒ€ë¦¬ ë°œê¸‰ ëŒ€ìƒì— í¬í•¨ë©ë‹ˆë‹¤.\", \"label\": \"yes\"}',\n",
    "        \"no\": '{\"question\": \"ì„±ì¸ ì§ì¥ì¸ì¸ë° ì¹œêµ¬ê°€ ëŒ€ì‹  ê°€ë„ ë˜ë‚˜ìš”?\", \"answer\": \"ì£„ì†¡í•˜ì§€ë§Œ, í•´ë‹¹ ì¡°ê±´ìœ¼ë¡œëŠ” ëŒ€ë¦¬ ë°œê¸‰ì´ ì–´ë µìŠµë‹ˆë‹¤. ëŒ€ë¦¬ ë°œê¸‰ì€ ì•„ë™, ì–´ë¥´ì‹ , ì¥ì• ì¸, ì„ì‚°ë¶€ë¡œ ëŒ€ìƒì´ ì œí•œë˜ì–´ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\", \"label\": \"no\"}',\n",
    "        \"info\": '{\"question\": \"ì¥ì• ì¸ ëŒ€ë¦¬ ë°œê¸‰ ì‹œ ì–´ë–¤ ì„œë¥˜ê°€ í•„ìš”í•œê°€ìš”?\", \"answer\": \"ë¬¸ì˜í•˜ì‹  ë‚´ìš©ì— ëŒ€í•´ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì¥ì• ì¸ ë³µì§€ì¹´ë“œ ë˜ëŠ” ì¥ì• ì¸ ì¦ëª…ì„œë¥¼ ì§€ì°¸í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\", \"label\": \"info\"}',\n",
    "        \"false\": '{\"question\": \"ë„ì„œê´€ ê·¼ì²˜ì— ë§›ìˆëŠ” ì‹ë‹¹ì´ ì–´ë””ì¸ê°€ìš”?\", \"answer\": \"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì œê³µëœ ì •ë³´ë§Œìœ¼ë¡œëŠ” í•´ë‹¹ ë‚´ìš©ì„ í™•ì¸í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.\", \"label\": \"false\"}'\n",
    "    }   \n",
    "\n",
    "    target_str = \", \".join(target_labels)\n",
    "    selected_examples = \",\\n      \".join([all_examples[l] for l in target_labels if l in all_examples])\n",
    "    system_message = (\n",
    "        f\"ë‹¹ì‹ ì€ ë„ì„œê´€ FAQ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶€ì¡±í•œ ìœ í˜•ì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ë³´ì¶©í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\n\"\n",
    "        f\"ì œê³µëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ë°˜ë“œì‹œ ë‹¤ìŒ ë¼ë²¨ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ ìƒì„±í•˜ì„¸ìš” : **[{target_str}]**\\n\\n\"\n",
    "        f\"ì´ë•Œ íŒë‹¨ì´ ì‰¬ìš´ ì˜ˆì‹œì™€ ë³´í†µ, ì–´ë ¤ìš´ ì˜ˆì‹œ ì´ 3ê°€ì§€ ìƒí™©ì„ ê°€ì •í•˜ì„¸ìš”.\"\n",
    "        f\"ê° ë¼ë²¨ë§ˆë‹¤ ìµœì†Œ 2~3ê°œì˜ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”\"\n",
    "        \n",
    "        f\"### [ë‹µë³€ ê°€ì´ë“œë¼ì¸]\\n{selected_guidelines}\\n\\n\"\n",
    "        \"ëª¨ë“  ë‹µë³€ì€ ì‹¤ì œ ë„ì„œê´€ ì‚¬ì„œê°€ ë°©ë¬¸ê°ì—ê²Œ ì„¤ëª…í•˜ë“¯ ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.\"\n",
    "        f\"**[{target_str}]**ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ë¼ë²¨ì€ ì ˆëŒ€ë¡œ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”\"\n",
    "        \"íŒë‹¨ ë¶ˆê°€ì˜ ê²½ìš° ë¬¸êµ¬ ì™¸ì— ë‹¤ë¥¸ ë¬¸ì¥ì€ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.\"\n",
    "        \"JSON ë‹µë³€ ì™¸ì— ë‹¤ë¥¸ ë¬¸ì¥ì€ ì¼ì²´ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”.\"\n",
    "    )\n",
    "\n",
    "    # ì‚¬ìš©ìê°€ ì •ì˜í•œ user_content\n",
    "    user_content = f\"\"\"\n",
    "    [ë„ì„œê´€ FAQ ì •ë³´]\n",
    "    {faq_content}\n",
    "    \n",
    "    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ë…¼ë¦¬ì ìœ¼ë¡œ ì™„ë²½í•˜ê²Œ ì´ì–´ì§€ëŠ” JSON ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n",
    "    \n",
    "    [ì¶œë ¥ ì˜ˆì‹œ]:\n",
    "    {selected_examples}\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]\n",
    "\n",
    "    print(messages)\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    outputs = pipe(\n",
    "        prompt, \n",
    "        max_new_tokens=2048, \n",
    "        do_sample=True, \n",
    "        temperature=0.7,\n",
    "        truncation=True,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # ìƒì„±ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê²°ê³¼ê°’ë§Œ ê¹”ë”í•˜ê²Œ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ prompt ì´í›„ ë‚´ìš©ë§Œ ìŠ¬ë¼ì´ì‹±)\n",
    "    full_text = outputs[0][\"generated_text\"]\n",
    "    response = full_text.split(\"[|assistant|]\")[-1].strip()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53259116-461e-4ff4-9c5e-c3c061d09998",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (868370360.py, line 31)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mitem[\"faq\"] =\u001b[39m\n                  ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ê° í–‰ë§ˆë‹¤ ë¶€ì¡±í•œ ë°ì´í„° ìœ í˜•ì„ í™•ì¸í•˜ì—¬ ë°ì´í„° ì¦ê°•\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_file = \"augmented_library_faq.jsonl\"\n",
    "target_titles = need_aug_idx.index.tolist()\n",
    "\n",
    "with open(output_file, \"a\", encoding=\"utf-8\") as f :\n",
    "    pbar = tqdm(target_titles, desc=\"íƒ€ê²Ÿ ë¼ë²¨ ë³´ì¶©\")\n",
    "    \n",
    "    for title in pbar :\n",
    "        current = pivot.loc[title]\n",
    "        missing_labels_list = [label for label in [\"yes\", \"no\", \"false\"] if current[label] <= 3]\n",
    "    \n",
    "        if not missing_labels_list :\n",
    "            continue\n",
    "    \n",
    "        missing_labels = \", \".join(missing_labels_list)\n",
    "        pbar.set_postfix(FAQ=title[:10] + \"..\", Labels=missing_labels)\n",
    "        \n",
    "        faq_data = [x for x in dataset if x[\"TITLE\"] == title][0]\n",
    "        faq_content = faq_data[\"DES\"]\n",
    "\n",
    "        try :\n",
    "            raw_output = generate_targeted_data(faq_content, missing_labels_list)\n",
    "            print(raw_output)\n",
    "            parsed_list = parse_generated_json(raw_output)\n",
    "\n",
    "            for item in parsed_list :\n",
    "                item[\"title\"] = title\n",
    "                item[\"faq\"] = \n",
    "                item[\"augmented\"] = True\n",
    "\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"\\n[ì—ëŸ¬ ë°œìƒ] {title}: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86303cf6-ca65-4baa-9dc6-dd0048fa33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "\n",
    "data = []\n",
    "with open(\"augmented_library_faq.jsonl\", \"r\", encoding=\"utf-8\") as f :\n",
    "    for line in f :\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5589dcb7-d46f-436c-bfc5-bb71c1540f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "info     593\n",
      "yes      533\n",
      "false    435\n",
      "no       388\n",
      "Name: count, dtype: int64\n",
      "-----\n",
      "question        2\n",
      "answer         16\n",
      "label           1\n",
      "faq             0\n",
      "title         678\n",
      "ë‹µë³€           1943\n",
      "augmented    1272\n",
      "dtype: int64\n",
      "-----\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1950 entries, 0 to 1949\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   question   1948 non-null   str   \n",
      " 1   answer     1934 non-null   str   \n",
      " 2   label      1949 non-null   str   \n",
      " 3   faq        1950 non-null   object\n",
      " 4   title      1272 non-null   str   \n",
      " 5   ë‹µë³€         7 non-null      str   \n",
      " 6   augmented  678 non-null    object\n",
      "dtypes: object(2), str(5)\n",
      "memory usage: 701.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ìƒì„±ëœ ë°ì´í„° í™•ì¸ (ê²°ì¸¡ì¹˜ í™•ì¸ ë° ë°ì´í„° ë³´ê°•ì„ ìœ„í•¨)\n",
    "\n",
    "print(df[\"label\"].value_counts())\n",
    "print(\"-----\")\n",
    "print(df.isnull().sum())\n",
    "print(\"-----\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b52193-acbd-4e75-842d-dd29a1b3ea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1950 entries, 0 to 1949\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   question   1948 non-null   str   \n",
      " 1   answer     1941 non-null   str   \n",
      " 2   label      1949 non-null   str   \n",
      " 3   faq        1950 non-null   object\n",
      " 4   title      1272 non-null   str   \n",
      " 5   augmented  678 non-null    object\n",
      "dtypes: object(2), str(4)\n",
      "memory usage: 686.1+ KB\n",
      "None\n",
      "question        2\n",
      "answer          9\n",
      "label           1\n",
      "faq             0\n",
      "title         678\n",
      "augmented    1272\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if \"ë‹µë³€\" in df.columns :\n",
    "    df[\"answer\"] = df[\"answer\"].fillna(df[\"ë‹µë³€\"])\n",
    "    df = df.drop(columns=[\"ë‹µë³€\"])\n",
    "\n",
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac23f65-c406-4db5-a905-4ce7ac6754c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1939 entries, 0 to 1938\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   question   1939 non-null   str   \n",
      " 1   answer     1939 non-null   str   \n",
      " 2   label      1939 non-null   str   \n",
      " 3   faq        1939 non-null   object\n",
      " 4   title      1262 non-null   str   \n",
      " 5   augmented  677 non-null    object\n",
      "dtypes: object(2), str(4)\n",
      "memory usage: 683.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"question\", \"answer\", \"label\"])\n",
    "df = df.reset_index(drop=True) # dropëœ í–‰ì˜ ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ë§¤ê¸°ê¸°\n",
    "\n",
    "print(df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df898bfc-368c-4e47-8729-0fcdacd99e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1. Label Distribution] ---\n",
      "label\n",
      "info     586\n",
      "yes      533\n",
      "false    433\n",
      "no       387\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAAHWCAYAAABt3aEVAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAANndJREFUeJzt3XtUVXX+//HXAeUiCAgJiCLqaCkl3kdPajpKkZmjk2U1jpdy9LsINaXMYcZbWNpYjmZjmn5NtMvXsinNSwbeS/FGo+MtU7PAFHBSQC1BZf/+aLl/ncBSRA58ej7W2muxP5/P3vv9ObNrXmv3Ofs4LMuyBAAAABjAw90FAAAAAOWFcAsAAABjEG4BAABgDMItAAAAjEG4BQAAgDEItwAAADAG4RYAAADGINwCAADAGIRbAAAAGINwC+BX76uvvpLD4dBLL71UbufcuHGjHA6HNm7cWG7nvGLSpElyOBzlft7SdO3aVV27drX3r8zrvffeq5DrDx48WA0aNKiQawEwA+EWQJWUkpIih8OhXbt2ubuUG3JlHlc2Hx8fRUREKC4uTrNmzdLZs2fL5TonTpzQpEmTtHv37nI5X3mqzLUBqHoItwBQCSQnJ+uNN97QnDlzNGLECEnSqFGj1Lx5c/3nP/9xGTtu3Dh9//3313X+EydO6Nlnn73uAJmamqrU1NTrOuZ6/Vxt8+fP16FDh27q9QGYpZq7CwAASD169FDbtm3t/aSkJK1fv17333+/fv/73+vgwYPy9fWVJFWrVk3Vqt3cf31/9913qlGjhry8vG7qdX5J9erV3Xp9AFUPT24BGKuoqEgTJkxQmzZtFBgYKD8/P3Xu3FkbNmy46jEzZsxQVFSUfH191aVLF+3bt6/EmM8//1wPPviggoOD5ePjo7Zt2+rDDz8s9/q7deum8ePH6+uvv9abb75pt5e25jYtLU2dOnVSUFCQ/P39ddttt+mvf/2rpB/WybZr106S9Nhjj9lLIFJSUiT9sK72jjvuUEZGhu666y7VqFHDPvana26vuHz5sv76178qPDxcfn5++v3vf6+srCyXMQ0aNNDgwYNLHPvjc/5SbaWtuT1//ryeeuopRUZGytvbW7fddpteeuklWZblMs7hcGj48OFatmyZ7rjjDnl7e+v222/XmjVrSv/AARiBJ7cAjFVQUKD//d//1aOPPqqhQ4fq7NmzWrBggeLi4rRjxw61bNnSZfzixYt19uxZJSQk6MKFC3r55ZfVrVs37d27V2FhYZKk/fv3q2PHjqpbt67+8pe/yM/PT++++6769Omjf/3rX/rDH/5QrnMYMGCA/vrXvyo1NVVDhw4tdcz+/ft1//33KyYmRsnJyfL29taRI0e0ZcsWSVKzZs2UnJysCRMmaNiwYercubMk6c4777TP8e2336pHjx565JFH9Kc//cme79U8//zzcjgcGjt2rHJzczVz5kzFxsZq9+7d9hPma3Ettf2YZVn6/e9/rw0bNmjIkCFq2bKlPv74Y40ZM0bffPONZsyY4TL+008/1fvvv68nnnhCNWvW1KxZs9S3b19lZmYqJCTkmusEUIVYAFAFLVy40JJk7dy586pjLl26ZBUWFrq0nTlzxgoLC7Mef/xxu+3YsWOWJMvX19c6fvy43b59+3ZLkjV69Gi7rXv37lbz5s2tCxcu2G3FxcXWnXfeaTVp0sRu27BhgyXJ2rBhww3PIzAw0GrVqpW9P3HiROvH//qeMWOGJck6derUVc+xc+dOS5K1cOHCEn1dunSxJFlz584tta9Lly4l5lW3bl2roKDAbn/33XctSdbLL79st0VFRVmDBg36xXP+XG2DBg2yoqKi7P1ly5ZZkqznnnvOZdyDDz5oORwO68iRI3abJMvLy8ulbc+ePZYk65VXXilxLQBmYFkCAGN5enraa0aLi4t1+vRpXbp0SW3bttVnn31WYnyfPn1Ut25de/+3v/2t2rdvr9WrV0uSTp8+rfXr16tfv346e/as/vvf/+q///2vvv32W8XFxenw4cP65ptvyn0e/v7+P/vWhKCgIEnS8uXLVVxcXKZreHt767HHHrvm8QMHDlTNmjXt/QcffFB16tSxP6ubZfXq1fL09NTIkSNd2p966ilZlqWPPvrIpT02Nla/+c1v7P2YmBgFBAToyy+/vKl1AnAfwi0Aoy1atEgxMTHy8fFRSEiIateurVWrVik/P7/E2CZNmpRou/XWW/XVV19Jko4cOSLLsjR+/HjVrl3bZZs4caIkKTc3t9zncO7cOZcg+VMPP/ywOnbsqD//+c8KCwvTI488onffffe6gm7dunWv68tjP/2sHA6HGjdubH9WN8vXX3+tiIiIEp9Hs2bN7P4fq1+/folz1KpVS2fOnLl5RQJwK9bcAjDWm2++qcGDB6tPnz4aM2aMQkND5enpqalTp+ro0aPXfb4rYfHpp59WXFxcqWMaN258QzX/1PHjx5Wfn/+z5/X19dXmzZu1YcMGrVq1SmvWrNE777yjbt26KTU1VZ6enr94netZJ3utrvZDE5cvX76mmsrD1a5j/eTLZwDMQbgFYKz33ntPjRo10vvvv+8StK48Zf2pw4cPl2j74osv7G/rN2rUSNIPr6eKjY0t/4JL8cYbb0jSVcP0FR4eHurevbu6d++uf/zjH5oyZYr+9re/acOGDYqNjS33XzT76WdlWZaOHDmimJgYu61WrVrKy8srcezXX39tf5bS1UNwaaKiorR27VqdPXvW5ent559/bvcD+HVjWQIAY115avfjp3Tbt29Xenp6qeOXLVvmsmZ2x44d2r59u3r06CFJCg0NVdeuXfXaa6/p5MmTJY4/depUeZav9evXa/LkyWrYsKH69+9/1XGnT58u0XblTRCFhYWSJD8/P0kqNWyWxZU3S1zx3nvv6eTJk/ZnJUm/+c1vtG3bNhUVFdltK1euLPHKsOup7b777tPly5f1z3/+06V9xowZcjgcLtcH8OvEk1sAVdrrr79e6ntLn3zySd1///16//339Yc//EE9e/bUsWPHNHfuXEVHR+vcuXMljmncuLE6deqk+Ph4FRYWaubMmQoJCdEzzzxjj5k9e7Y6deqk5s2ba+jQoWrUqJFycnKUnp6u48ePa8+ePWWax0cffaTPP/9cly5dUk5OjtavX6+0tDRFRUXpww8/lI+Pz1WPTU5O1ubNm9WzZ09FRUUpNzdXr776qurVq6dOnTpJ+iFoBgUFae7cuapZs6b8/PzUvn17NWzYsEz1BgcHq1OnTnrssceUk5OjmTNnqnHjxi6vK/vzn/+s9957T/fee6/69euno0eP6s0333T5gtf11tarVy/97ne/09/+9jd99dVXatGihVJTU7V8+XKNGjWqxLkB/Aq59V0NAFBGV16hdbUtKyvLKi4utqZMmWJFRUVZ3t7eVqtWrayVK1eWeL3UlVeBvfjii9b06dOtyMhIy9vb2+rcubO1Z8+eEtc+evSoNXDgQCs8PNyqXr26VbduXev++++33nvvPXvM9b4K7Mrm5eVlhYeHW3fffbf18ssvu7xu64qfvgps3bp1Vu/eva2IiAjLy8vLioiIsB599FHriy++cDlu+fLlVnR0tFWtWjWXV2916dLFuv3220ut72qvAvu///s/KykpyQoNDbV8fX2tnj17Wl9//XWJ46dPn27VrVvX8vb2tjp27Gjt2rWrxDl/rraf/m9lWZZ19uxZa/To0VZERIRVvXp1q0mTJtaLL75oFRcXu4yTZCUkJJSo6WqvKANgBodlsaoeAAAAZmDNLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAgAAwBiEWwAAABiDH3HQD78Xf+LECdWsWbPcf6ISAAAAN86yLJ09e1YRERHy8Lj681nCraQTJ04oMjLS3WUAAADgF2RlZalevXpX7SfcSqpZs6akHz6sgIAAN1cDAACAnyooKFBkZKSd266GcCvZSxECAgIItwAAAJXYLy0h5QtlAAAAMAbhFgAAAMZwe7j95ptv9Kc//UkhISHy9fVV8+bNtWvXLrvfsixNmDBBderUka+vr2JjY3X48GGXc5w+fVr9+/dXQECAgoKCNGTIEJ07d66ipwIAAAA3c2u4PXPmjDp27Kjq1avro48+0oEDBzR9+nTVqlXLHjNt2jTNmjVLc+fO1fbt2+Xn56e4uDhduHDBHtO/f3/t379faWlpWrlypTZv3qxhw4a5Y0oAAABwI4dlWZa7Lv6Xv/xFW7Zs0SeffFJqv2VZioiI0FNPPaWnn35akpSfn6+wsDClpKTokUce0cGDBxUdHa2dO3eqbdu2kqQ1a9bovvvu0/HjxxUREfGLdRQUFCgwMFD5+fl8oQwAAKASuta85tYntx9++KHatm2rhx56SKGhoWrVqpXmz59v9x87dkzZ2dmKjY212wIDA9W+fXulp6dLktLT0xUUFGQHW0mKjY2Vh4eHtm/fXup1CwsLVVBQ4LIBAACg6nNruP3yyy81Z84cNWnSRB9//LHi4+M1cuRILVq0SJKUnZ0tSQoLC3M5LiwszO7Lzs5WaGioS3+1atUUHBxsj/mpqVOnKjAw0N74AQcAAAAzuDXcFhcXq3Xr1poyZYpatWqlYcOGaejQoZo7d+5NvW5SUpLy8/PtLSsr66ZeDwAAABXDreG2Tp06io6Odmlr1qyZMjMzJUnh4eGSpJycHJcxOTk5dl94eLhyc3Nd+i9duqTTp0/bY37K29vb/sEGfrgBAADAHG4Ntx07dtShQ4dc2r744gtFRUVJkho2bKjw8HCtW7fO7i8oKND27dvldDolSU6nU3l5ecrIyLDHrF+/XsXFxWrfvn0FzAIAAACVhVt/fnf06NG68847NWXKFPXr1087duzQvHnzNG/ePEk//LzaqFGj9Nxzz6lJkyZq2LChxo8fr4iICPXp00fSD0967733Xns5w8WLFzV8+HA98sgj1/SmBAAAAJjDra8Ck6SVK1cqKSlJhw8fVsOGDZWYmKihQ4fa/ZZlaeLEiZo3b57y8vLUqVMnvfrqq7r11lvtMadPn9bw4cO1YsUKeXh4qG/fvpo1a5b8/f2vqQZeBQYAAFC5XWtec3u4rQwItwAAAJVblXjPLQAAAFCeCLcAAAAwhlu/UAYAqJzajFns7hJQgTJeHOjuEoByw5NbAAAAGINwCwAAAGMQbgEAAGAMwi0AAACMQbgFAACAMQi3AAAAMAbhFgAAAMYg3AIAAMAYhFsAAAAYg3ALAAAAYxBuAQAAYAzCLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAgAAwBiEWwAAABiDcAsAAABjEG4BAABgDMItAAAAjEG4BQAAgDEItwAAADAG4RYAAADGINwCAADAGIRbAAAAGINwCwAAAGMQbgEAAGAMwi0AAACMQbgFAACAMQi3AAAAMAbhFgAAAMYg3AIAAMAY1dxdgAnajFns7hJQgTJeHOjuEgAAwFXw5BYAAADGINwCAADAGIRbAAAAGINwCwAAAGMQbgEAAGAMwi0AAACMQbgFAACAMQi3AAAAMAbhFgAAAMYg3AIAAMAYhFsAAAAYg3ALAAAAYxBuAQAAYAzCLQAAAIxBuAUAAIAxCLcAAAAwhlvD7aRJk+RwOFy2pk2b2v0XLlxQQkKCQkJC5O/vr759+yonJ8flHJmZmerZs6dq1Kih0NBQjRkzRpcuXaroqQAAAKASqObuAm6//XatXbvW3q9W7f+XNHr0aK1atUpLly5VYGCghg8frgceeEBbtmyRJF2+fFk9e/ZUeHi4tm7dqpMnT2rgwIGqXr26pkyZUuFzAQAAgHu5PdxWq1ZN4eHhJdrz8/O1YMECvf322+rWrZskaeHChWrWrJm2bdumDh06KDU1VQcOHNDatWsVFhamli1bavLkyRo7dqwmTZokLy+vip4OAAAA3Mjta24PHz6siIgINWrUSP3791dmZqYkKSMjQxcvXlRsbKw9tmnTpqpfv77S09MlSenp6WrevLnCwsLsMXFxcSooKND+/fuves3CwkIVFBS4bAAAAKj63Bpu27dvr5SUFK1Zs0Zz5szRsWPH1LlzZ509e1bZ2dny8vJSUFCQyzFhYWHKzs6WJGVnZ7sE2yv9V/quZurUqQoMDLS3yMjI8p0YAAAA3MKtyxJ69Ohh/x0TE6P27dsrKipK7777rnx9fW/adZOSkpSYmGjvFxQUEHABAAAM4PZlCT8WFBSkW2+9VUeOHFF4eLiKioqUl5fnMiYnJ8deoxseHl7i7QlX9ktbx3uFt7e3AgICXDYAAABUfZUq3J47d05Hjx5VnTp11KZNG1WvXl3r1q2z+w8dOqTMzEw5nU5JktPp1N69e5Wbm2uPSUtLU0BAgKKjoyu8fgAAALiXW5clPP300+rVq5eioqJ04sQJTZw4UZ6ennr00UcVGBioIUOGKDExUcHBwQoICNCIESPkdDrVoUMHSdI999yj6OhoDRgwQNOmTVN2drbGjRunhIQEeXt7u3NqAAAAcAO3htvjx4/r0Ucf1bfffqvatWurU6dO2rZtm2rXri1JmjFjhjw8PNS3b18VFhYqLi5Or776qn28p6enVq5cqfj4eDmdTvn5+WnQoEFKTk5215QAAADgRm4Nt0uWLPnZfh8fH82ePVuzZ8++6pioqCitXr26vEsDAABAFVSp1twCAAAAN4JwCwAAAGMQbgEAAGAMwi0AAACMQbgFAACAMQi3AAAAMAbhFgAAAMYg3AIAAMAYhFsAAAAYg3ALAAAAYxBuAQAAYAzCLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAgAAwBiEWwAAABiDcAsAAABjEG4BAABgDMItAAAAjEG4BQAAgDEItwAAADAG4RYAAADGINwCAADAGIRbAAAAGINwCwAAAGMQbgEAAGAMwi0AAACMQbgFAACAMQi3AAAAMAbhFgAAAMYg3AIAAMAYhFsAAAAYg3ALAAAAYxBuAQAAYIxq7i4AAAD8erUZs9jdJaACZbw48KZfgye3AAAAMAbhFgAAAMYg3AIAAMAYhFsAAAAYg3ALAAAAYxBuAQAAYAzCLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAgAAwBiEWwAAABiDcAsAAABjEG4BAABgDMItAAAAjEG4BQAAgDEqTbh94YUX5HA4NGrUKLvtwoULSkhIUEhIiPz9/dW3b1/l5OS4HJeZmamePXuqRo0aCg0N1ZgxY3Tp0qUKrh4AAACVQaUItzt37tRrr72mmJgYl/bRo0drxYoVWrp0qTZt2qQTJ07ogQcesPsvX76snj17qqioSFu3btWiRYuUkpKiCRMmVPQUAAAAUAm4PdyeO3dO/fv31/z581WrVi27PT8/XwsWLNA//vEPdevWTW3atNHChQu1detWbdu2TZKUmpqqAwcO6M0331TLli3Vo0cPTZ48WbNnz1ZRUdFVr1lYWKiCggKXDQAAAFWf28NtQkKCevbsqdjYWJf2jIwMXbx40aW9adOmql+/vtLT0yVJ6enpat68ucLCwuwxcXFxKigo0P79+696zalTpyowMNDeIiMjy3lWAAAAcAe3htslS5bos88+09SpU0v0ZWdny8vLS0FBQS7tYWFhys7Otsf8ONhe6b/SdzVJSUnKz8+3t6ysrBucCQAAACqDau66cFZWlp588kmlpaXJx8enQq/t7e0tb2/vCr0mAAAAbj63PbnNyMhQbm6uWrdurWrVqqlatWratGmTZs2apWrVqiksLExFRUXKy8tzOS4nJ0fh4eGSpPDw8BJvT7iyf2UMAAAAfj3cFm67d++uvXv3avfu3fbWtm1b9e/f3/67evXqWrdunX3MoUOHlJmZKafTKUlyOp3au3evcnNz7TFpaWkKCAhQdHR0hc8JAAAA7uW2ZQk1a9bUHXfc4dLm5+enkJAQu33IkCFKTExUcHCwAgICNGLECDmdTnXo0EGSdM899yg6OloDBgzQtGnTlJ2drXHjxikhIYFlBwAAAL9Cbgu312LGjBny8PBQ3759VVhYqLi4OL366qt2v6enp1auXKn4+Hg5nU75+flp0KBBSk5OdmPVAAAAcJdKFW43btzosu/j46PZs2dr9uzZVz0mKipKq1evvsmVAQAAoCpw+3tuAQAAgPJSqZ7cAvh5bcYsdncJqEAZLw50dwkAUOXw5BYAAADGINwCAADAGIRbAAAAGINwCwAAAGMQbgEAAGAMwi0AAACMQbgFAACAMQi3AAAAMAbhFgAAAMYg3AIAAMAYhFsAAAAYg3ALAAAAYxBuAQAAYAzCLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAgAAwBiEWwAAABiDcAsAAABjEG4BAABgDMItAAAAjEG4BQAAgDEItwAAADAG4RYAAADGINwCAADAGIRbAAAAGINwCwAAAGMQbgEAAGAMwi0AAACMQbgFAACAMcoUbrt166a8vLwS7QUFBerWrduN1gQAAACUSZnC7caNG1VUVFSi/cKFC/rkk09uuCgAAACgLKpdz+D//Oc/9t8HDhxQdna2vX/58mWtWbNGdevWLb/qAAAAgOtwXeG2ZcuWcjgccjgcpS4/8PX11SuvvFJuxQEAAADX47rC7bFjx2RZlho1aqQdO3aodu3adp+Xl5dCQ0Pl6elZ7kUCAAAA1+K6wm1UVJQkqbi4+KYUAwAAANyI6wq3P3b48GFt2LBBubm5JcLuhAkTbrgwAAAA4HqVKdzOnz9f8fHxuuWWWxQeHi6Hw2H3ORwOwi0AAADcokzh9rnnntPzzz+vsWPHlnc9AAAAQJmV6T23Z86c0UMPPVTetQAAAAA3pEzh9qGHHlJqamp51wIAAADckDItS2jcuLHGjx+vbdu2qXnz5qpevbpL/8iRI8ulOAAAAOB6lCnczps3T/7+/tq0aZM2bdrk0udwOAi3AAAAcIsyhdtjx46Vdx0AAADADSvTmlsAAACgMirTk9vHH3/8Z/tff/31MhUDAAAA3IgyhdszZ8647F+8eFH79u1TXl6eunXrVi6FAQAAANerTOH2gw8+KNFWXFys+Ph4/eY3v7nhogAAAICyKLc1tx4eHkpMTNSMGTOu+Zg5c+YoJiZGAQEBCggIkNPp1EcffWT3X7hwQQkJCQoJCZG/v7/69u2rnJwcl3NkZmaqZ8+eqlGjhkJDQzVmzBhdunSpvKYFAACAKqRcv1B29OjR6wqW9erV0wsvvKCMjAzt2rVL3bp1U+/evbV//35J0ujRo7VixQotXbpUmzZt0okTJ/TAAw/Yx1++fFk9e/ZUUVGRtm7dqkWLFiklJUUTJkwoz2kBAACgiijTsoTExESXfcuydPLkSa1atUqDBg265vP06tXLZf/555/XnDlztG3bNtWrV08LFizQ22+/ba/jXbhwoZo1a6Zt27apQ4cOSk1N1YEDB7R27VqFhYWpZcuWmjx5ssaOHatJkybJy8urLNMDAABAFVWmcPvvf//bZd/Dw0O1a9fW9OnTf/FNCldz+fJlLV26VOfPn5fT6VRGRoYuXryo2NhYe0zTpk1Vv359paenq0OHDkpPT1fz5s0VFhZmj4mLi1N8fLz279+vVq1alXqtwsJCFRYW2vsFBQVlqhkAAACVS5nC7YYNG8qtgL1798rpdOrChQvy9/fXBx98oOjoaO3evVteXl4KCgpyGR8WFqbs7GxJUnZ2tkuwvdJ/pe9qpk6dqmeffbbc5gAAAIDK4YbW3J46dUqffvqpPv30U506dapM57jtttu0e/dubd++XfHx8Ro0aJAOHDhwI2X9oqSkJOXn59tbVlbWTb0eAAAAKkaZntyeP39eI0aM0OLFi1VcXCxJ8vT01MCBA/XKK6+oRo0a13wuLy8vNW7cWJLUpk0b7dy5Uy+//LIefvhhFRUVKS8vz+XpbU5OjsLDwyVJ4eHh2rFjh8v5rrxN4cqY0nh7e8vb2/uaawQAAEDVUKYnt4mJidq0aZNWrFihvLw85eXlafny5dq0aZOeeuqpGyqouLhYhYWFatOmjapXr65169bZfYcOHVJmZqacTqckyel0au/evcrNzbXHpKWlKSAgQNHR0TdUBwAAAKqeMj25/de//qX33ntPXbt2tdvuu+8++fr6ql+/fpozZ841nScpKUk9evRQ/fr1dfbsWb399tvauHGjPv74YwUGBmrIkCFKTExUcHCwAgICNGLECDmdTnXo0EGSdM899yg6OloDBgzQtGnTlJ2drXHjxikhIYEnswAAAL9CZQq33333XYkvcklSaGiovvvuu2s+T25urgYOHKiTJ08qMDBQMTEx+vjjj3X33XdLkmbMmCEPDw/17dtXhYWFiouL06uvvmof7+npqZUrVyo+Pl5Op1N+fn4aNGiQkpOTyzItAAAAVHFlCrdOp1MTJ07U4sWL5ePjI0n6/vvv9eyzz9pLBq7FggULfrbfx8dHs2fP1uzZs686JioqSqtXr77mawIAAMBcZQq3M2fO1L333qt69eqpRYsWkqQ9e/bI29tbqamp5VogAAAAcK3KFG6bN2+uw4cP66233tLnn38uSXr00UfVv39/+fr6lmuBAAAAwLUqU7idOnWqwsLCNHToUJf2119/XadOndLYsWPLpTgAAADgepTpVWCvvfaamjZtWqL99ttv19y5c2+4KAAAAKAsyhRus7OzVadOnRLttWvX1smTJ2+4KAAAAKAsyhRuIyMjtWXLlhLtW7ZsUURExA0XBQAAAJRFmdbcDh06VKNGjdLFixfVrVs3SdK6dev0zDPP3PAvlAEAAABlVaZwO2bMGH377bd64oknVFRUJOmHd9KOHTtWSUlJ5VogAAAAcK3KFG4dDof+/ve/a/z48Tp48KB8fX3VpEkTfvIWAAAAblWmcHuFv7+/2rVrV161AAAAADekTF8oAwAAACojwi0AAACMQbgFAACAMQi3AAAAMAbhFgAAAMYg3AIAAMAYhFsAAAAYg3ALAAAAYxBuAQAAYAzCLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAgAAwBiEWwAAABiDcAsAAABjEG4BAABgDMItAAAAjEG4BQAAgDEItwAAADAG4RYAAADGINwCAADAGIRbAAAAGINwCwAAAGMQbgEAAGAMwi0AAACMQbgFAACAMQi3AAAAMAbhFgAAAMYg3AIAAMAYhFsAAAAYg3ALAAAAYxBuAQAAYAzCLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAgAAwBiEWwAAABiDcAsAAABjEG4BAABgDMItAAAAjOHWcDt16lS1a9dONWvWVGhoqPr06aNDhw65jLlw4YISEhIUEhIif39/9e3bVzk5OS5jMjMz1bNnT9WoUUOhoaEaM2aMLl26VJFTAQAAQCXg1nC7adMmJSQkaNu2bUpLS9PFixd1zz336Pz58/aY0aNHa8WKFVq6dKk2bdqkEydO6IEHHrD7L1++rJ49e6qoqEhbt27VokWLlJKSogkTJrhjSgAAAHCjau68+Jo1a1z2U1JSFBoaqoyMDN11113Kz8/XggUL9Pbbb6tbt26SpIULF6pZs2batm2bOnTooNTUVB04cEBr165VWFiYWrZsqcmTJ2vs2LGaNGmSvLy83DE1AAAAuEGlWnObn58vSQoODpYkZWRk6OLFi4qNjbXHNG3aVPXr11d6erokKT09Xc2bN1dYWJg9Ji4uTgUFBdq/f3+p1yksLFRBQYHLBgAAgKqv0oTb4uJijRo1Sh07dtQdd9whScrOzpaXl5eCgoJcxoaFhSk7O9se8+Nge6X/Sl9ppk6dqsDAQHuLjIws59kAAADAHSpNuE1ISNC+ffu0ZMmSm36tpKQk5efn21tWVtZNvyYAAABuPreuub1i+PDhWrlypTZv3qx69erZ7eHh4SoqKlJeXp7L09ucnByFh4fbY3bs2OFyvitvU7gy5qe8vb3l7e1dzrMAAACAu7n1ya1lWRo+fLg++OADrV+/Xg0bNnTpb9OmjapXr65169bZbYcOHVJmZqacTqckyel0au/evcrNzbXHpKWlKSAgQNHR0RUzEQAAAFQKbn1ym5CQoLffflvLly9XzZo17TWygYGB8vX1VWBgoIYMGaLExEQFBwcrICBAI0aMkNPpVIcOHSRJ99xzj6KjozVgwABNmzZN2dnZGjdunBISEng6CwAA8Cvj1nA7Z84cSVLXrl1d2hcuXKjBgwdLkmbMmCEPDw/17dtXhYWFiouL06uvvmqP9fT01MqVKxUfHy+n0yk/Pz8NGjRIycnJFTUNAAAAVBJuDbeWZf3iGB8fH82ePVuzZ8++6pioqCitXr26PEsDAABAFVRp3pYAAAAA3CjCLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAgAAwBiEWwAAABiDcAsAAABjEG4BAABgDMItAAAAjEG4BQAAgDEItwAAADAG4RYAAADGINwCAADAGIRbAAAAGINwCwAAAGMQbgEAAGAMwi0AAACMQbgFAACAMQi3AAAAMAbhFgAAAMYg3AIAAMAYhFsAAAAYg3ALAAAAYxBuAQAAYAzCLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAgAAwBiEWwAAABiDcAsAAABjEG4BAABgDMItAAAAjEG4BQAAgDEItwAAADAG4RYAAADGINwCAADAGIRbAAAAGINwCwAAAGMQbgEAAGAMwi0AAACMQbgFAACAMQi3AAAAMAbhFgAAAMYg3AIAAMAYhFsAAAAYg3ALAAAAYxBuAQAAYAzCLQAAAIxBuAUAAIAx3BpuN2/erF69eikiIkIOh0PLli1z6bcsSxMmTFCdOnXk6+ur2NhYHT582GXM6dOn1b9/fwUEBCgoKEhDhgzRuXPnKnAWAAAAqCzcGm7Pnz+vFi1aaPbs2aX2T5s2TbNmzdLcuXO1fft2+fn5KS4uThcuXLDH9O/fX/v371daWppWrlypzZs3a9iwYRU1BQAAAFQi1dx58R49eqhHjx6l9lmWpZkzZ2rcuHHq3bu3JGnx4sUKCwvTsmXL9Mgjj+jgwYNas2aNdu7cqbZt20qSXnnlFd1333166aWXFBERUWFzAQAAgPtV2jW3x44dU3Z2tmJjY+22wMBAtW/fXunp6ZKk9PR0BQUF2cFWkmJjY+Xh4aHt27df9dyFhYUqKChw2QAAAFD1Vdpwm52dLUkKCwtzaQ8LC7P7srOzFRoa6tJfrVo1BQcH22NKM3XqVAUGBtpbZGRkOVcPAAAAd6i04fZmSkpKUn5+vr1lZWW5uyQAAACUg0obbsPDwyVJOTk5Lu05OTl2X3h4uHJzc136L126pNOnT9tjSuPt7a2AgACXDQAAAFVfpQ23DRs2VHh4uNatW2e3FRQUaPv27XI6nZIkp9OpvLw8ZWRk2GPWr1+v4uJitW/fvsJrBgAAgHu59W0J586d05EjR+z9Y8eOaffu3QoODlb9+vU1atQoPffcc2rSpIkaNmyo8ePHKyIiQn369JEkNWvWTPfee6+GDh2quXPn6uLFixo+fLgeeeQR3pQAAADwK+TWcLtr1y797ne/s/cTExMlSYMGDVJKSoqeeeYZnT9/XsOGDVNeXp46deqkNWvWyMfHxz7mrbfe0vDhw9W9e3d5eHiob9++mjVrVoXPBQAAAO7n1nDbtWtXWZZ11X6Hw6Hk5GQlJydfdUxwcLDefvvtm1EeAAAAqphKu+YWAAAAuF6EWwAAABiDcAsAAABjEG4BAABgDMItAAAAjEG4BQAAgDEItwAAADAG4RYAAADGINwCAADAGIRbAAAAGINwCwAAAGMQbgEAAGAMwi0AAACMQbgFAACAMQi3AAAAMAbhFgAAAMYg3AIAAMAYhFsAAAAYg3ALAAAAYxBuAQAAYAzCLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAgAAwBiEWwAAABiDcAsAAABjEG4BAABgDMItAAAAjEG4BQAAgDEItwAAADAG4RYAAADGINwCAADAGIRbAAAAGINwCwAAAGMQbgEAAGAMwi0AAACMQbgFAACAMQi3AAAAMAbhFgAAAMYg3AIAAMAYhFsAAAAYg3ALAAAAYxBuAQAAYAzCLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAgAAwBiEWwAAABiDcAsAAABjEG4BAABgDGPC7ezZs9WgQQP5+Pioffv22rFjh7tLAgAAQAUzIty+8847SkxM1MSJE/XZZ5+pRYsWiouLU25urrtLAwAAQAUyItz+4x//0NChQ/XYY48pOjpac+fOVY0aNfT666+7uzQAAABUoGruLuBGFRUVKSMjQ0lJSXabh4eHYmNjlZ6eXuoxhYWFKiwstPfz8/MlSQUFBWWq4XLh92U6DlVTWe+T8sC99uvCvYaKwr2GinIj99qVYy3L+vmBVhX3zTffWJKsrVu3urSPGTPG+u1vf1vqMRMnTrQksbGxsbGxsbGxVbEtKyvrZ7NhlX9yWxZJSUlKTEy094uLi3X69GmFhITI4XC4sbKqo6CgQJGRkcrKylJAQIC7y4HBuNdQUbjXUFG418rGsiydPXtWERERPzuuyofbW265RZ6ensrJyXFpz8nJUXh4eKnHeHt7y9vb26UtKCjoZpVotICAAP7BRIXgXkNF4V5DReFeu36BgYG/OKbKf6HMy8tLbdq00bp16+y24uJirVu3Tk6n042VAQAAoKJV+Se3kpSYmKhBgwapbdu2+u1vf6uZM2fq/Pnzeuyxx9xdGgAAACqQEeH24Ycf1qlTpzRhwgRlZ2erZcuWWrNmjcLCwtxdmrG8vb01ceLEEss7gPLGvYaKwr2GisK9dnM5LOuX3qcAAAAAVA1Vfs0tAAAAcAXhFgAAAMYg3AIAAMAYhFsAgLG6du2qUaNGXfP4zz//XB06dJCPj49atmx50+qCGSzL0rBhwxQcHCyHw6Hdu3f/7PivvvrqmsbhxhjxtgQAAErz/vvvq3r16tc8fuLEifLz89OhQ4fk7+9/EyuDCdasWaOUlBRt3LhRjRo10i233OLukiDCLQDAYMHBwdc1/ujRo+rZs6eioqJuUkUwydGjR1WnTh3deeed7i4FP8KyBLhYvHixQkJCVFhY6NLep08fDRgwQJK0fPlytW7dWj4+PmrUqJGeffZZXbp0SdIP/4lm0qRJql+/vry9vRUREaGRI0dW+DxQ9XTt2lUjR47UM888o+DgYIWHh2vSpEl2f2Zmpnr37i1/f38FBASoX79+JX52G/ipHy9LaNCggaZMmaLHH39cNWvWVP369TVv3jx7rMPhUEZGhpKTk+VwOOz7b+/everWrZt8fX0VEhKiYcOG6dy5c26YDSqTwYMHa8SIEcrMzJTD4VCDBg20Zs0aderUSUFBQQoJCdH999+vo0ePXvUcZ86cUf/+/VW7dm35+vqqSZMmWrhwod2flZWlfv36KSgoSMHBwerdu7e++uqrCphd1Ua4hYuHHnpIly9f1ocffmi35ebmatWqVXr88cf1ySefaODAgXryySd14MABvfbaa0pJSdHzzz8vSfrXv/6lGTNm6LXXXtPhw4e1bNkyNW/e3F3TQRWzaNEi+fn5afv27Zo2bZqSk5OVlpam4uJi9e7dW6dPn9amTZuUlpamL7/8Ug8//LC7S0YVM336dLVt21b//ve/9cQTTyg+Pl6HDh2SJJ08eVK33367nnrqKZ08eVJPP/20zp8/r7i4ONWqVUs7d+7U0qVLtXbtWg0fPtzNM4G7vfzyy0pOTla9evV08uRJ7dy5U+fPn1diYqJ27dqldevWycPDQ3/4wx9UXFxc6jnGjx+vAwcO6KOPPtLBgwc1Z84ce2nDxYsXFRcXp5o1a+qTTz7Rli1b5O/vr3vvvVdFRUUVOdWqxwJ+Ij4+3urRo4e9P336dKtRo0ZWcXGx1b17d2vKlCku49944w2rTp069thbb73VKioqqtCaUfV16dLF6tSpk0tbu3btrLFjx1qpqamWp6enlZmZafft37/fkmTt2LGjoktFFdKlSxfrySeftCzLsqKioqw//elPdl9xcbEVGhpqzZkzx25r0aKFNXHiRHt/3rx5Vq1ataxz587ZbatWrbI8PDys7Ozsm14/KrcZM2ZYUVFRV+0/deqUJcnau3evZVmWdezYMUuS9e9//9uyLMvq1auX9dhjj5V67BtvvGHddtttVnFxsd1WWFho+fr6Wh9//HG5zcFEPLlFCUOHDlVqaqq++eYbSVJKSooGDx4sh8OhPXv2KDk5Wf7+/vY2dOhQnTx5Ut99950eeughff/992rUqJGGDh2qDz74wF6yAPySmJgYl/06deooNzdXBw8eVGRkpCIjI+2+6OhoBQUF6eDBgxVdJqqwH99jDodD4eHhys3Nver4gwcPqkWLFvLz87PbOnbsqOLiYvuJL3DF4cOH9eijj6pRo0YKCAhQgwYNJP2wrKo08fHxWrJkiVq2bKlnnnlGW7dutfv27NmjI0eOqGbNmvb/3wYHB+vChQs/u9QBfKEMpWjVqpVatGihxYsX65577tH+/fu1atUqSdK5c+f07LPP6oEHHihxnI+PjyIjI3Xo0CGtXbtWaWlpeuKJJ/Tiiy9q06ZN1/WNZfw6/fQecTgcV/3PeUBZcI/hZurVq5eioqI0f/58RUREqLi4WHfcccdVlxH06NFDX3/9tVavXq20tDR1795dCQkJeumll3Tu3Dm1adNGb731VonjateufbOnUqURblGqP//5z5o5c6a++eYbxcbG2k/MWrdurUOHDqlx48ZXPdbX11e9evVSr169lJCQoKZNm2rv3r1q3bp1RZUPwzRr1kxZWVnKysqy78UDBw4oLy9P0dHRbq4OJmvWrJlSUlJ0/vx5++ntli1b5OHhodtuu83N1aEy+fbbb3Xo0CHNnz9fnTt3liR9+umnv3hc7dq1NWjQIA0aNEidO3fWmDFj9NJLL6l169Z65513FBoaqoCAgJtdvlFYloBS/fGPf9Tx48c1f/58Pf7443b7hAkTtHjxYj377LPav3+/Dh48qCVLlmjcuHGSfljCsGDBAu3bt09ffvml3nzzTfn6+vJaHdyQ2NhYNW/eXP3799dnn32mHTt2aODAgerSpYvatm3r7vJgsP79+8vHx0eDBg3Svn37tGHDBo0YMUIDBgxQWFiYu8tDJVKrVi2FhIRo3rx5OnLkiNavX6/ExMSfPWbChAlavny5jhw5ov3792vlypVq1qyZpB/uvVtuuUW9e/fWJ598omPHjmnjxo0aOXKkjh8/XhFTqrIItyhVYGCg+vbtK39/f/Xp08duj4uL08qVK5Wamqp27dqpQ4cOmjFjhh1eg4KCNH/+fHXs2FExMTFau3atVqxYoZCQEDfNBCZwOBxavny5atWqpbvuukuxsbFq1KiR3nnnHXeXBsPVqFFDH3/8sU6fPq127drpwQcfVPfu3fXPf/7T3aWhkvHw8NCSJUuUkZGhO+64Q6NHj9aLL774s8d4eXkpKSlJMTExuuuuu+Tp6aklS5ZI+uHe27x5s+rXr68HHnhAzZo105AhQ3ThwgWe5P4Ch2VZlruLQOXUvXt33X777Zo1a5a7SwEAALgmhFuUcObMGW3cuFEPPvigDhw4wLoyAABQZfCFMpTQqlUrnTlzRn//+98JtgAAoErhyS0AAACMwRfKAAAAYAzCLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAkAl1bVrV40aNeqaxm7cuFEOh0N5eXk3dM0GDRpo5syZN3QOAHAnwi0AAACMQbgFAACAMQi3AFAFvPHGG2rbtq1q1qyp8PBw/fGPf1Rubm6JcVu2bFFMTIx8fHzUoUMH7du3z6X/008/VefOneXr66vIyEiNHDlS58+fr6hpAMBNR7gFgCrg4sWLmjx5svbs2aNly5bpq6++0uDBg0uMGzNmjKZPn66dO3eqdu3a6tWrly5evChJOnr0qO6991717dtX//nPf/TOO+/o008/1fDhwyt4NgBw81RzdwEAgF/2+OOP2383atRIs2bNUrt27XTu3Dn5+/vbfRMnTtTdd98tSVq0aJHq1aunDz74QP369dPUqVPVv39/+0tqTZo00axZs9SlSxfNmTNHPj4+FTonALgZeHILAFVARkaGevXqpfr166tmzZrq0qWLJCkzM9NlnNPptP8ODg7WbbfdpoMHD0qS9uzZo5SUFPn7+9tbXFyciouLdezYsYqbDADcRDy5BYBK7vz584qLi1NcXJzeeust1a5dW5mZmYqLi1NRUdE1n+fcuXP6n//5H40cObJEX/369cuzZABwG8ItAFRyn3/+ub799lu98MILioyMlCTt2rWr1LHbtm2zg+qZM2f0xRdfqFmzZpKk1q1b68CBA2rcuHHFFA4AbsCyBACo5OrXry8vLy+98sor+vLLL/Xhhx9q8uTJpY5NTk7WunXrtG/fPg0ePFi33HKL+vTpI0kaO3astm7dquHDh2v37t06fPiwli9fzhfKABiFcAsAlVzt2rWVkpKipUuXKjo6Wi+88IJeeumlUse+8MILevLJJ9WmTRtlZ2drxYoV8vLykiTFxMRo06ZN+uKLL9S5c2e1atVKEyZMUEREREVOBwBuKodlWZa7iwAAAADKA09uAQAAYAzCLQAAAIxBuAUAAIAxCLcAAAAwBuEWAAAAxiDcAgAAwBiEWwAAABiDcAsAAABjEG4BAABgDMItAAAAjEG4BQAAgDH+HxS4YctD0B4dAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "\n",
    "# 2. ë¼ë²¨ ë¶„í¬ í™•ì¸ (ê· í˜•ì„±)\n",
    "print(\"--- [1. Label Distribution] ---\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='label', order=['yes', 'no', 'info', 'false'])\n",
    "plt.title(\"Label Distribution\")\n",
    "plt.savefig(\"label_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b7d031d-e58f-41f1-9c20-12e54ad56e59",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'faq'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3641\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3640\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:168\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:197\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7668\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7676\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'faq'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# ë§Œì•½ ë¬¸ìì—´ì´ë¼ë©´ (ì‹¤ìˆ˜ë¡œ ë“¤ì–´ê°„ TITLEì¸ ê²½ìš°)\u001b[39;00m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m title_to_des.get(faq_val, \u001b[33m\"\u001b[39m\u001b[33më³¸ë¬¸ ì—†ìŒ\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfaq\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.apply(recovery_des) \u001b[38;5;66;03m# ë°ì´í„°í”„ë ˆì„ì— í•¨ìˆ˜ ì ìš©\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/pandas/core/frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3648\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3644\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3645\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3646\u001b[39m     ):\n\u001b[32m   3647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3650\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3651\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3652\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3653\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'faq'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "id_to_des = {x['FAQ']: x['DES'] for x in dataset}\n",
    "title_to_des = {x['TITLE']: x['DES'] for x in dataset}\n",
    "\n",
    "def recovery_des(faq_val):\n",
    "    # ë§Œì•½ ìˆ«ìë¼ë©´ (ì›ë³¸ FAQ ë²ˆí˜¸ì¸ ê²½ìš°)\n",
    "    if isinstance(faq_val, (int, float)) or (str(faq_val).isdigit()):\n",
    "        return id_to_des.get(int(faq_val), \"ë³¸ë¬¸ ì—†ìŒ\")\n",
    "    # ë§Œì•½ ë¬¸ìì—´ì´ë¼ë©´ (ì‹¤ìˆ˜ë¡œ ë“¤ì–´ê°„ TITLEì¸ ê²½ìš°)\n",
    "    else:\n",
    "        return title_to_des.get(faq_val, \"ë³¸ë¬¸ ì—†ìŒ\")\n",
    "\n",
    "df['description'] = df['faq'].apply(recovery_des) # ë°ì´í„°í”„ë ˆì„ì— í•¨ìˆ˜ ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "042b91a6-6301-4963-8da5-a99462b6b478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1939 entries, 0 to 1938\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   question     1939 non-null   str   \n",
      " 1   answer       1939 non-null   str   \n",
      " 2   label        1939 non-null   str   \n",
      " 3   faq          1939 non-null   object\n",
      " 4   title        1262 non-null   str   \n",
      " 5   augmented    677 non-null    object\n",
      " 6   description  1939 non-null   str   \n",
      "dtypes: object(2), str(5)\n",
      "memory usage: 1.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374cc64c-2e8a-43c6-b88c-da78d9e0eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° ë°ì´í„° ì¦ê°• ì´í›„ íŒŒì¸íŠœë‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb56e5bb-0916-4e72-8d81-9535df7d3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. í•™ìŠµ ì‹œí‚¬ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import os, torch, json, wandb, subprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig, \n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e64500-cfdf-483b-a52b-381aaf53be73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afaa3cc28ef4ecdb2b5453f60f6eab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExaoneForCausalLM(\n",
      "  (transformer): ExaoneModel(\n",
      "    (wte): Embedding(102400, 4096, padding_idx=0)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-31): 32 x ExaoneBlock(\n",
      "        (ln_1): ExaoneRMSNorm()\n",
      "        (attn): ExaoneAttention(\n",
      "          (attention): ExaoneSdpaAttention(\n",
      "            (rotary): ExaoneRotaryEmbedding()\n",
      "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (ln_2): ExaoneRMSNorm()\n",
      "        (mlp): ExaoneGatedMLP(\n",
      "          (c_fc_0): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (c_fc_1): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (c_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): ExaoneRMSNorm()\n",
      "    (rotary): ExaoneRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "model_id = \"/home/vsc/LLM/model/EXAONE-3.5-7.8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04701875-bb81-4b6b-bd2b-cfc3ac0a21e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k_proj', 'v_proj', 'q_proj', 'c_proj', 'out_proj', 'c_fc_0', 'c_fc_1']\n"
     ]
    }
   ],
   "source": [
    "# LoRAë¥¼ ë¶™í ë ˆì´ì–´ì˜ ëª…ì¹­ì„ ì°¾ì•„ì£¼ëŠ” ì½”ë“œ\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    " \n",
    "modules = find_all_linear_names(model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10f2392b-20ec-41c8-a3b3-911af2a98076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=32, target_modules={'k_proj', 'out_proj', 'v_proj', 'q_proj'}, lora_alpha=16, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))\n"
     ]
    }
   ],
   "source": [
    "# ì–´ë–¤ ë¶€ë¶„ì„ í•™ìŠµí•˜ëƒì— ë”°ë¼ì„œë„ ê²°ê³¼ ê°’ì´ ë‹¬ë¼ì§\n",
    "modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"]\n",
    "\n",
    "# ë³€ê²½ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë“¤\n",
    "peft_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\", #CAUSAL_LM, FEATURE_EXTRACTION, QUESTION_ANS, SEQ_2_SEQ_LM, SEQ_CLS, TOKEN_CLS.\n",
    "    inference_mode=False, # í•™ìŠµ ì¤‘ì—ëŠ” Falseë¡œ ë‘ì–´ì•¼ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ ê°€ëŠ¥\n",
    "    r=32, # rì€ ë³´í†µ 2ì˜ ë°°ìˆ˜ë¡œ ë‘ëŠ”ë°, rì´ í´ìˆ˜ë¡ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ì˜ ìˆ˜ê°€ ë” ë§ì•„ì§\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=modules\n",
    ")\n",
    "\n",
    "print(peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b7b0db8-b096-457c-9698-820ab7993a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 27,262,976 || all params: 7,845,711,872 || trainable%: 0.3475\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "163129de-6900-4662-b6ac-9c97ba892895",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'faq'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3641\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3640\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:168\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:197\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7668\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7676\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'faq'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mfaq\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfaq\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m      2\u001b[39m hf_dataset = Dataset.from_pandas(df[[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m]])\n\u001b[32m      3\u001b[39m seed = \u001b[32m42\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/pandas/core/frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3648\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3644\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3645\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3646\u001b[39m     ):\n\u001b[32m   3647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3650\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3651\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3652\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3653\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'faq'"
     ]
    }
   ],
   "source": [
    "df['faq'] = df['faq'].astype(str)\n",
    "hf_dataset = Dataset.from_pandas(df[[\"question\", \"answer\",\"description\"]])\n",
    "seed = 42\n",
    "\n",
    "ds_split = hf_dataset.train_test_split(test_size=0.2, seed=seed)\n",
    "train_val_split = ds_split[\"train\"].train_test_split(test_size = 0.3, seed=seed)\n",
    "\n",
    "from datasets import DatasetDict\n",
    "\n",
    "final_dataset = DatasetDict({\n",
    "    'train': train_val_split['train'],\n",
    "    'val': train_val_split['test'],\n",
    "    'test': ds_split['test']\n",
    "})\n",
    "\n",
    "print(final_dataset)\n",
    "print(final_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84bb8b95-c232-47fc-88e3-53b5105e07b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'description'],\n",
      "    num_rows: 1085\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = final_dataset['train'], final_dataset['val'], final_dataset['test']\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdfdbff7-d52c-4e98-a455-4e49516a0a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompts(examples):\n",
    "    prompt_list = []\n",
    "    system_message = (\n",
    "        \"ë‹¹ì‹ ì€ ë„ì„œê´€ ìš´ì˜ì— ëŒ€í•œ ì „ë¬¸ì ì¸ ì§€ì‹ì„ ê°€ì§„ ì¸ê³µì§€ëŠ¥ ì‚¬ì„œì…ë‹ˆë‹¤.\"\n",
    "        \"ì œê³µëœ [ë„ì„œê´€ ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µí•˜ì‹­ì‹œì˜¤. \"\n",
    "        \"ì •ë³´ì— ì—†ëŠ” ë‚´ìš©ì€ í•¨ë¶€ë¡œ ì¶”ì¸¡í•˜ì§€ ë§ê³  ì •ì¤‘íˆ í™•ì¸ì´ ì–´ë µë‹¤ê³  ë‹µí•˜ì„¸ìš”.\"\n",
    "    )\n",
    "    \n",
    "    for i in range(len(examples['question'])):\n",
    "        question = examples[\"question\"][i]\n",
    "        answer = examples[\"answer\"][i]\n",
    "        context = examples[\"description\"][i]\n",
    "\n",
    "        user_content = (\n",
    "            f\"### [ë„ì„œê´€ ì •ë³´]\\n{context}\\n\\n\"\n",
    "            f\"### [ì§ˆë¬¸]\\n{question}\\n\\n\"\n",
    "            f\"### [ì§€ì‹œ ì‚¬í•­]\\n\"\n",
    "            f\"1. ì¹œì ˆí•œ ë§íˆ¬ë¡œ ê·œì •ì— ê·¼ê±°í•˜ì—¬ ë‹µë³€í•  ê²ƒ.\\n\"\n",
    "            f\"2. 3ë¬¸ë‹¨ ì´ë‚´ë¡œ ë‹µë³€í•  ê²ƒ.\\n\"\n",
    "            f\"3. ë‹µë³€ ëì— ì§€ì‹œ ì‚¬í•­ì„ ë°˜ë³µí•˜ì§€ ë§ ê²ƒ.\"\n",
    "        )\n",
    "\n",
    "        # ì±„íŒ… í…œí”Œë¦¿ êµ¬ì„±\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "\n",
    "        full_prompt = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        \n",
    "        prompt_list.append(full_prompt)\n",
    "    \n",
    "    return prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60b398c4-b235-48bb-bc0c-ef00a789f445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c002fd678a434118b6e03070b49953fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1085 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2337baa37c44db48ae5a3e1efff9db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœëŒ€ í† í° ê¸¸ì´: 770\n",
      "í‰ê·  í† í° ê¸¸ì´: 294.52\n",
      "95ë²ˆì§¸ ë°±ë¶„ìœ„ìˆ˜ (P95): 427.5\n",
      "99ë²ˆì§¸ ë°±ë¶„ìœ„ìˆ˜ (P99): 729.0\n"
     ]
    }
   ],
   "source": [
    "# max_length ê²°ì • (GPU Utilì„ ìµœì í™” í•˜ê¸° ìœ„í•¨)\n",
    "\n",
    "def generate_prompts_test(example) :\n",
    "    system_message = (\n",
    "        \"ë‹¹ì‹ ì€ ë„ì„œê´€ ìš´ì˜ì— ëŒ€í•œ ì „ë¬¸ì ì¸ ì§€ì‹ì„ ê°€ì§„ ì¸ê³µì§€ëŠ¥ ì‚¬ì„œì…ë‹ˆë‹¤.\"\n",
    "        \"ì œê³µëœ [ë„ì„œê´€ ì •ë³´]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µí•˜ì‹­ì‹œì˜¤. \"\n",
    "        \"ì •ë³´ì— ì—†ëŠ” ë‚´ìš©ì€ í•¨ë¶€ë¡œ ì¶”ì¸¡í•˜ì§€ ë§ê³  ì •ì¤‘íˆ í™•ì¸ì´ ì–´ë µë‹¤ê³  ë‹µí•˜ì„¸ìš”.\"\n",
    "    )\n",
    "    \n",
    "    question = example[\"question\"]\n",
    "    answer = example[\"answer\"]\n",
    "    context = example[\"description\"]\n",
    "\n",
    "    user_content = (\n",
    "            f\"### [ë„ì„œê´€ ì •ë³´]\\n{context}\\n\\n\"\n",
    "            f\"### [ì§ˆë¬¸]\\n{question}\\n\\n\"\n",
    "            f\"### [ì§€ì‹œ ì‚¬í•­]\\n\"\n",
    "            f\"1. ì¹œì ˆí•œ ë§íˆ¬ë¡œ ê·œì •ì— ê·¼ê±°í•˜ì—¬ ë‹µë³€í•  ê²ƒ.\\n\"\n",
    "            f\"2. 3ë¬¸ë‹¨ ì´ë‚´ë¡œ ë‹µë³€í•  ê²ƒ.\\n\"\n",
    "            f\"3. ë‹µë³€ ëì— ì§€ì‹œ ì‚¬í•­ì„ ë°˜ë³µí•˜ì§€ ë§ ê²ƒ.\"\n",
    "        )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "\n",
    "    full_prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    return {\"text\": full_prompt}\n",
    "\n",
    "train_prompts, val_prompts = train_dataset.map(generate_prompts_test), val_dataset.map(generate_prompts_test)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "token_lengths = [len(tokenizer.encode(p[\"text\"])) for p in train_prompts] + [len(tokenizer.encode(p[\"text\"])) for p in val_prompts]\n",
    "\n",
    "print(f\"ìµœëŒ€ í† í° ê¸¸ì´: {np.max(token_lengths)}\")\n",
    "print(f\"í‰ê·  í† í° ê¸¸ì´: {np.mean(token_lengths):.2f}\")\n",
    "print(f\"95ë²ˆì§¸ ë°±ë¶„ìœ„ìˆ˜ (P95): {np.percentile(token_lengths, 95)}\")\n",
    "print(f\"99ë²ˆì§¸ ë°±ë¶„ìœ„ìˆ˜ (P99): {np.percentile(token_lengths, 99)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42fa85e2-2960-4931-b04b-e3bee78a4a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/vsc/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjungseonglian\u001b[0m (\u001b[33muailab-unist_\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vsc/LLM_TUNE/ë„ì„œê´€_QA_Finetune/wandb/run-20260131_174830-library_QA_v1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/library_QA_v1' target=\"_blank\">2026-01-31 17:48:29</a></strong> to <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/library_QA_v1' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning/runs/library_QA_v1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/uailab-unist_/PromptTuning/runs/library_QA_v1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0xe7e4491b0ef0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í•™ìŠµì„ ê¸°ë¡í•  wanDB notebook ì„¤ì •\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"PromptTuning\" # í”„ë¡œì íŠ¸ ì´ë¦„\n",
    "os.environ[\"WANDB_RUN_ID\"] = \"library_QA_v1\" # ë…¸íŠ¸ë¶ ê³ ìœ  ID\n",
    "os.environ[\"WANDB_RESUME\"] = \"allow\" # í•´ë‹¹ ë…¸íŠ¸ë¶ì—ì„œ í•™ìŠµì„ ì´ì–´ì„œ ì§„í–‰í•  ê²ƒì¸ì§€\n",
    "\n",
    "wandb.init(\n",
    "    project=os.environ[\"WANDB_PROJECT\"],\n",
    "    id=os.environ[\"WANDB_RUN_ID\"],\n",
    "    resume=os.environ[\"WANDB_RESUME\"],\n",
    "    name=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") # ëŒ€ì‹œë³´ë“œì— í‘œì‹œë  ì´ë¦„\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8013b36-8e56-4e37-aba7-688fd5739591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8dbb99d5cf460ebff2cdf2a62f1218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1085 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98a84e46c6742c889f14c5a2428f503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ë¨¼ì € 1 epochë¡œ í›ˆë ¨ -> ì¶”ë¡ ì´ ì˜ ì´ë£¨ì–´ì§€ëŠ”ì§€ í™•ì¸\n",
    "# ì´í›„ epochë¥¼ ëŠ˜ë ¤ ê³¼ì í•©ì´ ì¼ì–´ë‚  ë•Œ ê¹Œì§€ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì¢‹ìŒ\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig, DataCollatorForCompletionOnlyLM # ì˜¤ì§ ë‹µë³€ ë¶€ë¶„ì— ëŒ€í•´ì„œë§Œ ì†ì‹¤ ê³„ì‚°\n",
    "from datetime import datetime\n",
    "\n",
    "response_template = \"[|assistant|]\" # EXAONE ê¸°ì¤€ response_template\n",
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template=response_template, \n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./SFT\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    max_seq_length=1024,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    load_best_model_at_end=True,\n",
    "    optim=\"paged_adamw_32bit\", # ì¼ë°˜ì ìœ¼ë¡œ adam ê³„ì—´ ì‚¬ìš©, paged_adamw_32bitëŠ” GPU ë©”ëª¨ë¦¬ ë¶€ë‹´ì„ ì¤„ì´ê¸° ìœ„í•´ CPU ë©”ëª¨ë¦¬ë¥´ í™•ì¥ ì‚¬ìš© ê¸°ë²•\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=11,\n",
    "    warmup_steps=10, # 0ë¶€í„° ëª©í‘œ lrê¹Œì§€ ì„ í˜•ì ìœ¼ë¡œ ëŠ˜ë¦¬ëŠ” steps ê¸°ê°„ ê²°ì • (í•™ìŠµ ì´ˆê¸°ì— í° lrì„ ì‚¬ìš©í•˜ë©´ ë°œì‚°í•  ìˆ˜ ìˆê¸° ë•Œë¬¸)\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=5e-5,\n",
    "    group_by_length=True, # ê¸¸ì´ê°€ ë¹„ìŠ·í•œ ìƒ˜í”Œì„ í•¨ê»˜ ë°°ì¹˜ í•¨ìœ¼ë¡œì¨ ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì í™”\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\"\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    formatting_func=generate_prompts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65bb648-7d64-401b-8025-1f815421b2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/34 : < :, Epoch 0.03/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "# PyTorch 2.6 ì´ìƒ ë²„ì „ì—ì„œ trainer.train(resume_from_checkpoint=True)ì„ í•˜ê³  ì‹¶ë‹¤ë©´ í•´ì£¼ì–´ì•¼ í•¨\n",
    "# torch.loadì˜ ê¸°ë³¸ê°’ì„ weights_only=Falseë¡œ ìˆ˜ì •\n",
    "torch.load = partial(torch.load, weights_only=False)\n",
    "\n",
    "final_save_path = \"./SFT/final\"\n",
    "os.makedirs(final_save_path, exist_ok=True)\n",
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=True) # ì´ì–´ì„œ í•™ìŠµì„ ì§„í–‰í•˜ê³  ì‹¶ì€ ê²½ìš°, ê°€ì¥ ë§ˆì§€ë§‰ checkpoint-XXë¥¼ ë¶ˆëŸ¬ì™€ì„œ í•™ìŠµì´ ì§„í–‰ëœë‹¤\n",
    "\n",
    "trainer.save_model(final_save_path)\n",
    "tokenizer.save_pretrained(final_save_path)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22e1e6-1a7f-476c-a72a-3cf3747bb656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vLLM",
   "language": "python",
   "name": ".venv_vllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
