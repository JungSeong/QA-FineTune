{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63df3b4",
   "metadata": {},
   "source": [
    "참고 : https://zero-ai.tistory.com/62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfc8bdf6-460a-4caa-8038-0056231c83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능 여부: True\n",
      "GPU 이름: NVIDIA GB10\n",
      "CUDA 버전: 13.0\n",
      "PyTorch 버전: <module 'torch.version' from '/home/vsc/LLM_TUNE/.venv_vLLM/lib/python3.12/site-packages/torch/version.py'>\n",
      "bf16 지원 여부: True\n",
      "현재 GPU : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsc/LLM_TUNE/.venv_vLLM/lib/python3.12/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA 사용 가능 여부: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "print(f\"PyTorch 버전: {torch.version}\")\n",
    "print(f\"bf16 지원 여부: {torch.cuda.is_bf16_supported()}\")\n",
    "print(f\"현재 GPU : {torch.cuda.current_device()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b03ed4-45a4-4772-850c-ea53128ebdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GPU Memory Status ---\n",
      "Allocated: 0.00 GB\n",
      "Reserved:  0.00 GB\n",
      "Total:     119.70 GB\n",
      "Free (in Reserved): 0.00 GB\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_vram_torch():\n",
    "    # 1. 현재 텐서들이 실제로 점유하고 있는 메모리\n",
    "    allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "    # 2. PyTorch가 OS로부터 할당받아 캐싱하고 있는 전체 메모리\n",
    "    reserved = torch.cuda.memory_reserved() / (1024**3)\n",
    "    # 3. 해당 GPU의 전체 용량\n",
    "    total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "\n",
    "    print(f\"--- GPU Memory Status ---\")\n",
    "    print(f\"Allocated: {allocated:.2f} GB\")\n",
    "    print(f\"Reserved:  {reserved:.2f} GB\")\n",
    "    print(f\"Total:     {total:.2f} GB\")\n",
    "    print(f\"Free (in Reserved): {reserved - allocated:.2f} GB\")\n",
    "    print(f\"--------------------------\")\n",
    "\n",
    "check_vram_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a7e77c-c1d1-4035-9c18-bb4e8226a148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['FAQ', 'TITLE', 'DES'],\n",
      "    num_rows: 110\n",
      "})\n",
      "{'FAQ': 1, 'TITLE': '회원증을 대리발급 할 수 있나요?', 'DES': '회원증 대리발급은 만14세 미만 아동, 만65세 이상 어르신, 장애인, 임산부만 가능하며 아래 구비서류를 지참하여 대리인이 방문 시 대리발급이 가능합니다.\\n\\n· 대상 : 만14세 미만 아동, 만65세 이상 어르신, 장애인, 임산부\\n· 구비서류\\n\\xa0 - 공통 : ①위임자 신분증, ②피위임자(대리인) 신분증\\n\\xa0 - 장애인 : 장애인 복지카드 또는 장애인 증명서\\n\\xa0 - 임신부 : 산모수첩 / 산모 : 주민등록등본(출산 후 12개월까지)\\n· 방법 : 홈페이지 회원가입 후 위 항목의 해당하는 구비서류를 지참하여 피위임자(대리인)이 도서관 방문'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "file_path = glob.glob(\"./data/*.xlsx\")\n",
    "df = pd.read_excel(file_path[0])\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0c5ff4-5b60-4a2e-9606-15e6b139993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강을 위해 로컬 EXAONE-3.5-7.8B-Instruct 모델 사용\n",
    "# Instruct 모델 : 명령 / 지시를 내리는 모델\n",
    "# 일반 LLM 모델 : 텍스트를 자연스럽게 이어가는 데 초점을 둔 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e4ba03d-f6f1-40f9-8c57-35f262834778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import os, torch, json, wandb, subprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5279e11-19b4-4210-8453-5baa012d5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"EMPTY\"\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"/home/vsc/LLM/model/Exaone-3.5-32B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f4fb5c-8564-45c3-b86a-ea513a0c31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vLLM의 경우 pipeline 방식에 비해 추론 속도가 빠르며, 메모리 안정성이 더 높음 + continuous batching으로 한 번에 여러 응답을 받을 수 있 음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f301929-fd87-4cee-a008-f5e6b6f9ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmented_data(faq_content):\n",
    "    system_message = (\n",
    "        \"당신은 도서관 FAQ 데이터를 바탕으로 자연스러운 대화형 학습 데이터를 생성하는 전문가입니다.\\n\"\n",
    "        \"제공된 정보를 분석하여 다음 4가지 유형의 데이터를 생성하세요. 각 유형별로 최소 3개씩, 총 12개의 예시를 만드세요.\\n\\n\"\n",
    "        \"이때 판단이 쉬운 예시와 보통, 어려운 예시 총 3가지 상황을 가정하세요.\"\n",
    "        \n",
    "        \"### [답변 가이드라인]\\n\"\n",
    "        \"1. **label: 'yes' (긍정 확인)**\\n\"\n",
    "        \"   - 질문이 '~할 수 있나요?', '~인가요?'처럼 '가부'를 물을 때만 사용하세요.\\n\"\n",
    "        \"   - 문구: '네, 가능합니다! 도서관 규정에 따르면...'\\n\"\n",
    "        \"   - 활용: 질문의 조건이 FAQ와 일치할 때 사용.\\n\"\n",
    "        \"2. **label: 'no' (부정/제한)**\\n\"\n",
    "        \"   - 질문이 '~할 수 있나요?', '~인가요?'처럼 '가부'를 물을 때만 사용하세요.\\n\"\n",
    "        \"   - 문구: '죄송하지만 어렵습니다. 그 이유는...'\\n\"\n",
    "        \"   - 활용: 질문의 조건이 FAQ 규정에 어긋날 때 사용. '사실과 다르다'는 표현 대신 '규정상 어렵다'를 사용하세요.\\n\"\n",
    "        \"3. **label: 'info' (단순 정보 제공)**\\n\"\n",
    "        \"   - 질문이 '~은 무엇인가요?', '~은 어떻게 하나요?', '~은 언제인가요?'처럼 절차/시간/방법을 물을 때 사용하세요.\\n\"\n",
    "        \"   - 문구: '문의하신 내용에 대해 안내해 드리겠습니다. 관련 서류는...'\\n\"\n",
    "        \"   - 활용: 네/아니오 판단이 아닌 정보 질문에 사용.\\n\"\n",
    "        \"4. **label: 'false' (판단 불가)**\\n\"\n",
    "        \"   - 문구: '죄송합니다. 현재 제공된 정보만으로는 해당 내용을 확인하기 어렵습니다.'\\n\"\n",
    "        \"   - 활용: FAQ에 없는 내용이거나 질문이 모호할 때 사용.\\n\\n\"\n",
    "        \n",
    "        \"모든 답변은 실제 도서관 사서가 방문객에게 설명하듯 친절하고 자연스러운 문장으로 작성하세요.\"\n",
    "        \"판단 불가의 경우 문구 외에 다른 문장은 생성하지 마세요.\"\n",
    "        \"JSON 답변 외에 다른 문장은 일체 생성하지 마세요.\"\n",
    "    )\n",
    "\n",
    "    # 사용자가 정의한 user_content\n",
    "    user_content = f\"\"\"\n",
    "    [도서관 FAQ 정보]\n",
    "    {faq_content}\n",
    "    \n",
    "    위 정보를 바탕으로 질문과 답변이 논리적으로 완벽하게 이어지는 JSON 데이터를 생성하세요.\n",
    "    \n",
    "    [출력 예시]:\n",
    "    [\n",
    "      {{\"question\": \"임산부인데 남편이 대신 발급받을 수 있나요?\", \"answer\": \"네, 가능합니다! 도서관 규정에 따르면 임산부의 경우 대리 발급 대상에 포함됩니다.\", \"label\": \"yes\"}},\n",
    "      {{\"question\": \"성인 직장인인데 친구가 대신 가도 되나요?\", \"answer\": \"죄송하지만, 해당 조건으로는 대리 발급이 어렵습니다. 대리 발급은 아동, 어르신, 장애인, 임산부로 대상이 제한되어 있기 때문입니다.\", \"label\": \"no\"}},\n",
    "      {{\"question\": \"장애인 대리 발급 시 어떤 서류가 필요한가요?\", \"answer\": \"문의하신 내용에 대해 안내해 드리겠습니다. 장애인 복지카드 또는 장애인 증명서를 지참하시면 됩니다.\", \"label\": \"info\"}},\n",
    "      {{\"question\": \"죄송합니다. 현재 제공된 정보만으로는 해당 내용을 확인하기 어렵습니다.\", \"label\": \"false\"}}\n",
    "    ]\n",
    "    \"\"\"\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "        ],\n",
    "        temperature=0.7,   # 창의성 조절 (0.0 ~ 2.0)\n",
    "        max_tokens=2048,   # 생성할 최대 토큰 수\n",
    "        top_p=0.9,         # 답변의 다양성 조절\n",
    "    )\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33de8dde-cbf3-4dbd-989c-650c254d993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_generated_json(response_text):\n",
    "    try:\n",
    "        # 1. 마크다운 코드 블록 제거 (```json ... ``` 사이의 내용만 추출)\n",
    "        json_pattern = re.compile(r\"```json\\s*(.*?)\\s*```\", re.DOTALL)\n",
    "        match = json_pattern.search(response_text)\n",
    "        \n",
    "        if match:\n",
    "            json_str = match.group(1)\n",
    "        else:\n",
    "            json_str = response_text.strip()\n",
    "            \n",
    "        # 2. JSON 문자열을 파이썬 리스트로 변환\n",
    "        data_list = json.loads(json_str)\n",
    "        return data_list\n",
    "    except Exception as e:\n",
    "        print(f\"파싱 에러 발생: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73de580c-58c9-4ee4-b1e7-ee6920124a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data Augmentation: 100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [02:15<00:00, 67.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 110개의 학습 데이터 생성 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "output_file = \"augmented_library_faq_quant_EXAONE_32B_vLLM.jsonl\"\n",
    "\n",
    "with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "    for i, row in enumerate(tqdm(dataset.select(range(108, len(dataset))), desc=\"Data Augmentation\")):\n",
    "        # 1. 모델로부터 텍스트 생성\n",
    "        raw_output = generate_augmented_data(row[\"DES\"])\n",
    "        \n",
    "        # 2. 파싱하여 리스트로 변환\n",
    "        parsed_list = parse_generated_json(raw_output)\n",
    "        \n",
    "        for item in parsed_list:\n",
    "            item['faq'] = row['FAQ'] \n",
    "            item['title'] = row['TITLE'] \n",
    "            item['DES'] = row['DES']\n",
    "            \n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "            \n",
    "print(f\"✅ 총 {len(df)}개의 학습 데이터 생성 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c3d6571-cf27-4977-ae65-4dbfcb38fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wanDB & weave + W&B artifact 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9daf6da-37d0-4dc6-a205-90b11759457e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">EXAONE-32B-vLLM-Run</strong> at: <a href='https://wandb.ai/uailab-unist_/library-faq-augmentation/runs/wv6qblnw' target=\"_blank\">https://wandb.ai/uailab-unist_/library-faq-augmentation/runs/wv6qblnw</a><br> View project at: <a href='https://wandb.ai/uailab-unist_/library-faq-augmentation' target=\"_blank\">https://wandb.ai/uailab-unist_/library-faq-augmentation</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260208_181018-wv6qblnw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vsc/LLM_TUNE/도서관_QA_Finetune/wandb/run-20260208_181543-lhd1mjkv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uailab-unist_/library-faq-augmentation/runs/lhd1mjkv' target=\"_blank\">EXAONE-32B-vLLM-Run</a></strong> to <a href='https://wandb.ai/uailab-unist_/library-faq-augmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uailab-unist_/library-faq-augmentation' target=\"_blank\">https://wandb.ai/uailab-unist_/library-faq-augmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uailab-unist_/library-faq-augmentation/runs/lhd1mjkv' target=\"_blank\">https://wandb.ai/uailab-unist_/library-faq-augmentation/runs/lhd1mjkv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Initializing weave.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da61f38c37248a1b952b53b7c439472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: jungseonglian.\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/uailab-unist_/library-faq-augmentation/weave\n",
      "[2026-02-08 18:15:49] INFO init_message.py:174: Logged in as Weights & Biases user: jungseonglian.\n",
      "View Weave data at https://wandb.ai/uailab-unist_/library-faq-augmentation/weave\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import asyncio, aiofiles\n",
    "import wandb\n",
    "from tqdm.asyncio import tqdm as async_tqdm\n",
    "from openai import AsyncOpenAI\n",
    "import weave\n",
    "\n",
    "PROJECT_NAME=\"library-faq-augmentation\"\n",
    "\n",
    "config = {\n",
    "    \"model\": \"Exaone-3.5-32B-Instruct\",\n",
    "    \"quantization\": \"bitsandbytes\",\n",
    "    \"engine\": \"vLLM-v1\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_model_len\": 16384,\n",
    "}\n",
    "\n",
    "wandb.init(project=PROJECT_NAME, name=\"EXAONE-32B-vLLM-Run\")\n",
    "weave.init(PROJECT_NAME)\n",
    "sample_table = wandb.Table(columns=[\"row_id\", \"question\", \"answer\", \"label\"])\n",
    "client = AsyncOpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"EMPTY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6a4d2b1-51d7-4f5e-9328-97d080fabc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "473a75b7-5601-42e3-8d9e-8ec4fe9d544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "async def generate_augmented_data_async(faq_content, row_id) :\n",
    "    system_message = (\n",
    "    \"당신은 도서관 FAQ 데이터를 바탕으로 자연스러운 대화형 학습 데이터를 생성하는 전문가입니다.\\n\"\n",
    "    \"제공된 정보를 분석하여 다음 4가지 유형의 데이터를 생성하세요. 각 유형별로 최소 3개씩, 총 12개의 예시를 만드세요.\\n\\n\"\n",
    "    \"이때 판단이 쉬운 예시와 보통, 어려운 예시 총 3가지 상황을 가정하세요.\"\n",
    "    \n",
    "    \"### [답변 가이드라인]\\n\"\n",
    "    \"1. **label: 'yes' (긍정 확인)**\\n\"\n",
    "    \"   - 질문이 '~할 수 있나요?', '~인가요?'처럼 '가부'를 물을 때만 사용하세요.\\n\"\n",
    "    \"   - 문구: '네, 가능합니다! 도서관 규정에 따르면...'\\n\"\n",
    "    \"   - 활용: 질문의 조건이 FAQ와 일치할 때 사용.\\n\"\n",
    "    \"2. **label: 'no' (부정/제한)**\\n\"\n",
    "    \"   - 질문이 '~할 수 있나요?', '~인가요?'처럼 '가부'를 물을 때만 사용하세요.\\n\"\n",
    "    \"   - 문구: '죄송하지만 어렵습니다. 그 이유는...'\\n\"\n",
    "    \"   - 활용: 질문의 조건이 FAQ 규정에 어긋날 때 사용. '사실과 다르다'는 표현 대신 '규정상 어렵다'를 사용하세요.\\n\"\n",
    "    \"3. **label: 'info' (단순 정보 제공)**\\n\"\n",
    "    \"   - 질문이 '~은 무엇인가요?', '~은 어떻게 하나요?', '~은 언제인가요?'처럼 절차/시간/방법을 물을 때 사용하세요.\\n\"\n",
    "    \"   - 문구: '문의하신 내용에 대해 안내해 드리겠습니다. 관련 서류는...'\\n\"\n",
    "    \"   - 활용: 네/아니오 판단이 아닌 정보 질문에 사용.\\n\"\n",
    "    \"4. **label: 'false' (판단 불가)**\\n\"\n",
    "    \"   - 문구: '죄송합니다. 현재 제공된 정보만으로는 해당 내용을 확인하기 어렵습니다.'\\n\"\n",
    "    \"   - 활용: FAQ에 없는 내용이거나 질문이 모호할 때 사용.\\n\\n\"\n",
    "    \n",
    "    \"모든 답변은 실제 도서관 사서가 방문객에게 설명하듯 친절하고 자연스러운 문장으로 작성하세요.\"\n",
    "    \"판단 불가의 경우 문구 외에 다른 문장은 생성하지 마세요.\"\n",
    "    \"JSON 답변 외에 다른 문장은 일체 생성하지 마세요.\"\n",
    "    )\n",
    "\n",
    "    # 사용자가 정의한 user_content\n",
    "    user_content = f\"\"\"\n",
    "        [도서관 FAQ 정보]\n",
    "        {faq_content}\n",
    "        \n",
    "        위 정보를 바탕으로 질문과 답변이 논리적으로 완벽하게 이어지는 JSON 데이터를 생성하세요.\n",
    "        \n",
    "        [출력 예시]:\n",
    "        [\n",
    "          {{\"question\": \"임산부인데 남편이 대신 발급받을 수 있나요?\", \"answer\": \"네, 가능합니다! 도서관 규정에 따르면 임산부의 경우 대리 발급 대상에 포함됩니다.\", \"label\": \"yes\"}},\n",
    "          {{\"question\": \"성인 직장인인데 친구가 대신 가도 되나요?\", \"answer\": \"죄송하지만, 해당 조건으로는 대리 발급이 어렵습니다. 대리 발급은 아동, 어르신, 장애인, 임산부로 대상이 제한되어 있기 때문입니다.\", \"label\": \"no\"}},\n",
    "          {{\"question\": \"장애인 대리 발급 시 어떤 서류가 필요한가요?\", \"answer\": \"문의하신 내용에 대해 안내해 드리겠습니다. 장애인 복지카드 또는 장애인 증명서를 지참하시면 됩니다.\", \"label\": \"info\"}},\n",
    "          {{\"question\": \"죄송합니다. 현재 제공된 정보만으로는 해당 내용을 확인하기 어렵습니다.\", \"label\": \"false\"}}\n",
    "        ]\n",
    "    \"\"\"\n",
    "    \n",
    "    try :\n",
    "        chat_completion = await client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_content},\n",
    "            ],\n",
    "            temperature=0.7,   # 창의성 조절 (0.0 ~ 2.0)\n",
    "            max_tokens=2048,   # 생성할 최대 토큰 수\n",
    "            top_p=0.9,         # 답변의 다양성 조절\n",
    "        )\n",
    "\n",
    "        raw_output = chat_completion.choices[0].message.content\n",
    "\n",
    "        if \"```json\" in raw_output:\n",
    "            raw_output = raw_output.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "        parsed_list = json.loads(raw_output)\n",
    "\n",
    "        if row_id < 5:\n",
    "            for item in parsed_list[:2]:\n",
    "                sample_table.add_data(row_id, item.get(\"question\"), item.get(\"answer\"), item.get(\"label\"))\n",
    "        \n",
    "        return parsed_list\n",
    "\n",
    "    except Exception as e :\n",
    "        print(f\"Error at {row_id} : {e}\")\n",
    "        return []\n",
    "    \n",
    "async def process_dataset(dataset) :\n",
    "    output_file = \"async_library_faq_quant_EXAONE_32B_vLLM_async.jsonl\"\n",
    "    async with aiofiles.open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        semaphore = asyncio.Semaphore(2)\n",
    "        lock = asyncio.Lock()\n",
    "\n",
    "        async def semaphore_task(row, idx) :\n",
    "            async with semaphore :\n",
    "                results = await generate_augmented_data_async(row[\"DES\"], idx)\n",
    "                \n",
    "                if results:  # 결과가 있을 때만 쓰기\n",
    "                    async with lock:\n",
    "                        for item in results:\n",
    "                            item.update({\n",
    "                                'faq': row['FAQ'], \n",
    "                                'title': row['TITLE'], \n",
    "                                'DES': row['DES']\n",
    "                            })\n",
    "                            await f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "                \n",
    "                return len(results)\n",
    "\n",
    "        tasks = [semaphore_task(row, i) for i, row in enumerate(dataset)]\n",
    "\n",
    "        total_created = 0\n",
    "        for coro in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"데이터 생성\"):\n",
    "            total_created += await coro\n",
    "\n",
    "    wandb.log({\"augmented_samples\": sample_table})\n",
    "    wandb.finish()\n",
    "    print(f\"✅ 생성 완료! 총 {total_created}개의 데이터가 저장되었습니다.\")\n",
    "\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e09f8c4-bd7a-4e77-9221-b945b2c4d7ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m outputfile_name = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mprocess_dataset\u001b[49m(dataset)\n\u001b[32m      2\u001b[39m artifact = wandb.Artifact(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutputfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_v0\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m artifact.add_file(output_filename)\n",
      "\u001b[31mNameError\u001b[39m: name 'process_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "outputfile_name = await process_dataset(dataset)\n",
    "artifact = wandb.Artifact(f\"{outputfile_name}_v0\", type='dataset')\n",
    "artifact.add_file(output_filename)\n",
    "wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5093550b-b22f-46fa-ac29-290b417922ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "\n",
    "data = []\n",
    "with open(\"augmented_library_faq.jsonl\", \"r\", encoding=\"utf-8\") as f :\n",
    "    for line in f :\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6ebcae-b100-4cbf-be03-31d84ea7d43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "info     593\n",
      "yes      533\n",
      "false    435\n",
      "no       388\n",
      "Name: count, dtype: int64\n",
      "-----\n",
      "question        2\n",
      "answer         16\n",
      "label           1\n",
      "faq             0\n",
      "title         678\n",
      "답변           1943\n",
      "augmented    1272\n",
      "dtype: int64\n",
      "-----\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1950 entries, 0 to 1949\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   question   1948 non-null   str   \n",
      " 1   answer     1934 non-null   str   \n",
      " 2   label      1949 non-null   str   \n",
      " 3   faq        1950 non-null   object\n",
      " 4   title      1272 non-null   str   \n",
      " 5   답변         7 non-null      str   \n",
      " 6   augmented  678 non-null    object\n",
      "dtypes: object(2), str(5)\n",
      "memory usage: 701.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 생성된 데이터 확인 (결측치 확인 및 데이터 보강을 위함)\n",
    "\n",
    "print(df[\"label\"].value_counts())\n",
    "print(\"-----\")\n",
    "print(df.isnull().sum())\n",
    "print(\"-----\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680d627a-6814-4fca-9188-52678aa673df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1950 entries, 0 to 1949\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   question   1948 non-null   str   \n",
      " 1   answer     1941 non-null   str   \n",
      " 2   label      1949 non-null   str   \n",
      " 3   faq        1950 non-null   object\n",
      " 4   title      1272 non-null   str   \n",
      " 5   augmented  678 non-null    object\n",
      "dtypes: object(2), str(4)\n",
      "memory usage: 686.1+ KB\n",
      "None\n",
      "question        2\n",
      "answer          9\n",
      "label           1\n",
      "faq             0\n",
      "title         678\n",
      "augmented    1272\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if \"답변\" in df.columns :\n",
    "    df[\"answer\"] = df[\"answer\"].fillna(df[\"답변\"])\n",
    "    df = df.drop(columns=[\"답변\"])\n",
    "\n",
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7225930c-9c3c-47ef-b7a0-2aca30774724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1939 entries, 0 to 1938\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   question   1939 non-null   str   \n",
      " 1   answer     1939 non-null   str   \n",
      " 2   label      1939 non-null   str   \n",
      " 3   faq        1939 non-null   object\n",
      " 4   title      1262 non-null   str   \n",
      " 5   augmented  677 non-null    object\n",
      "dtypes: object(2), str(4)\n",
      "memory usage: 683.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"question\", \"answer\", \"label\"])\n",
    "df = df.reset_index(drop=True) # drop된 행의 인덱스를 다시 매기기\n",
    "\n",
    "print(df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b6dfec-9a4a-45b6-878a-cad0b4418854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1. Label Distribution] ---\n",
      "label\n",
      "info     586\n",
      "yes      533\n",
      "false    433\n",
      "no       387\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "\n",
    "# 2. 라벨 분포 확인 (균형성)\n",
    "print(\"--- [1. Label Distribution] ---\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='label', order=['yes', 'no', 'info', 'false'])\n",
    "plt.title(\"Label Distribution\")\n",
    "plt.savefig(\"label_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d68c7ba-f8df-4143-9ec5-8098d8a5eaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label                                               false  info  no  yes\n",
      "title                                                                   \n",
      "E-BOOK 리더기(크레마)에서 YES24 서비스가 안되는 경우                     1     7   4    0\n",
      "가족회원이 무엇인가요?                                            2     3   3    4\n",
      "가좌도서관 위치 및 전화번호가 어떻게 되나요?                               2     5   0    5\n",
      "가좌도서관 이용시간이 어떻게 되나요?                                    1     3   3    3\n",
      "가좌도서관 휴관일은 언제인가요?                                       2     7   2    1\n",
      "...                                                   ...   ...  ..  ...\n",
      "화정어린이도서관 이용시간이 어떻게 되나요?                                 1     3   3    5\n",
      "화정어린이도서관 휴관일은 언제인가요?                                    1     6   2    3\n",
      "회원증은 도서관마다 각각 만들어야 하나요? 또, 회원증을 분실한 경우에는 어떻게 해야...      3     4   1    4\n",
      "회원증을 대리발급 할 수 있나요?                                      1     5   4    3\n",
      "희망도서 신청은 어떻게 하며, 도서구입은 얼마나 자주하나요?                       1     3   4    4\n",
      "\n",
      "[106 rows x 4 columns]\n",
      "106\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "pivot = df.groupby([\"title\", \"label\"]).size().unstack(fill_value=0)\n",
    "print(pivot)\n",
    "need_aug_idx = pivot[(pivot[\"yes\"]<=1) | (pivot[\"no\"]<=1) | (pivot[\"false\"] <=1)]\n",
    "\n",
    "print(len(pivot))\n",
    "print(len(need_aug_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf9ede0-43d8-48ac-9293-de241dd9db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_targeted_data(faq_content, target_labels):\n",
    "    # 필요한 라벨에 대한 가이드라인 / 예시만 프롬프트로 넣어서, 다른 예시가 생성되지 않도록 하기\n",
    "    all_guidelines = {\n",
    "        \"yes\" : \"질문이 '~할 수 있나요?', '~인가요?'처럼 '가부'를 물을 때만 사용하세요.\\n - 문구: '네, 가능합니다! 도서관 규정에 따르면...'\\n - 활용: 질문의 조건이 FAQ와 일치할 때 사용.\\n\",\n",
    "        \"no\" : \"질문이 '~할 수 있나요?', '~인가요?'처럼 '가부'를 물을 때만 사용하세요.\\n - 문구: '죄송하지만 어렵습니다. 그 이유는...'\\n - 활용: 질문의 조건이 FAQ 규정에 어긋날 때 사용. '사실과 다르다'는 표현 대신 '규정상 어렵다'를 사용하세요.\\n\",\n",
    "        \"info\" : \"질문이 '~은 무엇인가요?', '~은 어떻게 하나요?', '~은 언제인가요?'처럼 절차/시간/방법을 물을 때 사용하세요.\\n 문구: '문의하신 내용에 대해 안내해 드리겠습니다. 관련 서류는...'\\n - 활용: 네/아니오 판단이 아닌 정보 질문에 사용.\\n\",\n",
    "        \"false\" : \"문구: '죄송합니다. 현재 제공된 정보만으로는 해당 내용을 확인하기 어렵습니다.'\\n - 활용: FAQ에 없는 내용이거나 질문이 모호할 때 사용.\\n\\n\"\n",
    "    }\n",
    "    selected_guidelines = \"\\n\".join([all_guidelines[l] for l in target_labels if l in all_guidelines])\n",
    "\n",
    "    all_examples = {\n",
    "        \"yes\": '{\"question\": \"임산부인데 남편이 대신 발급받을 수 있나요?\", \"answer\": \"네, 가능합니다! 도서관 규정에 따르면 임산부의 경우 대리 발급 대상에 포함됩니다.\", \"label\": \"yes\"}',\n",
    "        \"no\": '{\"question\": \"성인 직장인인데 친구가 대신 가도 되나요?\", \"answer\": \"죄송하지만, 해당 조건으로는 대리 발급이 어렵습니다. 대리 발급은 아동, 어르신, 장애인, 임산부로 대상이 제한되어 있기 때문입니다.\", \"label\": \"no\"}',\n",
    "        \"info\": '{\"question\": \"장애인 대리 발급 시 어떤 서류가 필요한가요?\", \"answer\": \"문의하신 내용에 대해 안내해 드리겠습니다. 장애인 복지카드 또는 장애인 증명서를 지참하시면 됩니다.\", \"label\": \"info\"}',\n",
    "        \"false\": '{\"question\": \"도서관 근처에 맛있는 식당이 어디인가요?\", \"answer\": \"죄송합니다. 현재 제공된 정보만으로는 해당 내용을 확인하기 어렵습니다.\", \"label\": \"false\"}'\n",
    "    }   \n",
    "\n",
    "    target_str = \", \".join(target_labels)\n",
    "    selected_examples = \",\\n      \".join([all_examples[l] for l in target_labels if l in all_examples])\n",
    "    system_message = (\n",
    "        f\"당신은 도서관 FAQ 데이터를 바탕으로 부족한 유형의 학습 데이터를 보충하는 전문가입니다.\\n\"\n",
    "        f\"제공된 정보를 분석하여 반드시 다음 라벨에 해당하는 데이터만 생성하세요 : **[{target_str}]**\\n\\n\"\n",
    "        f\"이때 판단이 쉬운 예시와 보통, 어려운 예시 총 3가지 상황을 가정하세요.\"\n",
    "        f\"각 라벨마다 최소 2~3개의 답변을 생성하세요\"\n",
    "        \n",
    "        f\"### [답변 가이드라인]\\n{selected_guidelines}\\n\\n\"\n",
    "        \"모든 답변은 실제 도서관 사서가 방문객에게 설명하듯 친절하고 자연스러운 문장으로 작성하세요.\"\n",
    "        f\"**[{target_str}]**에 해당하지 않는 라벨은 절대로 생성하지 마세요\"\n",
    "        \"판단 불가의 경우 문구 외에 다른 문장은 생성하지 마세요.\"\n",
    "        \"JSON 답변 외에 다른 문장은 일체 생성하지 마세요.\"\n",
    "    )\n",
    "\n",
    "    # 사용자가 정의한 user_content\n",
    "    user_content = f\"\"\"\n",
    "    [도서관 FAQ 정보]\n",
    "    {faq_content}\n",
    "    \n",
    "    위 정보를 바탕으로 질문과 답변이 논리적으로 완벽하게 이어지는 JSON 데이터를 생성하세요.\n",
    "    \n",
    "    [출력 예시]:\n",
    "    {selected_examples}\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]\n",
    "\n",
    "    print(messages)\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    outputs = pipe(\n",
    "        prompt, \n",
    "        max_new_tokens=2048, \n",
    "        do_sample=True, \n",
    "        temperature=0.7,\n",
    "        truncation=True,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # 생성된 텍스트 추출 (결과값만 깔끔하게 가져오기 위해 prompt 이후 내용만 슬라이싱)\n",
    "    full_text = outputs[0][\"generated_text\"]\n",
    "    response = full_text.split(\"[|assistant|]\")[-1].strip()\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53259116-461e-4ff4-9c5e-c3c061d09998",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (868370360.py, line 31)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mitem[\"faq\"] =\u001b[39m\n                  ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 각 행마다 부족한 데이터 유형을 확인하여 데이터 증강\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_file = \"augmented_library_faq.jsonl\"\n",
    "target_titles = need_aug_idx.index.tolist()\n",
    "\n",
    "with open(output_file, \"a\", encoding=\"utf-8\") as f :\n",
    "    pbar = tqdm(target_titles, desc=\"타겟 라벨 보충\")\n",
    "    \n",
    "    for title in pbar :\n",
    "        current = pivot.loc[title]\n",
    "        missing_labels_list = [label for label in [\"yes\", \"no\", \"false\"] if current[label] <= 3]\n",
    "    \n",
    "        if not missing_labels_list :\n",
    "            continue\n",
    "    \n",
    "        missing_labels = \", \".join(missing_labels_list)\n",
    "        pbar.set_postfix(FAQ=title[:10] + \"..\", Labels=missing_labels)\n",
    "        \n",
    "        faq_data = [x for x in dataset if x[\"TITLE\"] == title][0]\n",
    "        faq_content = faq_data[\"DES\"]\n",
    "\n",
    "        try :\n",
    "            raw_output = generate_targeted_data(faq_content, missing_labels_list)\n",
    "            print(raw_output)\n",
    "            parsed_list = parse_generated_json(raw_output)\n",
    "\n",
    "            for item in parsed_list :\n",
    "                item[\"title\"] = title\n",
    "                item[\"faq\"] = \n",
    "                item[\"augmented\"] = True\n",
    "\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"\\n[에러 발생] {title}: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86303cf6-ca65-4baa-9dc6-dd0048fa33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "\n",
    "data = []\n",
    "with open(\"augmented_library_faq.jsonl\", \"r\", encoding=\"utf-8\") as f :\n",
    "    for line in f :\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5589dcb7-d46f-436c-bfc5-bb71c1540f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "info     593\n",
      "yes      533\n",
      "false    435\n",
      "no       388\n",
      "Name: count, dtype: int64\n",
      "-----\n",
      "question        2\n",
      "answer         16\n",
      "label           1\n",
      "faq             0\n",
      "title         678\n",
      "답변           1943\n",
      "augmented    1272\n",
      "dtype: int64\n",
      "-----\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1950 entries, 0 to 1949\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   question   1948 non-null   str   \n",
      " 1   answer     1934 non-null   str   \n",
      " 2   label      1949 non-null   str   \n",
      " 3   faq        1950 non-null   object\n",
      " 4   title      1272 non-null   str   \n",
      " 5   답변         7 non-null      str   \n",
      " 6   augmented  678 non-null    object\n",
      "dtypes: object(2), str(5)\n",
      "memory usage: 701.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 생성된 데이터 확인 (결측치 확인 및 데이터 보강을 위함)\n",
    "\n",
    "print(df[\"label\"].value_counts())\n",
    "print(\"-----\")\n",
    "print(df.isnull().sum())\n",
    "print(\"-----\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1b52193-acbd-4e75-842d-dd29a1b3ea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1950 entries, 0 to 1949\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   question   1948 non-null   str   \n",
      " 1   answer     1941 non-null   str   \n",
      " 2   label      1949 non-null   str   \n",
      " 3   faq        1950 non-null   object\n",
      " 4   title      1272 non-null   str   \n",
      " 5   augmented  678 non-null    object\n",
      "dtypes: object(2), str(4)\n",
      "memory usage: 686.1+ KB\n",
      "None\n",
      "question        2\n",
      "answer          9\n",
      "label           1\n",
      "faq             0\n",
      "title         678\n",
      "augmented    1272\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if \"답변\" in df.columns :\n",
    "    df[\"answer\"] = df[\"answer\"].fillna(df[\"답변\"])\n",
    "    df = df.drop(columns=[\"답변\"])\n",
    "\n",
    "print(df.info())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac23f65-c406-4db5-a905-4ce7ac6754c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1939 entries, 0 to 1938\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   question   1939 non-null   str   \n",
      " 1   answer     1939 non-null   str   \n",
      " 2   label      1939 non-null   str   \n",
      " 3   faq        1939 non-null   object\n",
      " 4   title      1262 non-null   str   \n",
      " 5   augmented  677 non-null    object\n",
      "dtypes: object(2), str(4)\n",
      "memory usage: 683.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"question\", \"answer\", \"label\"])\n",
    "df = df.reset_index(drop=True) # drop된 행의 인덱스를 다시 매기기\n",
    "\n",
    "print(df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df898bfc-368c-4e47-8729-0fcdacd99e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [1. Label Distribution] ---\n",
      "label\n",
      "info     586\n",
      "yes      533\n",
      "false    433\n",
      "no       387\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import json\n",
    "\n",
    "# 2. 라벨 분포 확인 (균형성)\n",
    "print(\"--- [1. Label Distribution] ---\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='label', order=['yes', 'no', 'info', 'false'])\n",
    "plt.title(\"Label Distribution\")\n",
    "plt.savefig(\"label_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b7d031d-e58f-41f1-9c20-12e54ad56e59",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'faq'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3641\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3640\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:168\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:197\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7668\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7676\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'faq'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# 만약 문자열이라면 (실수로 들어간 TITLE인 경우)\u001b[39;00m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m title_to_des.get(faq_val, \u001b[33m\"\u001b[39m\u001b[33m본문 없음\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfaq\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.apply(recovery_des) \u001b[38;5;66;03m# 데이터프레임에 함수 적용\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/pandas/core/frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3648\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3644\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3645\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3646\u001b[39m     ):\n\u001b[32m   3647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3650\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3651\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3652\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3653\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'faq'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "id_to_des = {x['FAQ']: x['DES'] for x in dataset}\n",
    "title_to_des = {x['TITLE']: x['DES'] for x in dataset}\n",
    "\n",
    "def recovery_des(faq_val):\n",
    "    # 만약 숫자라면 (원본 FAQ 번호인 경우)\n",
    "    if isinstance(faq_val, (int, float)) or (str(faq_val).isdigit()):\n",
    "        return id_to_des.get(int(faq_val), \"본문 없음\")\n",
    "    # 만약 문자열이라면 (실수로 들어간 TITLE인 경우)\n",
    "    else:\n",
    "        return title_to_des.get(faq_val, \"본문 없음\")\n",
    "\n",
    "df['description'] = df['faq'].apply(recovery_des) # 데이터프레임에 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "042b91a6-6301-4963-8da5-a99462b6b478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1939 entries, 0 to 1938\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   question     1939 non-null   str   \n",
      " 1   answer       1939 non-null   str   \n",
      " 2   label        1939 non-null   str   \n",
      " 3   faq          1939 non-null   object\n",
      " 4   title        1262 non-null   str   \n",
      " 5   augmented    677 non-null    object\n",
      " 6   description  1939 non-null   str   \n",
      "dtypes: object(2), str(5)\n",
      "memory usage: 1.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374cc64c-2e8a-43c6-b88c-da78d9e0eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 처리 및 데이터 증강 이후 파인튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb56e5bb-0916-4e72-8d81-9535df7d3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 학습 시킬 모델 불러오기\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import os, torch, json, wandb, subprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig, \n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e64500-cfdf-483b-a52b-381aaf53be73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afaa3cc28ef4ecdb2b5453f60f6eab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExaoneForCausalLM(\n",
      "  (transformer): ExaoneModel(\n",
      "    (wte): Embedding(102400, 4096, padding_idx=0)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-31): 32 x ExaoneBlock(\n",
      "        (ln_1): ExaoneRMSNorm()\n",
      "        (attn): ExaoneAttention(\n",
      "          (attention): ExaoneSdpaAttention(\n",
      "            (rotary): ExaoneRotaryEmbedding()\n",
      "            (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "            (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (ln_2): ExaoneRMSNorm()\n",
      "        (mlp): ExaoneGatedMLP(\n",
      "          (c_fc_0): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (c_fc_1): Linear(in_features=4096, out_features=14336, bias=False)\n",
      "          (c_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): ExaoneRMSNorm()\n",
      "    (rotary): ExaoneRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 및 토크나이저 불러오기\n",
    "\n",
    "model_id = \"/home/vsc/LLM/model/EXAONE-3.5-7.8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04701875-bb81-4b6b-bd2b-cfc3ac0a21e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k_proj', 'v_proj', 'q_proj', 'c_proj', 'out_proj', 'c_fc_0', 'c_fc_1']\n"
     ]
    }
   ],
   "source": [
    "# LoRA를 붙힐 레이어의 명칭을 찾아주는 코드\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    " \n",
    "modules = find_all_linear_names(model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10f2392b-20ec-41c8-a3b3-911af2a98076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=32, target_modules={'k_proj', 'out_proj', 'v_proj', 'q_proj'}, lora_alpha=16, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))\n"
     ]
    }
   ],
   "source": [
    "# 어떤 부분을 학습하냐에 따라서도 결과 값이 달라짐\n",
    "modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"]\n",
    "\n",
    "# 변경 가능한 파라미터들\n",
    "peft_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\", #CAUSAL_LM, FEATURE_EXTRACTION, QUESTION_ANS, SEQ_2_SEQ_LM, SEQ_CLS, TOKEN_CLS.\n",
    "    inference_mode=False, # 학습 중에는 False로 두어야 가중치 업데이트 가능\n",
    "    r=32, # r은 보통 2의 배수로 두는데, r이 클수록 학습 가능한 파라미터의 수가 더 많아짐\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=modules\n",
    ")\n",
    "\n",
    "print(peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b7b0db8-b096-457c-9698-820ab7993a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 27,262,976 || all params: 7,845,711,872 || trainable%: 0.3475\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "163129de-6900-4662-b6ac-9c97ba892895",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'faq'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3641\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3640\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:168\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:197\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7668\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7676\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'faq'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mfaq\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfaq\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m      2\u001b[39m hf_dataset = Dataset.from_pandas(df[[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m\"\u001b[39m]])\n\u001b[32m      3\u001b[39m seed = \u001b[32m42\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/pandas/core/frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3648\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3644\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3645\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3646\u001b[39m     ):\n\u001b[32m   3647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3650\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3651\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3652\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3653\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'faq'"
     ]
    }
   ],
   "source": [
    "df['faq'] = df['faq'].astype(str)\n",
    "hf_dataset = Dataset.from_pandas(df[[\"question\", \"answer\",\"description\"]])\n",
    "seed = 42\n",
    "\n",
    "ds_split = hf_dataset.train_test_split(test_size=0.2, seed=seed)\n",
    "train_val_split = ds_split[\"train\"].train_test_split(test_size = 0.3, seed=seed)\n",
    "\n",
    "from datasets import DatasetDict\n",
    "\n",
    "final_dataset = DatasetDict({\n",
    "    'train': train_val_split['train'],\n",
    "    'val': train_val_split['test'],\n",
    "    'test': ds_split['test']\n",
    "})\n",
    "\n",
    "print(final_dataset)\n",
    "print(final_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84bb8b95-c232-47fc-88e3-53b5105e07b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'description'],\n",
      "    num_rows: 1085\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = final_dataset['train'], final_dataset['val'], final_dataset['test']\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdfdbff7-d52c-4e98-a455-4e49516a0a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompts(examples):\n",
    "    prompt_list = []\n",
    "    system_message = (\n",
    "        \"당신은 도서관 운영에 대한 전문적인 지식을 가진 인공지능 사서입니다.\"\n",
    "        \"제공된 [도서관 정보]를 바탕으로 사용자의 질문에 정확하고 친절하게 답하십시오. \"\n",
    "        \"정보에 없는 내용은 함부로 추측하지 말고 정중히 확인이 어렵다고 답하세요.\"\n",
    "    )\n",
    "    \n",
    "    for i in range(len(examples['question'])):\n",
    "        question = examples[\"question\"][i]\n",
    "        answer = examples[\"answer\"][i]\n",
    "        context = examples[\"description\"][i]\n",
    "\n",
    "        user_content = (\n",
    "            f\"### [도서관 정보]\\n{context}\\n\\n\"\n",
    "            f\"### [질문]\\n{question}\\n\\n\"\n",
    "            f\"### [지시 사항]\\n\"\n",
    "            f\"1. 친절한 말투로 규정에 근거하여 답변할 것.\\n\"\n",
    "            f\"2. 3문단 이내로 답변할 것.\\n\"\n",
    "            f\"3. 답변 끝에 지시 사항을 반복하지 말 것.\"\n",
    "        )\n",
    "\n",
    "        # 채팅 템플릿 구성\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "\n",
    "        full_prompt = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        \n",
    "        prompt_list.append(full_prompt)\n",
    "    \n",
    "    return prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60b398c4-b235-48bb-bc0c-ef00a789f445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c002fd678a434118b6e03070b49953fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1085 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2337baa37c44db48ae5a3e1efff9db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 토큰 길이: 770\n",
      "평균 토큰 길이: 294.52\n",
      "95번째 백분위수 (P95): 427.5\n",
      "99번째 백분위수 (P99): 729.0\n"
     ]
    }
   ],
   "source": [
    "# max_length 결정 (GPU Util을 최적화 하기 위함)\n",
    "\n",
    "def generate_prompts_test(example) :\n",
    "    system_message = (\n",
    "        \"당신은 도서관 운영에 대한 전문적인 지식을 가진 인공지능 사서입니다.\"\n",
    "        \"제공된 [도서관 정보]를 바탕으로 사용자의 질문에 정확하고 친절하게 답하십시오. \"\n",
    "        \"정보에 없는 내용은 함부로 추측하지 말고 정중히 확인이 어렵다고 답하세요.\"\n",
    "    )\n",
    "    \n",
    "    question = example[\"question\"]\n",
    "    answer = example[\"answer\"]\n",
    "    context = example[\"description\"]\n",
    "\n",
    "    user_content = (\n",
    "            f\"### [도서관 정보]\\n{context}\\n\\n\"\n",
    "            f\"### [질문]\\n{question}\\n\\n\"\n",
    "            f\"### [지시 사항]\\n\"\n",
    "            f\"1. 친절한 말투로 규정에 근거하여 답변할 것.\\n\"\n",
    "            f\"2. 3문단 이내로 답변할 것.\\n\"\n",
    "            f\"3. 답변 끝에 지시 사항을 반복하지 말 것.\"\n",
    "        )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "\n",
    "    full_prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    return {\"text\": full_prompt}\n",
    "\n",
    "train_prompts, val_prompts = train_dataset.map(generate_prompts_test), val_dataset.map(generate_prompts_test)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "token_lengths = [len(tokenizer.encode(p[\"text\"])) for p in train_prompts] + [len(tokenizer.encode(p[\"text\"])) for p in val_prompts]\n",
    "\n",
    "print(f\"최대 토큰 길이: {np.max(token_lengths)}\")\n",
    "print(f\"평균 토큰 길이: {np.mean(token_lengths):.2f}\")\n",
    "print(f\"95번째 백분위수 (P95): {np.percentile(token_lengths, 95)}\")\n",
    "print(f\"99번째 백분위수 (P99): {np.percentile(token_lengths, 99)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42fa85e2-2960-4931-b04b-e3bee78a4a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/vsc/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjungseonglian\u001b[0m (\u001b[33muailab-unist_\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vsc/LLM_TUNE/도서관_QA_Finetune/wandb/run-20260131_174830-library_QA_v1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/library_QA_v1' target=\"_blank\">2026-01-31 17:48:29</a></strong> to <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/library_QA_v1' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning/runs/library_QA_v1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/uailab-unist_/PromptTuning/runs/library_QA_v1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0xe7e4491b0ef0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습을 기록할 wanDB notebook 설정\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"PromptTuning\" # 프로젝트 이름\n",
    "os.environ[\"WANDB_RUN_ID\"] = \"library_QA_v1\" # 노트북 고유 ID\n",
    "os.environ[\"WANDB_RESUME\"] = \"allow\" # 해당 노트북에서 학습을 이어서 진행할 것인지\n",
    "\n",
    "wandb.init(\n",
    "    project=os.environ[\"WANDB_PROJECT\"],\n",
    "    id=os.environ[\"WANDB_RUN_ID\"],\n",
    "    resume=os.environ[\"WANDB_RESUME\"],\n",
    "    name=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") # 대시보드에 표시될 이름\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8013b36-8e56-4e37-aba7-688fd5739591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8dbb99d5cf460ebff2cdf2a62f1218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1085 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98a84e46c6742c889f14c5a2428f503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 먼저 1 epoch로 훈련 -> 추론이 잘 이루어지는지 확인\n",
    "# 이후 epoch를 늘려 과적합이 일어날 때 까지 학습하는 것이 좋음\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig, DataCollatorForCompletionOnlyLM # 오직 답변 부분에 대해서만 손실 계산\n",
    "from datetime import datetime\n",
    "\n",
    "response_template = \"[|assistant|]\" # EXAONE 기준 response_template\n",
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template=response_template, \n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./SFT\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    max_seq_length=1024,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    load_best_model_at_end=True,\n",
    "    optim=\"paged_adamw_32bit\", # 일반적으로 adam 계열 사용, paged_adamw_32bit는 GPU 메모리 부담을 줄이기 위해 CPU 메모리르 확장 사용 기법\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=11,\n",
    "    warmup_steps=10, # 0부터 목표 lr까지 선형적으로 늘리는 steps 기간 결정 (학습 초기에 큰 lr을 사용하면 발산할 수 있기 때문)\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=5e-5,\n",
    "    group_by_length=True, # 길이가 비슷한 샘플을 함께 배치 함으로써 메모리 사용 최적화\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\"\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    formatting_func=generate_prompts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65bb648-7d64-401b-8025-1f815421b2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/34 : < :, Epoch 0.03/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "# PyTorch 2.6 이상 버전에서 trainer.train(resume_from_checkpoint=True)을 하고 싶다면 해주어야 함\n",
    "# torch.load의 기본값을 weights_only=False로 수정\n",
    "torch.load = partial(torch.load, weights_only=False)\n",
    "\n",
    "final_save_path = \"./SFT/final\"\n",
    "os.makedirs(final_save_path, exist_ok=True)\n",
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=True) # 이어서 학습을 진행하고 싶은 경우, 가장 마지막 checkpoint-XX를 불러와서 학습이 진행된다\n",
    "\n",
    "trainer.save_model(final_save_path)\n",
    "tokenizer.save_pretrained(final_save_path)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22e1e6-1a7f-476c-a72a-3cf3747bb656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vLLM",
   "language": "python",
   "name": ".venv_vllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
