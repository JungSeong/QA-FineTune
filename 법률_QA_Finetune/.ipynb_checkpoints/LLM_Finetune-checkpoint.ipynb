{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63df3b4",
   "metadata": {},
   "source": [
    "참고 : https://zero-ai.tistory.com/62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eceafe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능 여부: True\n",
      "GPU 이름: NVIDIA GB10\n",
      "CUDA 버전: 13.0\n",
      "PyTorch 버전: <module 'torch.version' from '/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/version.py'>\n",
      "bf16 지원 여부: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  queued_call()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA 사용 가능 여부: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "print(f\"PyTorch 버전: {torch.version}\")\n",
    "print(f\"bf16 지원 여부: {torch.cuda.is_bf16_supported()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6440e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O : 성공 : TL_10.개인정보.ICT.zip\n",
      "O : 성공 : TL_05.행정.zip\n",
      "X : 실패 (파일 깨짐): TL_01.민사.zip (크기: 18409624 bytes)\n",
      "O : 성공 : TL_06.기업.zip\n",
      "O : 성공 : TL_02.가사.zip\n",
      "O : 성공 : TL_04.형사B(일반형).zip\n",
      "O : 성공 : TL_08.특허.저작권.zip\n",
      "O : 성공 : TL_07.근로자.zip\n",
      "O : 성공 : TL_09.금융조세.zip\n",
      "O : 성공 : TL_03.형사A(생활형).zip\n",
      "O : 성공 : VL_02.가사.zip\n",
      "O : 성공 : VL_10.개인정보.ICT.zip\n",
      "O : 성공 : VL_07.근로자.zip\n",
      "O : 성공 : VL_09.금융조세.zip\n",
      "O : 성공 : VL_05.행정.zip\n",
      "O : 성공 : VL_08.특허.저작권.zip\n",
      "O : 성공 : VL_03.형사A(생활형).zip\n",
      "O : 성공 : VL_01.민사.zip\n",
      "O : 성공 : VL_04.형사B(일반형).zip\n",
      "O : 성공 : VL_06.기업.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "target_dir_list = [\"./3.개방데이터/1.데이터/Training/02.라벨링데이터\", \"./3.개방데이터/1.데이터/Validation/02.라벨링데이터\"]\n",
    "extract_dir_list = [\"./3.개방데이터/1.데이터/extract/Training/02.라벨링데이터\", \"./3.개방데이터/1.데이터/extract/Validation/02.라벨링데이터\", \"./3.개방데이터/1.데이터/raw/Training/0.1.원천데이터\"]\n",
    "\n",
    "if not os.path.exists(extract_dir_list[0]):\n",
    "    os.makedirs(extract_dir_list[0])\n",
    "if not os.path.exists(extract_dir_list[1]):\n",
    "    os.makedirs(extract_dir_list[1])\n",
    "\n",
    "for target_dir, extract_dir in zip(target_dir_list, extract_dir_list):\n",
    "    for file in os.listdir(target_dir):\n",
    "        if file.endswith(\".zip\"):\n",
    "            file_path = os.path.join(target_dir, file)\n",
    "\n",
    "            try :\n",
    "                with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "                    zip_ref.extractall(extract_dir)\n",
    "                    print(f\"O : 성공 : {file}\")\n",
    "            except zipfile.BadZipFile :\n",
    "                file_size = os.path.getsize(file_path)\n",
    "                print(f\"X : 실패 (파일 깨짐): {file} (크기: {file_size} bytes)\")\n",
    "        \n",
    "            except Exception as e:\n",
    "                print(f\"기타 에러 ({file}): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7b9f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O : 성공 : 01.원천데이터\\TS_1.판례_10.개인정보.ICT.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_10.개인정보.ICT.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_06.기업.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_05.행정.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_05.행정.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_09.금융조세.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_04.형사B(일반형).zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_02.가사.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_07.근로자.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_08.특허.저작권.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_09.금융조세.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_07.근로자.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_08.특허.저작권.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_03.형사A(생활형).zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_01.민사.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_06.기업.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_04.형사B(일반형).zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_01.민사.zip\n"
     ]
    }
   ],
   "source": [
    "raw_dir_list = [\"./3.개방데이터/1.데이터/Training/01.원천데이터\"]\n",
    "\n",
    "if not os.path.exists(raw_dir_list[0]):\n",
    "    os.makedirs(raw_dir_list[0])\n",
    "\n",
    "for file in os.listdir(raw_dir_list[0]):\n",
    "    if file.endswith(\".zip\"):\n",
    "        file_path = os.path.join(raw_dir_list[0], file)\n",
    "\n",
    "        try :\n",
    "            with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(extract_dir_list[2])\n",
    "                print(f\"O : 성공 : {file}\")\n",
    "        except zipfile.BadZipFile :\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"X : 실패 (파일 깨짐): {file} (크기: {file_size} bytes)\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"기타 에러 ({file}): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f912885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 셋 전처리\n",
    "\n",
    "import json, os\n",
    "from datasets import Dataset\n",
    "\n",
    "def load_json_files(dir) :\n",
    "    loaded_data = []\n",
    "    for filename in os.listdir(dir) :\n",
    "        if filename.endswith('.json') :\n",
    "            with open(os.path.join(dir, filename), 'r', encoding='utf-8') as f :\n",
    "                loaded_data.append(json.load(f))\n",
    "    \n",
    "    return loaded_data\n",
    "\n",
    "def create_dataset(data) :\n",
    "    dataset_dict = {\n",
    "        \"id\": [],\n",
    "        \"question\": [],\n",
    "        \"context\": [],\n",
    "        \"summary\": [],\n",
    "        \"answer\" : [],\n",
    "    }\n",
    "\n",
    "    for item in data:\n",
    "        dataset_dict[\"id\"].append(item[\"info\"][\"id\"])\n",
    "        dataset_dict[\"question\"].append(item[\"jdgmnInfo\"][0][\"question\"])\n",
    "        dataset_dict[\"context\"].append(item[\"Summary\"][0][\"summ_contxt\"])\n",
    "        dataset_dict[\"summary\"].append(item[\"Summary\"][0][\"summ_pass\"])\n",
    "        dataset_dict[\"answer\"].append(item[\"jdgmnInfo\"][0][\"answer\"])\n",
    "\n",
    "    return Dataset.from_dict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9ff410",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dir_list = [\"./3.개방데이터/1.데이터/extract/Training/02.라벨링데이터\", \"./3.개방데이터/1.데이터/extract/Validation/02.라벨링데이터\", \"./3.개방데이터/1.데이터/raw/Training/0.1.원천데이터\"]\n",
    "train_data, val_data = load_json_files(extract_dir_list[0]), load_json_files(extract_dir_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498262bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 || 400 || 200\n"
     ]
    }
   ],
   "source": [
    "# 처음에는 일부 데이터 셋으로 테스트\n",
    "train_dataset = create_dataset(train_data)\n",
    "val_dataset = create_dataset(val_data)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "train_subset = train_dataset.shuffle(seed=seed).select(range(1000))\n",
    "val_subset = val_dataset.shuffle(seed=seed).select(range(400))\n",
    "test_subset = val_dataset.shuffle(seed=seed).select(range(401, 601))\n",
    "\n",
    "print(f\"{len(train_subset)} || {len(val_subset)} || {len(test_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074a3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 학습 시킬 모델 불러오기\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import os, torch, json, wandb, subprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig, \n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b232b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양자화 설정\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 4bit 할 것이냐\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, #bfloat16 or float16\n",
    "    bnb_4bit_quant_type=\"nf4\", # nf4 or fp4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a33ff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  queued_call()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a38ef4b34d481895a11f7643fd93a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExaoneForCausalLM(\n",
      "  (transformer): ExaoneModel(\n",
      "    (wte): Embedding(102400, 4096, padding_idx=0)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-31): 32 x ExaoneBlock(\n",
      "        (ln_1): ExaoneRMSNorm()\n",
      "        (attn): ExaoneAttention(\n",
      "          (attention): ExaoneSdpaAttention(\n",
      "            (rotary): ExaoneRotaryEmbedding()\n",
      "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "            (out_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (ln_2): ExaoneRMSNorm()\n",
      "        (mlp): ExaoneGatedMLP(\n",
      "          (c_fc_0): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (c_fc_1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (c_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): ExaoneRMSNorm()\n",
      "    (rotary): ExaoneRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 및 토크나이저 불러오기\n",
    "\n",
    "model_id = \"/home/vsc/LLM/model/EXAONE-3.5-7.8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de923173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q_proj', 'c_fc_1', 'c_proj', 'out_proj', 'v_proj', 'c_fc_0', 'k_proj']\n"
     ]
    }
   ],
   "source": [
    "# LoRA를 붙힐 레이어의 명칭을 찾아주는 코드\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    " \n",
    "modules = find_all_linear_names(model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dabce7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules={'q_proj', 'out_proj', 'k_proj', 'v_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))\n"
     ]
    }
   ],
   "source": [
    "# 어떤 부분을 학습하냐에 따라서도 결과 값이 달라짐\n",
    "modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"]\n",
    "\n",
    "# 변경 가능한 파라미터들\n",
    "peft_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\", #CAUSAL_LM, FEATURE_EXTRACTION, QUESTION_ANS, SEQ_2_SEQ_LM, SEQ_CLS, TOKEN_CLS.\n",
    "    inference_mode=False, # 학습 중에는 False로 두어야 가중치 업데이트 가능\n",
    "    r=16, # r은 보통 2의 배수로 두는데, r이 클수록 학습 가능한 파라미터의 수가 더 많아짐\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=modules\n",
    ")\n",
    "\n",
    "print(peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce8e3fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13,631,488 || all params: 7,832,080,384 || trainable%: 0.1740\n"
     ]
    }
   ],
   "source": [
    "# 전체 파라미터 중 일부만 업데이트 되는 것을 확인할 수 있음\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6942527f-b97e-4571-9fef-8fec269ad9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 프롬프트의 경우 상황 (context)까지 학습시켰기에, RAG로의 확장성도 있음\n",
    "\n",
    "def generate_prompts(examples):\n",
    "    prompt_list = []\n",
    "    system_message = \"당신은 법률 및 규정 관련 전문가입니다. 사용자의 질문에 대해 '긍정'및 '부정', '불명' 여부를 판단한 후, 그에 대한 구체적인 근거를 문맥(context)에서 추출해서 설명하세요.\"\n",
    "\n",
    "    for i in range(len(examples['question'])):\n",
    "        # 각 리스트에서 i번째 데이터를 추출합니다.\n",
    "        answer = str(examples[\"answer\"][i]).strip()\n",
    "        question = examples[\"question\"][i]\n",
    "        context = examples[\"context\"][i]\n",
    "        summary = examples[\"summary\"][i]\n",
    "\n",
    "        # 사용자님의 정답 생성 로직\n",
    "        if answer == \"긍정\":\n",
    "            target_answer = f\"네 그렇습니다! {summary}에 의하여 질문하신 내용은 옳습니다.\"\n",
    "        elif answer == \"부정\":\n",
    "            target_answer = f\"아니요, 그렇지 않습니다! {summary}에 의하면 상충되는 내용이 있으므로 질문하신 내용은 옳지 않습니다.\"\n",
    "        elif answer == \"불명\":\n",
    "            target_answer = f\"확실하지 않습니다만, {summary}에 적힌 내용을 근거로 판단해 볼 수 있을 것 같습니다.\"\n",
    "        else:\n",
    "            target_answer = f\"해당 사안에 대해서는 제공된 근거({summary})를 바탕으로 판단이 필요합니다.\"\n",
    "\n",
    "        # 채팅 템플릿 구성\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": f\"사용자의 질문인 {question}에 대해 {context}를 참조하여 3문단 이내로 답변하세요.\"},\n",
    "            {\"role\": \"assistant\", \"content\": target_answer}\n",
    "        ]\n",
    "\n",
    "        full_prompt = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        \n",
    "        prompt_list.append(full_prompt)\n",
    "    \n",
    "    return prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ce8f6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded7f8c6250e4e5f9d8c1e37eac6e507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfbb78cd5b74c598085ecf2ad7332e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 토큰 길이: 1232\n",
      "평균 토큰 길이: 523.87\n",
      "95번째 백분위수 (P95): 823.0\n",
      "99번째 백분위수 (P99): 975.02\n"
     ]
    }
   ],
   "source": [
    "# max_length 결정|\n",
    "\n",
    "def generate_prompts_test(example) :\n",
    "    prompt_list = []\n",
    "    system_message = \"당신은 법률 및 규정 관련 전문가입니다. 사용자의 질문에 대해 '긍정' 및 '부정', 혹은 '불명' 여부를 판단한 후, 그에 대한 구체적인 근거를 문맥(context)에서 추출해서 설명하세요.\"\n",
    "\n",
    "    answer = str(example[\"answer\"]).strip()\n",
    "    question = example[\"question\"]\n",
    "    context = example[\"context\"]\n",
    "    summary = example[\"summary\"]\n",
    "\n",
    "    if answer == \"긍정\" :\n",
    "        target_answer = f\"네 그렇습니다! {summary}에 의하여 질문하신 내용은 옳습니다.\"\n",
    "    elif answer == \"부정\" :\n",
    "        target_answer = f\"아니요, 그렇지 않습니다! {summary}에 의하면 상충되는 내용이 있으므로 질문하신 내용은 옳지 않습니다.\"\n",
    "    elif answer == \"불명\" :\n",
    "        target_answer = f\"확실하지 않습니다만, {summary}에 적힌 내용을 근거로 판단해 볼 수 있을 것 같습니다.\"\n",
    "    else :\n",
    "        target_answer = f\"해당 사안에 대해서는 제공된 근거({summary})를 바탕으로 판단이 필요합니다.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": f\"사용자의 질문인 {question}에 대해 {context}를 참조하여 3문단 이내로 답변하세요.\"},\n",
    "        {\"role\": \"assistant\", \"content\": target_answer}\n",
    "    ]\n",
    "\n",
    "    full_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    \n",
    "    return {\"text\": full_prompt}\n",
    "\n",
    "train_prompts, val_prompts = train_subset.map(generate_prompts_test), val_subset.map(generate_prompts_test)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "token_lengths = [len(tokenizer.encode(p[\"text\"])) for p in train_prompts] + [len(tokenizer.encode(p[\"text\"])) for p in val_prompts]\n",
    "\n",
    "print(f\"최대 토큰 길이: {np.max(token_lengths)}\")\n",
    "print(f\"평균 토큰 길이: {np.mean(token_lengths):.2f}\")\n",
    "print(f\"95번째 백분위수 (P95): {np.percentile(token_lengths, 95)}\") # 95번째로 큰 데이터의 토큰 수\n",
    "print(f\"99번째 백분위수 (P99): {np.percentile(token_lengths, 99)}\") # 99번째로 큰 데이터의 토큰 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14e0cf8d-41c3-4d2b-a1f0-3df1374bc7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/vsc/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vsc/LLM_TUNE/115.법률-규정 텍스트 분석 데이터_고도화_상황에 따른 판례 데이터/wandb/run-20260129_141210-legal_testv4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4' target=\"_blank\">2026-01-29 14:12:04</a></strong> to <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0xe13002aad610>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습을 기록할 wanDB notebook 설정\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"PromptTuning\" # 프로젝트 이름\n",
    "os.environ[\"WANDB_RUN_ID\"] = \"legal_testv4\" # 노트북 고유 ID\n",
    "os.environ[\"WANDB_RESUME\"] = \"allow\" # 해당 노트북에서 학습을 이어서 진행할 것인지\n",
    "\n",
    "wandb.init(\n",
    "    project=os.environ[\"WANDB_PROJECT\"],\n",
    "    id=os.environ[\"WANDB_RUN_ID\"],\n",
    "    resume=os.environ[\"WANDB_RESUME\"],\n",
    "    name=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") # 대시보드에 표시될 이름\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14760be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7954f46a36924df38831227cb4ed00dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Error occurred while packing the dataset. Make sure that your dataset has enough samples to at least yield one packed sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/builder.py:1576\u001b[39m, in \u001b[36mGeneratorBasedBuilder._prepare_split_single\u001b[39m\u001b[34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, job_id)\u001b[39m\n\u001b[32m   1575\u001b[39m _time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1576\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1577\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# old custom builders may not use Key\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/packaged_modules/generator/generator.py:37\u001b[39m, in \u001b[36mGenerator._generate_examples\u001b[39m\u001b[34m(self, **gen_kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m shard_idx, shard_gen_kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(_split_gen_kwargs(gen_kwargs, max_num_jobs=num_shards)):\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mshard_gen_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:626\u001b[39m, in \u001b[36mSFTTrainer._prepare_packed_dataloader.<locals>.data_generator\u001b[39m\u001b[34m(constant_length_iterator)\u001b[39m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdata_generator\u001b[39m(constant_length_iterator):\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m constant_length_iterator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/utils.py:633\u001b[39m, in \u001b[36mConstantLengthDataset.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     buffer.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    634\u001b[39m     buffer_len += \u001b[38;5;28mlen\u001b[39m(buffer[-\u001b[32m1\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mgenerate_prompts\u001b[39m\u001b[34m(examples)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(examples[\u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m])):\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# 각 리스트에서 i번째 데이터를 추출합니다.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     answer = \u001b[38;5;28mstr\u001b[39m(\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m).strip()\n\u001b[32m     10\u001b[39m     question = examples[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m][i]\n",
      "\u001b[31mIndexError\u001b[39m: string index out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatasetGenerationError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:629\u001b[39m, in \u001b[36mSFTTrainer._prepare_packed_dataloader\u001b[39m\u001b[34m(self, tokenizer, dataset, dataset_text_field, max_seq_length, num_of_sequences, chars_per_token, formatting_func, append_concat_token, add_special_tokens)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     packed_dataset = \u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconstant_length_iterator\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_length_iterator\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (DatasetGenerationError, SchemaInferenceError) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/arrow_dataset.py:1204\u001b[39m, in \u001b[36mDataset.from_generator\u001b[39m\u001b[34m(generator, features, cache_dir, keep_in_memory, gen_kwargs, num_proc, split, fingerprint, **kwargs)\u001b[39m\n\u001b[32m   1192\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeneratorDatasetInputStream\n\u001b[32m   1194\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGeneratorDatasetInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1204\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/io/generator.py:52\u001b[39m, in \u001b[36mGeneratorDatasetInputStream.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m base_path = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m dataset = \u001b[38;5;28mself\u001b[39m.builder.as_dataset(\n\u001b[32m     60\u001b[39m     split=\u001b[38;5;28mself\u001b[39m.builder.config.split, verification_mode=verification_mode, in_memory=\u001b[38;5;28mself\u001b[39m.keep_in_memory\n\u001b[32m     61\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/builder.py:884\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare\u001b[39m\u001b[34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[39m\n\u001b[32m    883\u001b[39m     prepare_split_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_proc\u001b[39m\u001b[33m\"\u001b[39m] = num_proc\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/builder.py:1634\u001b[39m, in \u001b[36mGeneratorBasedBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[39m\n\u001b[32m   1633\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, **prepare_splits_kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1637\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_splits_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1638\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/builder.py:947\u001b[39m, in \u001b[36mDatasetBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[39m\n\u001b[32m    945\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    946\u001b[39m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/builder.py:1438\u001b[39m, in \u001b[36mGeneratorBasedBuilder._prepare_split\u001b[39m\u001b[34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[39m\n\u001b[32m   1437\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[32m-> \u001b[39m\u001b[32m1438\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_split_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_prepare_split_args\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1441\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/builder.py:1617\u001b[39m, in \u001b[36mGeneratorBasedBuilder._prepare_split_single\u001b[39m\u001b[34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, job_id)\u001b[39m\n\u001b[32m   1616\u001b[39m         e = e.__context__\n\u001b[32m-> \u001b[39m\u001b[32m1617\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationError(\u001b[33m\"\u001b[39m\u001b[33mAn error occurred while generating the dataset\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m (\n\u001b[32m   1620\u001b[39m     job_id,\n\u001b[32m   1621\u001b[39m     \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1630\u001b[39m     ),\n\u001b[32m   1631\u001b[39m )\n",
      "\u001b[31mDatasetGenerationError\u001b[39m: An error occurred while generating the dataset",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m      7\u001b[39m training_args = SFTConfig(\n\u001b[32m      8\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./SFT\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     save_strategy=\u001b[33m\"\u001b[39m\u001b[33msteps\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     run_name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.now().strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m trainer = \u001b[43mSFTTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerate_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[39m, in \u001b[36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m         message += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + custom_message\n\u001b[32m    100\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:361\u001b[39m, in \u001b[36mSFTTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics, peft_config, dataset_text_field, packing, formatting_func, max_seq_length, infinite, num_of_sequences, chars_per_token, dataset_num_proc, dataset_batch_size, neftune_noise_alpha, model_init_kwargs, dataset_kwargs, eval_packing)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m PartialState().local_main_process_first():\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m train_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m         train_dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpacking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_text_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m            \u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_of_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchars_per_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m            \u001b[49m\u001b[43mremove_unused_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove_unused_columns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m eval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    374\u001b[39m         _multiple = \u001b[38;5;28misinstance\u001b[39m(eval_dataset, \u001b[38;5;28mdict\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:525\u001b[39m, in \u001b[36mSFTTrainer._prepare_dataset\u001b[39m\u001b[34m(self, dataset, tokenizer, packing, dataset_text_field, max_seq_length, formatting_func, num_of_sequences, chars_per_token, remove_unused_columns, append_concat_token, add_special_tokens, skip_prepare_dataset)\u001b[39m\n\u001b[32m    514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prepare_non_packed_dataloader(\n\u001b[32m    515\u001b[39m         tokenizer,\n\u001b[32m    516\u001b[39m         dataset,\n\u001b[32m   (...)\u001b[39m\u001b[32m    521\u001b[39m         remove_unused_columns,\n\u001b[32m    522\u001b[39m     )\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_packed_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_text_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_of_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchars_per_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mappend_concat_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:633\u001b[39m, in \u001b[36mSFTTrainer._prepare_packed_dataloader\u001b[39m\u001b[34m(self, tokenizer, dataset, dataset_text_field, max_seq_length, num_of_sequences, chars_per_token, formatting_func, append_concat_token, add_special_tokens)\u001b[39m\n\u001b[32m    629\u001b[39m         packed_dataset = Dataset.from_generator(\n\u001b[32m    630\u001b[39m             data_generator, gen_kwargs={\u001b[33m\"\u001b[39m\u001b[33mconstant_length_iterator\u001b[39m\u001b[33m\"\u001b[39m: constant_length_iterator}\n\u001b[32m    631\u001b[39m         )\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (DatasetGenerationError, SchemaInferenceError) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    634\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mError occurred while packing the dataset. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    635\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMake sure that your dataset has enough samples to at least yield one packed sequence.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    636\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m packed_dataset\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Error occurred while packing the dataset. Make sure that your dataset has enough samples to at least yield one packed sequence."
     ]
    }
   ],
   "source": [
    "# 먼저 1 epoch로 훈련 -> 추론이 잘 이루어지는지 확인\n",
    "# 이후 epoch를 늘려 과적합이 일어날 때 까지 학습하는 것이 좋음\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datetime import datetime\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./SFT\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    max_seq_length=1024,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    load_best_model_at_end=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=11,\n",
    "    warmup_steps=1,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=5e-5,\n",
    "    group_by_length=True,\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\"\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=val_subset,\n",
    "    args=training_args,\n",
    "    formatting_func=generate_prompts,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)] # 3번 연속으로 성적이 나쁘면 중단\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e672dbac-5f70-4149-a708-4ba39536b45a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 2:59:29, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.186900</td>\n",
       "      <td>1.046735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.962100</td>\n",
       "      <td>0.953926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.929190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.913100</td>\n",
       "      <td>0.914811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.872100</td>\n",
       "      <td>0.906348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.903418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>0.901169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.900246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.806900</td>\n",
       "      <td>0.899870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.791700</td>\n",
       "      <td>0.900180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.807700</td>\n",
       "      <td>0.901579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.761800</td>\n",
       "      <td>0.901505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▅▄▅▄▅▅▂▄▁▃▃█</td></tr><tr><td>eval/samples_per_second</td><td>▄▄▄▄▄▄▆▆█▆▆▁</td></tr><tr><td>eval/steps_per_second</td><td>██▁█▁██████▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>█▃▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▆▄▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.90151</td></tr><tr><td>eval/runtime</td><td>127.8985</td></tr><tr><td>eval/samples_per_second</td><td>3.127</td></tr><tr><td>eval/steps_per_second</td><td>1.564</td></tr><tr><td>total_flos</td><td>2.3204562474973594e+17</td></tr><tr><td>train/epoch</td><td>9.92</td></tr><tr><td>train/global_step</td><td>620</td></tr><tr><td>train/grad_norm</td><td>0.84141</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.794</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2026-01-29 01:23:51</strong> at: <a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv3' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv3</a><br> View project at: <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260129_012352-legal_testv3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_save_path = \"./SFT/final\"\n",
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=True) # 이어서 학습을 진행하고 싶은 경우, 가장 마지막 checkpoint-XX를 불러와서 학습이 진행된다\n",
    "\n",
    "trainer.save_model(final_save_path)\n",
    "tokenizer.save_pretrained(final_save_path)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa6f9ed-12a8-46b9-891a-1d6d4f7566cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 추론된 모델 확인\n",
    "# 중요!!! 학습 이후 커널을 내리고 다시 올려야 파인튜닝된 가중치를 모델에 올릴 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f960ed74-2364-4466-9c56-9d699b5915ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import os, torch, json, wandb, subprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig, \n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7ea6a2-5ef9-4d84-9766-fc7f33d9a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 4bit 할 것이냐\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, #bfloat16 or float16\n",
    "    bnb_4bit_quant_type=\"nf4\", # nf4 or fp4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0950899f-4b1c-4ae8-b14e-f6235d6793d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  queued_call()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38228d6fc8824768a8457c6a6bf5ccd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 및 토크나이저 불러오기\n",
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "model_id = \"/home/vsc/LLM/model/EXAONE-3.5-7.8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672d9e5e-2a0e-4488-a811-02fdfef93271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): ExaoneForCausalLM(\n",
       "      (transformer): ExaoneModel(\n",
       "        (wte): Embedding(102400, 4096, padding_idx=0)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-31): 32 x ExaoneBlock(\n",
       "            (ln_1): ExaoneRMSNorm()\n",
       "            (attn): ExaoneAttention(\n",
       "              (attention): ExaoneSdpaAttention(\n",
       "                (rotary): ExaoneRotaryEmbedding()\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (ln_2): ExaoneRMSNorm()\n",
       "            (mlp): ExaoneGatedMLP(\n",
       "              (c_fc_0): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (c_fc_1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (c_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): ExaoneRMSNorm()\n",
       "        (rotary): ExaoneRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_path = \"./SFT/final\"\n",
    "model = PeftModel.from_pretrained(model, adapter_path) # 학습된 LoRA Config를 씌운다\n",
    "model.eval() # 추론 모드로 모델을 바꾼다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcae29ae-d7a0-425b-83cd-6a6699f38c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 || 400 || 200\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "from datasets import Dataset\n",
    "\n",
    "def load_json_files(dir) :\n",
    "    loaded_data = []\n",
    "    for filename in os.listdir(dir) :\n",
    "        if filename.endswith('.json') :\n",
    "            with open(os.path.join(dir, filename), 'r', encoding='utf-8') as f :\n",
    "                loaded_data.append(json.load(f))\n",
    "    \n",
    "    return loaded_data\n",
    "\n",
    "def create_dataset(data) :\n",
    "    dataset_dict = {\n",
    "        \"id\": [],\n",
    "        \"question\": [],\n",
    "        \"context\": [],\n",
    "        \"summary\": [],\n",
    "        \"answer\" : [],\n",
    "    }\n",
    "\n",
    "    for item in data:\n",
    "        dataset_dict[\"id\"].append(item[\"info\"][\"id\"])\n",
    "        dataset_dict[\"question\"].append(item[\"jdgmnInfo\"][0][\"question\"])\n",
    "        dataset_dict[\"context\"].append(item[\"Summary\"][0][\"summ_contxt\"])\n",
    "        dataset_dict[\"summary\"].append(item[\"Summary\"][0][\"summ_pass\"])\n",
    "        dataset_dict[\"answer\"].append(item[\"jdgmnInfo\"][0][\"answer\"])\n",
    "\n",
    "    return Dataset.from_dict(dataset_dict)\n",
    "    \n",
    "extract_dir_list = [\"./3.개방데이터/1.데이터/extract/Training/02.라벨링데이터\", \"./3.개방데이터/1.데이터/extract/Validation/02.라벨링데이터\", \"./3.개방데이터/1.데이터/raw/Training/0.1.원천데이터\"]\n",
    "train_data, val_data = load_json_files(extract_dir_list[0]), load_json_files(extract_dir_list[1])\n",
    "\n",
    "train_dataset = create_dataset(train_data)\n",
    "val_dataset = create_dataset(val_data)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "train_subset = train_dataset.shuffle(seed=seed).select(range(1000))\n",
    "val_subset = val_dataset.shuffle(seed=seed).select(range(400))\n",
    "test_subset = val_dataset.shuffle(seed=seed).select(range(401, 601))\n",
    "\n",
    "print(f\"{len(train_subset)} || {len(val_subset)} || {len(test_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791e331d-da49-4468-9196-7a39411f4e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_legal_answer(question) :\n",
    "    system_message = \"당신은 법률 및 규정 관련 전문가입니다. 사용자의 질문에 대해 '긍정' 및 '부정', 혹은 '불명' 여부를 판단한 후, 그에 대한 구체적인 근거를 문맥(context)에서 추출해서 설명하세요.\"\n",
    "    messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": f\"사용자의 질문인 {question}에 대해 3문단 이내로 답변하세요.\"},\n",
    "        ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True, # 모델이 답변을 하도록 만드는 프롬프트\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad() : # 추론 단계에서는 가중치가 업데이트 되지 않도록\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False, # True : 확률적으로 다음 단어 선택, False : 가장 높은 확률만 선택\n",
    "            repetition_penalty=1.1, # 이미 등장한 단어가 나올 확률을 줄임\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            # do_sample=False면 무시됨\n",
    "            # temperature=0.0, # 낮을수록 창의적이지 않은, 정확한 답을 낸다\n",
    "            # top_p=1.0, # 누적 확률이 p 이내인 후보 단어들 중 샘플링\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d48eefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 및 비교 시작... 총 200개 데이터\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [17:20<00:00,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[최종 검증 요약]\n",
      "- Label Accuracy: 68.50%\n",
      "- ROUGE-L: 0.0753\n",
      "- BLEU: 0.1541\n",
      "\n",
      "[상세 분류 리포트]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          긍정       0.81      0.66      0.73       119\n",
      "          부정       0.57      0.78      0.66        74\n",
      "          불명       0.00      0.00      0.00         7\n",
      "          실패       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.34      0.36      0.35       200\n",
      "weighted avg       0.69      0.69      0.68       200\n",
      "\n",
      "검증 완료! 로그 파일: ./result/log_without_context2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 유저가 Context를 주지 않을 경우\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher # 텍스트간 유사도 측정 라이브러리\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import evaluate  # Hugging Face evaluate 라이브러리\n",
    "\n",
    "# 1. 지표 로더\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "\n",
    "# 2. 결과 파일 및 통계 초기화\n",
    "output_file_path = \"./result/log_without_context2.txt\"\n",
    "os.makedirs(\"./result\", exist_ok=True)\n",
    "\n",
    "all_preds_text = []    # ROUGE/BLEU용 모델 답변\n",
    "all_refs_text = []     # ROUGE/BLEU용 실제 정답\n",
    "y_true_idx = []        # 혼동행렬용 실제 라벨\n",
    "y_pred_idx = []        # 혼동행렬용 예측 라벨\n",
    "\n",
    "label_map = {\"긍정\": 0, \"부정\": 1, \"불명\": 2}\n",
    "correct_labels = 0\n",
    "total_samples = len(test_subset)\n",
    "\n",
    "print(f\"검증 및 비교 시작... 총 {total_samples}개 데이터\")\n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== EXAONE 법률 QA 정답 비교 검증 로그 ===\\n\\n\")\n",
    "\n",
    "    for i, data in enumerate(tqdm(test_subset, desc=\"Evaluating\")):\n",
    "        question = data[\"question\"]\n",
    "        context = data[\"context\"]\n",
    "        actual_label = str(data[\"answer\"]).strip() # 실제 정답 (긍정/부정/불명)\n",
    "        summary = data[\"summary\"]\n",
    "        \n",
    "        if actual_label == \"긍정\":\n",
    "            ground_truth = f\"네 그렇습니다! {summary}에 의하여 질문하신 내용은 옳습니다.\"\n",
    "        elif actual_label == \"부정\":\n",
    "            ground_truth = f\"아니요, 그렇지 않습니다! {summary}에 의하면 상충되는 내용이 있으므로 질문하신 내용은 옳지 않습니다.\"\n",
    "        else:\n",
    "            ground_truth = f\"확실하지 않습니다만, {summary}에 적힌 내용을 근거로 판단해 볼 수 있을 것 같습니다.\"\n",
    "\n",
    "        # 모델 답변 생성\n",
    "        generated_answer = generate_legal_answer(question)\n",
    "\n",
    "        actual_idx = label_map.get(actual_label, 3)\n",
    "        if \"네\" in generated_answer[:10]: pred_idx = 0\n",
    "        elif \"아니요\" in generated_answer[:10]: pred_idx = 1\n",
    "        elif \"확실하지\" in generated_answer[:10]: pred_idx = 2\n",
    "        else: pred_idx = 3 # 분류 실패\n",
    "\n",
    "        y_true_idx.append(actual_idx)\n",
    "        y_pred_idx.append(pred_idx)\n",
    "        if actual_idx == pred_idx: correct_labels += 1\n",
    "\n",
    "        all_preds_text.append(generated_answer)\n",
    "        all_refs_text.append(ground_truth)\n",
    "\n",
    "        similarity = SequenceMatcher(None, ground_truth, generated_answer).ratio()\n",
    "\n",
    "        # 로그 기록\n",
    "        f.write(f\"[{i+1}번 데이터] | Label 일치: {'O' if actual_idx == pred_idx else 'X'} | 유사도: {similarity:.2f}\\n\")\n",
    "        f.write(f\"질문: {question}\\n\")\n",
    "        f.write(f\"실제 정답: {ground_truth}\\n\")\n",
    "        f.write(f\"모델 답변: {generated_answer}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    rouge_results = rouge_metric.compute(predictions=all_preds_text, references=all_refs_text)\n",
    "    bleu_results = bleu_metric.compute(predictions=all_preds_text, references=all_refs_text)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_true_idx, y_pred_idx, labels=[0, 1, 2, 3])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='RdPu', \n",
    "                xticklabels=[\"pos\", \"neg\", \"non\", \"fail\"], \n",
    "                yticklabels=[\"pos\", \"neg\", \"non\", \"fail\"])\n",
    "    plt.title(\"Without Context\")\n",
    "    plt.savefig(\"./result/confusion_matrix_wiithout_context.png\")\n",
    "\n",
    "    # 5. 최종 통계 기록\n",
    "    accuracy = (correct_labels / total_samples) * 100\n",
    "    report = classification_report(y_true_idx, y_pred_idx, \n",
    "                                   target_names=['긍정', '부정', '불명', '실패'], labels=[0, 1, 2, 3])\n",
    "    summary_msg = (\n",
    "        f\"\\n[최종 검증 요약]\\n\"\n",
    "        f\"- Label Accuracy: {accuracy:.2f}%\\n\"\n",
    "        f\"- ROUGE-L: {rouge_results['rougeL']:.4f}\\n\"\n",
    "        f\"- BLEU: {bleu_results['bleu']:.4f}\\n\"\n",
    "        f\"\\n[상세 분류 리포트]\\n{report}\"\n",
    "    )\n",
    "    \n",
    "    print(summary_msg)\n",
    "    f.write(summary_msg)\n",
    "\n",
    "print(f\"검증 완료! 로그 파일: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84135781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_legal_answer_with_context(question, context) :\n",
    "    system_message = \"당신은 법률 및 규정 관련 전문가입니다. 사용자의 질문에 대해 '긍정' 및 '부정', 혹은 '불명' 여부를 판단한 후, 그에 대한 구체적인 근거를 문맥(context)에서 추출해서 설명하세요.\"\n",
    "    messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": f\"사용자의 질문인 {question}에 대해 {context}를 참조하여 3문단 이내로 답변하세요.\"},\n",
    "        ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True, # 모델이 답변을 하도록 만드는 프롬프트\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad() : # 추론 단계에서는 가중치가 업데이트 되지 않도록\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False, # True : 확률적으로 다음 단어 선택, False : 가장 높은 확률만 선택\n",
    "            repetition_penalty=1.1, # 이미 등장한 단어가 나올 확률을 줄임\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            # do_sample=False면 무시됨\n",
    "            # temperature=0.0, # 낮을수록 창의적이지 않은, 정확한 답을 낸다\n",
    "            # top_p=1.0, # 누적 확률이 p 이내인 후보 단어들 중 샘플링\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab16fdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 및 비교 시작... 총 200개 데이터\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [15:42<00:00,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[최종 검증 요약]\n",
      "- Label Accuracy: 88.50%\n",
      "- ROUGE-L: 0.2117\n",
      "- BLEU: 0.4497\n",
      "\n",
      "[상세 분류 리포트]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          긍정       0.93      0.90      0.91       119\n",
      "          부정       0.82      0.95      0.88        74\n",
      "          불명       0.00      0.00      0.00         7\n",
      "          실패       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.44      0.46      0.45       200\n",
      "weighted avg       0.86      0.89      0.87       200\n",
      "\n",
      "검증 완료! 로그 파일: ./result/log_with_context.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 유저가 Context를 주는 경우\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher # 텍스트간 유사도 측정 라이브러리\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import evaluate  # Hugging Face evaluate 라이브러리\n",
    "\n",
    "# 1. 지표 로더\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "\n",
    "# 2. 결과 파일 및 통계 초기화\n",
    "output_file_path = \"./result/log_with_context.txt\"\n",
    "os.makedirs(\"./result\", exist_ok=True)\n",
    "\n",
    "all_preds_text = []    # ROUGE/BLEU용 모델 답변\n",
    "all_refs_text = []     # ROUGE/BLEU용 실제 정답\n",
    "y_true_idx = []        # 혼동행렬용 실제 라벨\n",
    "y_pred_idx = []        # 혼동행렬용 예측 라벨\n",
    "\n",
    "label_map = {\"긍정\": 0, \"부정\": 1, \"불명\": 2}\n",
    "correct_labels = 0\n",
    "total_samples = len(test_subset)\n",
    "\n",
    "print(f\"검증 및 비교 시작... 총 {total_samples}개 데이터\")\n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== EXAONE 법률 QA 정답 비교 검증 로그 ===\\n\\n\")\n",
    "\n",
    "    for i, data in enumerate(tqdm(test_subset, desc=\"Evaluating\")):\n",
    "        question = data[\"question\"]\n",
    "        context = data[\"context\"]\n",
    "        actual_label = str(data[\"answer\"]).strip() # 실제 정답 (긍정/부정/불명)\n",
    "        summary = data[\"summary\"]\n",
    "        \n",
    "        if actual_label == \"긍정\":\n",
    "            ground_truth = f\"네 그렇습니다! {summary}에 의하여 질문하신 내용은 옳습니다.\"\n",
    "        elif actual_label == \"부정\":\n",
    "            ground_truth = f\"아니요, 그렇지 않습니다! {summary}에 의하면 상충되는 내용이 있으므로 질문하신 내용은 옳지 않습니다.\"\n",
    "        else:\n",
    "            ground_truth = f\"확실하지 않습니다만, {summary}에 적힌 내용을 근거로 판단해 볼 수 있을 것 같습니다.\"\n",
    "\n",
    "        # 모델 답변 생성\n",
    "        generated_answer = generate_legal_answer_with_context(question, context)\n",
    "\n",
    "        actual_idx = label_map.get(actual_label, 3)\n",
    "        if \"네\" in generated_answer[:10]: pred_idx = 0\n",
    "        elif \"아니요\" in generated_answer[:10]: pred_idx = 1\n",
    "        elif \"확실하지\" in generated_answer[:10]: pred_idx = 2\n",
    "        else: pred_idx = 3 # 분류 실패\n",
    "\n",
    "        y_true_idx.append(actual_idx)\n",
    "        y_pred_idx.append(pred_idx)\n",
    "        if actual_idx == pred_idx: correct_labels += 1\n",
    "\n",
    "        all_preds_text.append(generated_answer)\n",
    "        all_refs_text.append(ground_truth)\n",
    "\n",
    "        similarity = SequenceMatcher(None, ground_truth, generated_answer).ratio()\n",
    "\n",
    "        # 로그 기록\n",
    "        f.write(f\"[{i+1}번 데이터] | Label 일치: {'O' if actual_idx == pred_idx else 'X'} | 유사도: {similarity:.2f}\\n\")\n",
    "        f.write(f\"질문: {question}\\n\")\n",
    "        f.write(f\"실제 정답: {ground_truth}\\n\")\n",
    "        f.write(f\"모델 답변: {generated_answer}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    rouge_results = rouge_metric.compute(predictions=all_preds_text, references=all_refs_text)\n",
    "    bleu_results = bleu_metric.compute(predictions=all_preds_text, references=all_refs_text)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_true_idx, y_pred_idx, labels=[0, 1, 2, 3])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='RdPu', \n",
    "                xticklabels=[\"pos\", \"neg\", \"non\", \"fail\"], \n",
    "                yticklabels=[\"pos\", \"neg\", \"non\", \"fail\"])\n",
    "    plt.title(\"With Context\")\n",
    "    plt.savefig(\"./result/confusion_matrix_wiith_context.png\")\n",
    "\n",
    "    # 5. 최종 통계 기록\n",
    "    accuracy = (correct_labels / total_samples) * 100\n",
    "    report = classification_report(y_true_idx, y_pred_idx, \n",
    "                                   target_names=['긍정', '부정', '불명', '실패'], labels=[0, 1, 2, 3])\n",
    "    summary_msg = (\n",
    "        f\"\\n[최종 검증 요약]\\n\"\n",
    "        f\"- Label Accuracy: {accuracy:.2f}%\\n\"\n",
    "        f\"- ROUGE-L: {rouge_results['rougeL']:.4f}\\n\"\n",
    "        f\"- BLEU: {bleu_results['bleu']:.4f}\\n\"\n",
    "        f\"\\n[상세 분류 리포트]\\n{report}\"\n",
    "    )\n",
    "    \n",
    "    print(summary_msg)\n",
    "    f.write(summary_msg)\n",
    "\n",
    "print(f\"검증 완료! 로그 파일: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62898087-f28f-46ce-815d-37849b2e0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def count_instruction_leakage(file_path):\n",
    "    # 찾고자 하는 특정 패턴 (정규표현식을 사용해 'n문단' 부분 유연하게 대응 가능)\n",
    "    # 만약 정확히 '3문단'만 찾고 싶다면 \"를 참조하여 3문단 이내로 답변하세요.\" 로 수정하세요.\n",
    "    target_suffix = \"를 참조하여 3문단 이내로 답변하세요.\"\n",
    "    \n",
    "    leakage_count = 0\n",
    "    total_answers = 0\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "            # '모델 답변:' 이후부터 다음 구분선(---) 혹은 파일 끝까지의 텍스트를 추출\n",
    "            model_answers = re.findall(r\"모델 답변:\\s*(.*?)(?=\\n-{10,}|\\n===|\\Z)\", content, re.DOTALL)\n",
    "            \n",
    "            total_answers = len(model_answers)\n",
    "            \n",
    "            for answer in model_answers:\n",
    "                # 앞뒤 공백 제거 후 타겟 문구로 끝나는지 확인\n",
    "                clean_answer = answer.strip()\n",
    "                if clean_answer.endswith(target_suffix):\n",
    "                    leakage_count += 1\n",
    "                    \n",
    "        print(f\"📊 검증 결과 리포트\")\n",
    "        print(f\"----------------------\")\n",
    "        print(f\"✅ 전체 모델 답변 수: {total_answers}개\")\n",
    "        print(f\"⚠️ 지시 사항 누수 발생: {leakage_count}개\")\n",
    "        \n",
    "        if total_answers > 0:\n",
    "            leakage_rate = (leakage_count / total_answers) * 100\n",
    "            print(f\"📈 누수 발생률: {leakage_rate:.2f}%\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 파일을 찾을 수 없습니다: {file_path}\")\n",
    "\n",
    "# 파일 경로를 넣고 실행하세요\n",
    "count_instruction_leakage(\"./result/log_without_context.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a910c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace에 모델 load / unload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0babcf18-a72d-4430-adc4-25b0583f0ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QA",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
