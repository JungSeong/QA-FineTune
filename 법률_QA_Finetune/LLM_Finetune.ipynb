{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63df3b4",
   "metadata": {},
   "source": [
    "참고 : https://zero-ai.tistory.com/62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eceafe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능 여부: True\n",
      "GPU 이름: NVIDIA GB10\n",
      "CUDA 버전: 13.0\n",
      "PyTorch 버전: <module 'torch.version' from '/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/version.py'>\n",
      "bf16 지원 여부: <function is_bf16_supported at 0xe23e5619be20>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA 사용 가능 여부: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "print(f\"PyTorch 버전: {torch.version}\")\n",
    "print(f\"bf16 지원 여부: {torch.cuda.is_bf16_supported}\")\n",
    "print(torch.cuda.get_device_capability()[0] >= 8) # 8 이상이면 고성능 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6440e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O : 성공 : TL_10.개인정보.ICT.zip\n",
      "O : 성공 : TL_05.행정.zip\n",
      "X : 실패 (파일 깨짐): TL_01.민사.zip (크기: 18409624 bytes)\n",
      "O : 성공 : TL_06.기업.zip\n",
      "O : 성공 : TL_02.가사.zip\n",
      "O : 성공 : TL_04.형사B(일반형).zip\n",
      "O : 성공 : TL_08.특허.저작권.zip\n",
      "O : 성공 : TL_07.근로자.zip\n",
      "O : 성공 : TL_09.금융조세.zip\n",
      "O : 성공 : TL_03.형사A(생활형).zip\n",
      "O : 성공 : VL_02.가사.zip\n",
      "O : 성공 : VL_10.개인정보.ICT.zip\n",
      "O : 성공 : VL_07.근로자.zip\n",
      "O : 성공 : VL_09.금융조세.zip\n",
      "O : 성공 : VL_05.행정.zip\n",
      "O : 성공 : VL_08.특허.저작권.zip\n",
      "O : 성공 : VL_03.형사A(생활형).zip\n",
      "O : 성공 : VL_01.민사.zip\n",
      "O : 성공 : VL_04.형사B(일반형).zip\n",
      "O : 성공 : VL_06.기업.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "target_dir_list = [\"./3.개방데이터/1.데이터/Training/02.라벨링데이터\", \"./3.개방데이터/1.데이터/Validation/02.라벨링데이터\"]\n",
    "extract_dir_list = [\"./3.개방데이터/1.데이터/extract/Training/02.라벨링데이터\", \"./3.개방데이터/1.데이터/extract/Validation/02.라벨링데이터\", \"./3.개방데이터/1.데이터/raw/Training/0.1.원천데이터\"]\n",
    "\n",
    "if not os.path.exists(extract_dir_list[0]):\n",
    "    os.makedirs(extract_dir_list[0])\n",
    "if not os.path.exists(extract_dir_list[1]):\n",
    "    os.makedirs(extract_dir_list[1])\n",
    "\n",
    "for target_dir, extract_dir in zip(target_dir_list, extract_dir_list):\n",
    "    for file in os.listdir(target_dir):\n",
    "        if file.endswith(\".zip\"):\n",
    "            file_path = os.path.join(target_dir, file)\n",
    "\n",
    "            try :\n",
    "                with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "                    zip_ref.extractall(extract_dir)\n",
    "                    print(f\"O : 성공 : {file}\")\n",
    "            except zipfile.BadZipFile :\n",
    "                file_size = os.path.getsize(file_path)\n",
    "                print(f\"X : 실패 (파일 깨짐): {file} (크기: {file_size} bytes)\")\n",
    "            except Exception as e:\n",
    "                print(f\"기타 에러 ({file}): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7b9f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O : 성공 : 01.원천데이터\\TS_1.판례_10.개인정보.ICT.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_10.개인정보.ICT.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_06.기업.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_05.행정.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_05.행정.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_09.금융조세.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_04.형사B(일반형).zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_02.가사.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_07.근로자.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_08.특허.저작권.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_09.금융조세.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_07.근로자.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_08.특허.저작권.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_03.형사A(생활형).zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_01.민사.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_06.기업.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_04.형사B(일반형).zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_01.민사.zip\n"
     ]
    }
   ],
   "source": [
    "raw_dir_list = [\"./3.개방데이터/1.데이터/Training/01.원천데이터\"]\n",
    "\n",
    "if not os.path.exists(raw_dir_list[0]):\n",
    "    os.makedirs(raw_dir_list[0])\n",
    "\n",
    "for file in os.listdir(raw_dir_list[0]):\n",
    "    if file.endswith(\".zip\"):\n",
    "        file_path = os.path.join(raw_dir_list[0], file)\n",
    "\n",
    "        try :\n",
    "            with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(extract_dir_list[2])\n",
    "                print(f\"O : 성공 : {file}\")\n",
    "        except zipfile.BadZipFile :\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"X : 실패 (파일 깨짐): {file} (크기: {file_size} bytes)\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"기타 에러 ({file}): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f912885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 셋 전처리\n",
    "\n",
    "import json, os\n",
    "from datasets import Dataset\n",
    "\n",
    "def load_json_files(dir) :\n",
    "    loaded_data = []\n",
    "    for filename in os.listdir(dir) :\n",
    "        if filename.endswith('.json') :\n",
    "            with open(os.path.join(dir, filename), 'r', encoding='utf-8') as f :\n",
    "                loaded_data.append(json.load(f))\n",
    "    \n",
    "    return loaded_data\n",
    "\n",
    "def create_dataset(data) :\n",
    "    dataset_dict = {\n",
    "        \"id\": [],\n",
    "        \"question\": [],\n",
    "        \"context\": [],\n",
    "        \"summary\": [],\n",
    "        \"answer\" : [],\n",
    "    }\n",
    "\n",
    "    for item in data:\n",
    "        dataset_dict[\"id\"].append(item[\"info\"][\"id\"])\n",
    "        dataset_dict[\"question\"].append(item[\"jdgmnInfo\"][0][\"question\"])\n",
    "        dataset_dict[\"context\"].append(item[\"Summary\"][0][\"summ_contxt\"])\n",
    "        dataset_dict[\"summary\"].append(item[\"Summary\"][0][\"summ_pass\"])\n",
    "        dataset_dict[\"answer\"].append(item[\"jdgmnInfo\"][0][\"answer\"])\n",
    "\n",
    "    return Dataset.from_dict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9ff410",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dir_list = [\"./3.개방데이터/1.데이터/extract/Training/02.라벨링데이터\", \"./3.개방데이터/1.데이터/extract/Validation/02.라벨링데이터\", \"./3.개방데이터/1.데이터/raw/Training/0.1.원천데이터\"]\n",
    "train_data, val_data = load_json_files(extract_dir_list[0]), load_json_files(extract_dir_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498262bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 || 400 || 200\n"
     ]
    }
   ],
   "source": [
    "# 처음에는 일부 데이터 셋으로 테스트\n",
    "train_dataset = create_dataset(train_data)\n",
    "val_dataset = create_dataset(val_data)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "train_subset = train_dataset.shuffle(seed=seed).select(range(1000))\n",
    "val_subset = val_dataset.shuffle(seed=seed).select(range(400))\n",
    "test_subset = val_dataset.shuffle(seed=seed).select(range(401, 601))\n",
    "\n",
    "print(f\"{len(train_subset)} || {len(val_subset)} || {len(test_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074a3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 학습 시킬 모델 불러오기\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import os, torch, json, wandb, subprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig, \n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b232b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양자화 설정\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 4bit 할 것이냐\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, #bfloat16 or float16\n",
    "    bnb_4bit_quant_type=\"nf4\", # nf4 or fp4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a33ff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  queued_call()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d52c24964cd4c2fab1627456e146a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExaoneForCausalLM(\n",
      "  (transformer): ExaoneModel(\n",
      "    (wte): Embedding(102400, 4096, padding_idx=0)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-31): 32 x ExaoneBlock(\n",
      "        (ln_1): ExaoneRMSNorm()\n",
      "        (attn): ExaoneAttention(\n",
      "          (attention): ExaoneSdpaAttention(\n",
      "            (rotary): ExaoneRotaryEmbedding()\n",
      "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "            (out_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (ln_2): ExaoneRMSNorm()\n",
      "        (mlp): ExaoneGatedMLP(\n",
      "          (c_fc_0): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (c_fc_1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (c_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): ExaoneRMSNorm()\n",
      "    (rotary): ExaoneRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 및 토크나이저 불러오기\n",
    "\n",
    "model_id = \"/home/vsc/LLM/model/EXAONE-3.5-7.8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de923173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c_proj', 'c_fc_1', 'v_proj', 'c_fc_0', 'k_proj', 'q_proj', 'out_proj']\n"
     ]
    }
   ],
   "source": [
    "# LoRA를 붙힐 레이어의 명칭을 찾아주는 코드\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    " \n",
    "modules = find_all_linear_names(model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dabce7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules={'v_proj', 'out_proj', 'k_proj', 'q_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))\n"
     ]
    }
   ],
   "source": [
    "# 어떤 부분을 학습하냐에 따라서도 결과 값이 달라짐\n",
    "modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"]\n",
    "\n",
    "# 변경 가능한 파라미터들\n",
    "peft_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\", #CAUSAL_LM, FEATURE_EXTRACTION, QUESTION_ANS, SEQ_2_SEQ_LM, SEQ_CLS, TOKEN_CLS.\n",
    "    inference_mode=False, # 학습 중에는 False로 두어야 가중치 업데이트 가능\n",
    "    r=16, # r은 보통 2의 배수로 두는데, r이 클수록 학습 가능한 파라미터의 수가 더 많아짐\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=modules\n",
    ")\n",
    "\n",
    "print(peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce8e3fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13,631,488 || all params: 7,832,080,384 || trainable%: 0.1740\n"
     ]
    }
   ],
   "source": [
    "# 전체 파라미터 중 일부만 업데이트 되는 것을 확인할 수 있음\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6942527f-b97e-4571-9fef-8fec269ad9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompts(examples):\n",
    "    prompt_list = []\n",
    "    system_message = \"당신은 법률 및 규정 관련 전문가입니다. 사용자의 질문에 대해 '긍정'및 '부정', '불명' 여부를 판단한 후, 그에 대한 구체적인 근거를 문맥(context)에서 추출해서 설명하세요.\"\n",
    "\n",
    "    for i in range(len(examples['question'])):\n",
    "        # 각 리스트에서 i번째 데이터를 추출합니다.\n",
    "        answer = str(examples[\"answer\"][i]).strip()\n",
    "        question = examples[\"question\"][i]\n",
    "        context = examples[\"context\"][i]\n",
    "        summary = examples[\"summary\"][i]\n",
    "\n",
    "        # 사용자님의 정답 생성 로직\n",
    "        if answer == \"긍정\":\n",
    "            target_answer = f\"네 그렇습니다! {summary}에 의하여 질문하신 내용은 옳습니다.\"\n",
    "        elif answer == \"부정\":\n",
    "            target_answer = f\"아니요, 그렇지 않습니다! {summary}에 의하면 상충되는 내용이 있으므로 질문하신 내용은 옳지 않습니다.\"\n",
    "        elif answer == \"불명\":\n",
    "            target_answer = f\"확실하지 않습니다만, {summary}에 적힌 내용을 근거로 판단해 볼 수 있을 것 같습니다.\"\n",
    "        else:\n",
    "            target_answer = f\"해당 사안에 대해서는 제공된 근거({summary})를 바탕으로 판단이 필요합니다.\"\n",
    "\n",
    "        # 채팅 템플릿 구성\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": f\"사용자의 질문인 {question}에 대해 {context}를 참조하여 3문단 이내로 답변하세요.\"},\n",
    "            {\"role\": \"assistant\", \"content\": target_answer}\n",
    "        ]\n",
    "\n",
    "        full_prompt = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        \n",
    "        prompt_list.append(full_prompt)\n",
    "    \n",
    "    return prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e0bd675-4218-4f27-a727-7450628f7052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[|system|]당신은 법률 및 규정 관련 전문가입니다. 사용자의 질문에 대해 '긍정'및 '부정', '불명' 여부를 판단한 후, 그에 대한 구체적인 근거를 문맥(context)에서 추출해서 설명하세요.[|endofturn|]\n",
      "[|user|]사용자의 질문인 입찰에서 관련 시장은 각 입찰별로 특정 상품·용역에 대한 구매 물량·금액이 정해져 있고 해당 상품·용역은 낙찰사로 결정된 특정 사업자만이 공급을 담당하게 된다는 점에서 각 개별 입찰 건을 하나의 시장으로 보는 것이 타당한가?에 대해 <!--각주-->18) 입찰 시장은 각 입찰별로 특정 상품·용역에 대한 구매 물량·금액이 정해져 있고 해당 상품·용역은 낙찰사로 결정된 특정 사업자만이 공급을 담당하게 되므로, 입찰에서 관련시장은 각 개별 입찰 건을 하나의 시장으로 보는 것이 타당하다.\n",
      "19) 피심인 한진의 석○○ 차장은 “적격심사제의 특성상 합의에 참여하지 않은 경쟁자들의 존재로 인해 낙찰은 담보되어 있지 않았지만, 최대한 협조사들을 동원하여 당사 판단 하에 낙찰 가능성이 가장 높은 투찰가격을 당사에게 배분하고 당사보다는 높은 가격이지만 그 다음으로 낙찰가능성이 있는 가격을 순차적으로 다른 들러리사에게 배분하여 투찰하도록 함으로써 당사의 낙찰 확률을 높일 목적으로 합의를 하였습니다.”라고 진술하였다(소갑 제7호증 참조).를 참조하여 3문단 이내로 답변하세요.\n",
      "[|assistant|]네 그렇습니다! 입찰 시장은 각 입찰별로 특정 상품·용역에 대한 구매 물량·금액이 정해져 있고 해당 상품·용역은 낙찰사로 결정된 특정 사업자만이 공급을 담당하게 되므로, 입찰에서 관련시장은 각 개별 입찰 건을 하나의 시장으로 보는 것이 타당하다.에 의하여 질문하신 내용은 옳습니다.[|endofturn|]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_prompts(train_subset)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ce8f6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa693e9a4ba043fe8a3ba6ffc2ef44e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d9976d409b43809c568c6f6e6adf8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 41000982, 'question': '입찰에서 관련 시장은 각 입찰별로 특정 상품·용역에 대한 구매 물량·금액이 정해져 있고 해당 상품·용역은 낙찰사로 결정된 특정 사업자만이 공급을 담당하게 된다는 점에서 각 개별 입찰 건을 하나의 시장으로 보는 것이 타당한가?', 'context': '<!--각주-->18) 입찰 시장은 각 입찰별로 특정 상품·용역에 대한 구매 물량·금액이 정해져 있고 해당 상품·용역은 낙찰사로 결정된 특정 사업자만이 공급을 담당하게 되므로, 입찰에서 관련시장은 각 개별 입찰 건을 하나의 시장으로 보는 것이 타당하다.\\n19) 피심인 한진의 석○○ 차장은 “적격심사제의 특성상 합의에 참여하지 않은 경쟁자들의 존재로 인해 낙찰은 담보되어 있지 않았지만, 최대한 협조사들을 동원하여 당사 판단 하에 낙찰 가능성이 가장 높은 투찰가격을 당사에게 배분하고 당사보다는 높은 가격이지만 그 다음으로 낙찰가능성이 있는 가격을 순차적으로 다른 들러리사에게 배분하여 투찰하도록 함으로써 당사의 낙찰 확률을 높일 목적으로 합의를 하였습니다.”라고 진술하였다(소갑 제7호증 참조).', 'summary': '입찰 시장은 각 입찰별로 특정 상품·용역에 대한 구매 물량·금액이 정해져 있고 해당 상품·용역은 낙찰사로 결정된 특정 사업자만이 공급을 담당하게 되므로, 입찰에서 관련시장은 각 개별 입찰 건을 하나의 시장으로 보는 것이 타당하다.', 'answer': '긍정', 'text': \"[|system|]당신은 법률 및 규정 관련 전문가입니다. 사용자의 질문에 대해 '긍정' 및 '부정', 혹은 '불명' 여부를 판단한 후, 그에 대한 구체적인 근거를 문맥(context)에서 추출해서 설명하세요.[|endofturn|]\\n[|user|]사용자의 질문인 입찰에서 관련 시장은 각 입찰별로 특정 상품·용역에 대한 구매 물량·금액이 정해져 있고 해당 상품·용역은 낙찰사로 결정된 특정 사업자만이 공급을 담당하게 된다는 점에서 각 개별 입찰 건을 하나의 시장으로 보는 것이 타당한가?에 대해 <!--각주-->18) 입찰 시장은 각 입찰별로 특정 상품·용역에 대한 구매 물량·금액이 정해져 있고 해당 상품·용역은 낙찰사로 결정된 특정 사업자만이 공급을 담당하게 되므로, 입찰에서 관련시장은 각 개별 입찰 건을 하나의 시장으로 보는 것이 타당하다.\\n19) 피심인 한진의 석○○ 차장은 “적격심사제의 특성상 합의에 참여하지 않은 경쟁자들의 존재로 인해 낙찰은 담보되어 있지 않았지만, 최대한 협조사들을 동원하여 당사 판단 하에 낙찰 가능성이 가장 높은 투찰가격을 당사에게 배분하고 당사보다는 높은 가격이지만 그 다음으로 낙찰가능성이 있는 가격을 순차적으로 다른 들러리사에게 배분하여 투찰하도록 함으로써 당사의 낙찰 확률을 높일 목적으로 합의를 하였습니다.”라고 진술하였다(소갑 제7호증 참조).를 참조하여 3문단 이내로 답변하세요.\\n[|assistant|]네 그렇습니다! 입찰 시장은 각 입찰별로 특정 상품·용역에 대한 구매 물량·금액이 정해져 있고 해당 상품·용역은 낙찰사로 결정된 특정 사업자만이 공급을 담당하게 되므로, 입찰에서 관련시장은 각 개별 입찰 건을 하나의 시장으로 보는 것이 타당하다.에 의하여 질문하신 내용은 옳습니다.[|endofturn|]\\n\"}\n",
      "최대 토큰 길이: 1232\n",
      "평균 토큰 길이: 523.87\n",
      "95번째 백분위수 (P95): 823.0\n",
      "99번째 백분위수 (P99): 975.02\n"
     ]
    }
   ],
   "source": [
    "# max_length 결정\n",
    "\n",
    "def generate_prompts_test(example) :\n",
    "    prompt_list = []\n",
    "    system_message = \"당신은 법률 및 규정 관련 전문가입니다. 사용자의 질문에 대해 '긍정' 및 '부정', 혹은 '불명' 여부를 판단한 후, 그에 대한 구체적인 근거를 문맥(context)에서 추출해서 설명하세요.\"\n",
    "\n",
    "    answer = str(example[\"answer\"]).strip()\n",
    "    question = example[\"question\"]\n",
    "    context = example[\"context\"]\n",
    "    summary = example[\"summary\"]\n",
    "\n",
    "    if answer == \"긍정\" :\n",
    "        target_answer = f\"네 그렇습니다! {summary}에 의하여 질문하신 내용은 옳습니다.\"\n",
    "    elif answer == \"부정\" :\n",
    "        target_answer = f\"아니요, 그렇지 않습니다! {summary}에 의하면 상충되는 내용이 있으므로 질문하신 내용은 옳지 않습니다.\"\n",
    "    elif answer == \"불명\" :\n",
    "        target_answer = f\"확실하지 않습니다만, {summary}에 적힌 내용을 근거로 판단해 볼 수 있을 것 같습니다.\"\n",
    "    else :\n",
    "        target_answer = f\"해당 사안에 대해서는 제공된 근거({summary})를 바탕으로 판단이 필요합니다.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": f\"사용자의 질문인 {question}에 대해 {context}를 참조하여 3문단 이내로 답변하세요.\"},\n",
    "        {\"role\": \"assistant\", \"content\": target_answer}\n",
    "    ]\n",
    "\n",
    "    full_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    \n",
    "    return {\"text\": full_prompt}\n",
    "\n",
    "train_prompts, val_prompts = train_subset.map(generate_prompts_test), val_subset.map(generate_prompts_test)\n",
    "print(train_prompts[0])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "token_lengths = [len(tokenizer.encode(p[\"text\"])) for p in train_prompts] + [len(tokenizer.encode(p[\"text\"])) for p in val_prompts]\n",
    "\n",
    "print(f\"최대 토큰 길이: {np.max(token_lengths)}\")\n",
    "print(f\"평균 토큰 길이: {np.mean(token_lengths):.2f}\")\n",
    "print(f\"95번째 백분위수 (P95): {np.percentile(token_lengths, 95)}\") # 95번째로 큰 데이터의 토큰 수\n",
    "print(f\"99번째 백분위수 (P99): {np.percentile(token_lengths, 99)}\") # 99번째로 큰 데이터의 토큰 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14e0cf8d-41c3-4d2b-a1f0-3df1374bc7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/vsc/.netrc.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vsc/LLM_TUNE/115.법률-규정 텍스트 분석 데이터_고도화_상황에 따른 판례 데이터/wandb/run-20260129_141210-legal_testv4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4' target=\"_blank\">2026-01-29 14:12:04</a></strong> to <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0xe13002aad610>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습을 기록할 wanDB notebook 설정\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"PromptTuning\" # 프로젝트 이름\n",
    "os.environ[\"WANDB_RUN_ID\"] = \"legal_testv4\" # 노트북 고유 ID\n",
    "os.environ[\"WANDB_RESUME\"] = \"allow\" # 해당 노트북에서 학습을 이어서 진행할 것인지\n",
    "\n",
    "wandb.init(\n",
    "    project=os.environ[\"WANDB_PROJECT\"],\n",
    "    id=os.environ[\"WANDB_RUN_ID\"],\n",
    "    resume=os.environ[\"WANDB_RESUME\"],\n",
    "    name=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") # 대시보드에 표시될 이름\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14760be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7954f46a36924df38831227cb4ed00dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Error occurred while packing the dataset. Make sure that your dataset has enough samples to at least yield one packed sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/builder.py:1576\u001b[39m, in \u001b[36mGeneratorBasedBuilder._prepare_split_single\u001b[39m\u001b[34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, job_id)\u001b[39m\n\u001b[32m   1575\u001b[39m _time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1576\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1577\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# old custom builders may not use Key\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/packaged_modules/generator/generator.py:37\u001b[39m, in \u001b[36mGenerator._generate_examples\u001b[39m\u001b[34m(self, **gen_kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m shard_idx, shard_gen_kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(_split_gen_kwargs(gen_kwargs, max_num_jobs=num_shards)):\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mshard_gen_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:626\u001b[39m, in \u001b[36mSFTTrainer._prepare_packed_dataloader.<locals>.data_generator\u001b[39m\u001b[34m(constant_length_iterator)\u001b[39m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdata_generator\u001b[39m(constant_length_iterator):\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m constant_length_iterator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/utils.py:633\u001b[39m, in \u001b[36mConstantLengthDataset.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     buffer.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    634\u001b[39m     buffer_len += \u001b[38;5;28mlen\u001b[39m(buffer[-\u001b[32m1\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mgenerate_prompts\u001b[39m\u001b[34m(examples)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(examples[\u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m])):\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# 각 리스트에서 i번째 데이터를 추출합니다.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     answer = \u001b[38;5;28mstr\u001b[39m(\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m).strip()\n\u001b[32m     10\u001b[39m     question = examples[\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m][i]\n",
      "\u001b[31mIndexError\u001b[39m: string index out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatasetGenerationError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:629\u001b[39m, in \u001b[36mSFTTrainer._prepare_packed_dataloader\u001b[39m\u001b[34m(self, tokenizer, dataset, dataset_text_field, max_seq_length, num_of_sequences, chars_per_token, formatting_func, append_concat_token, add_special_tokens)\u001b[39m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     packed_dataset = \u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconstant_length_iterator\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_length_iterator\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (DatasetGenerationError, SchemaInferenceError) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/arrow_dataset.py:1204\u001b[39m, in \u001b[36mDataset.from_generator\u001b[39m\u001b[34m(generator, features, cache_dir, keep_in_memory, gen_kwargs, num_proc, split, fingerprint, **kwargs)\u001b[39m\n\u001b[32m   1192\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeneratorDatasetInputStream\n\u001b[32m   1194\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGeneratorDatasetInputStream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1204\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/io/generator.py:52\u001b[39m, in \u001b[36mGeneratorDatasetInputStream.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m base_path = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m dataset = \u001b[38;5;28mself\u001b[39m.builder.as_dataset(\n\u001b[32m     60\u001b[39m     split=\u001b[38;5;28mself\u001b[39m.builder.config.split, verification_mode=verification_mode, in_memory=\u001b[38;5;28mself\u001b[39m.keep_in_memory\n\u001b[32m     61\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/builder.py:884\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare\u001b[39m\u001b[34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[39m\n\u001b[32m    883\u001b[39m     prepare_split_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_proc\u001b[39m\u001b[33m\"\u001b[39m] = num_proc\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/builder.py:1634\u001b[39m, in \u001b[36mGeneratorBasedBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[39m\n\u001b[32m   1633\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, **prepare_splits_kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1634\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1637\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_splits_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1638\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/builder.py:947\u001b[39m, in \u001b[36mDatasetBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[39m\n\u001b[32m    945\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    946\u001b[39m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/builder.py:1438\u001b[39m, in \u001b[36mGeneratorBasedBuilder._prepare_split\u001b[39m\u001b[34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[39m\n\u001b[32m   1437\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[32m-> \u001b[39m\u001b[32m1438\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_split_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_prepare_split_args\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1441\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/datasets/builder.py:1617\u001b[39m, in \u001b[36mGeneratorBasedBuilder._prepare_split_single\u001b[39m\u001b[34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, job_id)\u001b[39m\n\u001b[32m   1616\u001b[39m         e = e.__context__\n\u001b[32m-> \u001b[39m\u001b[32m1617\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationError(\u001b[33m\"\u001b[39m\u001b[33mAn error occurred while generating the dataset\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1619\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m (\n\u001b[32m   1620\u001b[39m     job_id,\n\u001b[32m   1621\u001b[39m     \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1630\u001b[39m     ),\n\u001b[32m   1631\u001b[39m )\n",
      "\u001b[31mDatasetGenerationError\u001b[39m: An error occurred while generating the dataset",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m      7\u001b[39m training_args = SFTConfig(\n\u001b[32m      8\u001b[39m     output_dir=\u001b[33m\"\u001b[39m\u001b[33m./SFT\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     save_strategy=\u001b[33m\"\u001b[39m\u001b[33msteps\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     run_name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.now().strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m trainer = \u001b[43mSFTTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerate_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[39m, in \u001b[36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m         message += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + custom_message\n\u001b[32m    100\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:361\u001b[39m, in \u001b[36mSFTTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics, peft_config, dataset_text_field, packing, formatting_func, max_seq_length, infinite, num_of_sequences, chars_per_token, dataset_num_proc, dataset_batch_size, neftune_noise_alpha, model_init_kwargs, dataset_kwargs, eval_packing)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m PartialState().local_main_process_first():\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m train_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m         train_dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpacking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_text_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m            \u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_of_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchars_per_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m            \u001b[49m\u001b[43mremove_unused_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove_unused_columns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m eval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    374\u001b[39m         _multiple = \u001b[38;5;28misinstance\u001b[39m(eval_dataset, \u001b[38;5;28mdict\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:525\u001b[39m, in \u001b[36mSFTTrainer._prepare_dataset\u001b[39m\u001b[34m(self, dataset, tokenizer, packing, dataset_text_field, max_seq_length, formatting_func, num_of_sequences, chars_per_token, remove_unused_columns, append_concat_token, add_special_tokens, skip_prepare_dataset)\u001b[39m\n\u001b[32m    514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._prepare_non_packed_dataloader(\n\u001b[32m    515\u001b[39m         tokenizer,\n\u001b[32m    516\u001b[39m         dataset,\n\u001b[32m   (...)\u001b[39m\u001b[32m    521\u001b[39m         remove_unused_columns,\n\u001b[32m    522\u001b[39m     )\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_packed_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_text_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_of_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchars_per_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mappend_concat_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:633\u001b[39m, in \u001b[36mSFTTrainer._prepare_packed_dataloader\u001b[39m\u001b[34m(self, tokenizer, dataset, dataset_text_field, max_seq_length, num_of_sequences, chars_per_token, formatting_func, append_concat_token, add_special_tokens)\u001b[39m\n\u001b[32m    629\u001b[39m         packed_dataset = Dataset.from_generator(\n\u001b[32m    630\u001b[39m             data_generator, gen_kwargs={\u001b[33m\"\u001b[39m\u001b[33mconstant_length_iterator\u001b[39m\u001b[33m\"\u001b[39m: constant_length_iterator}\n\u001b[32m    631\u001b[39m         )\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (DatasetGenerationError, SchemaInferenceError) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    634\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mError occurred while packing the dataset. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    635\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMake sure that your dataset has enough samples to at least yield one packed sequence.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    636\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m packed_dataset\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Error occurred while packing the dataset. Make sure that your dataset has enough samples to at least yield one packed sequence."
     ]
    }
   ],
   "source": [
    "# 먼저 1 epoch로 훈련 -> 추론이 잘 이루어지는지 확인\n",
    "# 이후 epoch를 늘려 과적합이 일어날 때 까지 학습하는 것이 좋음\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datetime import datetime\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./SFT\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    max_seq_length=1024,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    load_best_model_at_end=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=11,\n",
    "    warmup_steps=1,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=5e-5,\n",
    "    group_by_length=True,\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\"\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=val_subset,\n",
    "    args=training_args,\n",
    "    formatting_func=generate_prompts,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)] # 3번 연속으로 성적이 나쁘면 중단\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e672dbac-5f70-4149-a708-4ba39536b45a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [620/620 2:59:29, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.186900</td>\n",
       "      <td>1.046735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.962100</td>\n",
       "      <td>0.953926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.929190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.913100</td>\n",
       "      <td>0.914811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.872100</td>\n",
       "      <td>0.906348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.903418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>0.901169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.900246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.806900</td>\n",
       "      <td>0.899870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.791700</td>\n",
       "      <td>0.900180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.807700</td>\n",
       "      <td>0.901579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.761800</td>\n",
       "      <td>0.901505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▅▄▅▄▅▅▂▄▁▃▃█</td></tr><tr><td>eval/samples_per_second</td><td>▄▄▄▄▄▄▆▆█▆▆▁</td></tr><tr><td>eval/steps_per_second</td><td>██▁█▁██████▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>█▃▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▆▄▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.90151</td></tr><tr><td>eval/runtime</td><td>127.8985</td></tr><tr><td>eval/samples_per_second</td><td>3.127</td></tr><tr><td>eval/steps_per_second</td><td>1.564</td></tr><tr><td>total_flos</td><td>2.3204562474973594e+17</td></tr><tr><td>train/epoch</td><td>9.92</td></tr><tr><td>train/global_step</td><td>620</td></tr><tr><td>train/grad_norm</td><td>0.84141</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.794</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2026-01-29 01:23:51</strong> at: <a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv3' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv3</a><br> View project at: <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260129_012352-legal_testv3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_save_path = \"./SFT/final\"\n",
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=True) # 이어서 학습을 진행하고 싶은 경우, 가장 마지막 checkpoint-XX를 불러와서 학습이 진행된다\n",
    "\n",
    "trainer.save_model(final_save_path)\n",
    "tokenizer.save_pretrained(final_save_path)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa6f9ed-12a8-46b9-891a-1d6d4f7566cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 추론된 모델 확인\n",
    "# 중요!!! 학습 이후 커널을 내리고 다시 올려야 파인튜닝된 가중치를 모델에 올릴 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f960ed74-2364-4466-9c56-9d699b5915ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import os, torch, json, wandb, subprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig, \n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7ea6a2-5ef9-4d84-9766-fc7f33d9a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 4bit 할 것이냐\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, #bfloat16 or float16\n",
    "    bnb_4bit_quant_type=\"nf4\", # nf4 or fp4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0950899f-4b1c-4ae8-b14e-f6235d6793d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  queued_call()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd09b2bef734adc8d47686d4fd94b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 및 토크나이저 불러오기\n",
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "model_id = \"/home/vsc/LLM/model/EXAONE-3.5-7.8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672d9e5e-2a0e-4488-a811-02fdfef93271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): ExaoneForCausalLM(\n",
       "      (transformer): ExaoneModel(\n",
       "        (wte): Embedding(102400, 4096, padding_idx=0)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-31): 32 x ExaoneBlock(\n",
       "            (ln_1): ExaoneRMSNorm()\n",
       "            (attn): ExaoneAttention(\n",
       "              (attention): ExaoneSdpaAttention(\n",
       "                (rotary): ExaoneRotaryEmbedding()\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (ln_2): ExaoneRMSNorm()\n",
       "            (mlp): ExaoneGatedMLP(\n",
       "              (c_fc_0): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (c_fc_1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (c_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): ExaoneRMSNorm()\n",
       "        (rotary): ExaoneRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_path = \"./SFT/final\"\n",
    "model = PeftModel.from_pretrained(model, adapter_path) # 학습된 LoRA Config를 씌운다\n",
    "model.eval() # 추론 모드로 모델을 바꾼다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcae29ae-d7a0-425b-83cd-6a6699f38c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 || 400 || 200\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "from datasets import Dataset\n",
    "\n",
    "def load_json_files(dir) :\n",
    "    loaded_data = []\n",
    "    for filename in os.listdir(dir) :\n",
    "        if filename.endswith('.json') :\n",
    "            with open(os.path.join(dir, filename), 'r', encoding='utf-8') as f :\n",
    "                loaded_data.append(json.load(f))\n",
    "    \n",
    "    return loaded_data\n",
    "\n",
    "def create_dataset(data) :\n",
    "    dataset_dict = {\n",
    "        \"id\": [],\n",
    "        \"question\": [],\n",
    "        \"context\": [],\n",
    "        \"summary\": [],\n",
    "        \"answer\" : [],\n",
    "    }\n",
    "\n",
    "    for item in data:\n",
    "        dataset_dict[\"id\"].append(item[\"info\"][\"id\"])\n",
    "        dataset_dict[\"question\"].append(item[\"jdgmnInfo\"][0][\"question\"])\n",
    "        dataset_dict[\"context\"].append(item[\"Summary\"][0][\"summ_contxt\"])\n",
    "        dataset_dict[\"summary\"].append(item[\"Summary\"][0][\"summ_pass\"])\n",
    "        dataset_dict[\"answer\"].append(item[\"jdgmnInfo\"][0][\"answer\"])\n",
    "\n",
    "    return Dataset.from_dict(dataset_dict)\n",
    "    \n",
    "extract_dir_list = [\"./3.개방데이터/1.데이터/extract/Training/02.라벨링데이터\", \"./3.개방데이터/1.데이터/extract/Validation/02.라벨링데이터\", \"./3.개방데이터/1.데이터/raw/Training/0.1.원천데이터\"]\n",
    "train_data, val_data = load_json_files(extract_dir_list[0]), load_json_files(extract_dir_list[1])\n",
    "\n",
    "train_dataset = create_dataset(train_data)\n",
    "val_dataset = create_dataset(val_data)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "train_subset = train_dataset.shuffle(seed=seed).select(range(1000))\n",
    "val_subset = val_dataset.shuffle(seed=seed).select(range(400))\n",
    "test_subset = val_dataset.shuffle(seed=seed).select(range(401, 601))\n",
    "\n",
    "print(f\"{len(train_subset)} || {len(val_subset)} || {len(test_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791e331d-da49-4468-9196-7a39411f4e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_legal_answer(question):\n",
    "    system_message = \"당신은 법률 및 규정 관련 전문가입니다. 사용자의 질문에 대해 '긍정'및 '부정', '불명' 여부를 판단한 후, 그에 대한 구체적인 근거를 문맥(context)에서 추출해서 설명하세요.\"\n",
    "    \n",
    "    # 학습 시 사용한 유저 프롬프트: \"사용자의 질문인 {question}에 대해 {context}를 참조하여 3문단 이내로 답변하세요.\"\n",
    "    user_content = f\"사용자의 질문인 {question}에 대해 3문단 이내로 답변하세요.\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False, \n",
    "            repetition_penalty=1.1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d48eefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 및 비교 시작... 총 200개 데이터\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████| 200/200 [16:42<00:00,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[최종 검증 요약]\n",
      "- Label Accuracy: 71.00%\n",
      "- ROUGE-L: 0.0856\n",
      "- BLEU: 0.1632\n",
      "\n",
      "[상세 분류 리포트]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          긍정       0.80      0.72      0.76       119\n",
      "          부정       0.60      0.76      0.67        74\n",
      "          불명       0.00      0.00      0.00         7\n",
      "          실패       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.35      0.37      0.36       200\n",
      "weighted avg       0.70      0.71      0.70       200\n",
      "\n",
      "검증 완료! 로그 파일: ./result/log_without_context.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 유저가 Context를 주지 않을 경우\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher # 텍스트간 유사도 측정 라이브러리\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import evaluate  # Hugging Face evaluate 라이브러리\n",
    "\n",
    "# 1. 지표 로더\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "\n",
    "# 2. 결과 파일 및 통계 초기화\n",
    "output_file_path = \"./result/log_without_context.txt\"\n",
    "os.makedirs(\"./result\", exist_ok=True)\n",
    "\n",
    "all_preds_text = []    # ROUGE/BLEU용 모델 답변\n",
    "all_refs_text = []     # ROUGE/BLEU용 실제 정답\n",
    "y_true_idx = []        # 혼동행렬용 실제 라벨\n",
    "y_pred_idx = []        # 혼동행렬용 예측 라벨\n",
    "\n",
    "label_map = {\"긍정\": 0, \"부정\": 1, \"불명\": 2}\n",
    "correct_labels = 0\n",
    "total_samples = len(test_subset)\n",
    "\n",
    "print(f\"검증 및 비교 시작... 총 {total_samples}개 데이터\")\n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== EXAONE 법률 QA 정답 비교 검증 로그 ===\\n\\n\")\n",
    "\n",
    "    for i, data in enumerate(tqdm(test_subset, desc=\"Evaluating\")):\n",
    "        question = data[\"question\"]\n",
    "        context = data[\"context\"]\n",
    "        actual_label = str(data[\"answer\"]).strip() # 실제 정답 (긍정/부정/불명)\n",
    "        summary = data[\"summary\"]\n",
    "        \n",
    "        if actual_label == \"긍정\":\n",
    "            ground_truth = f\"네 그렇습니다! {summary}에 의하여 질문하신 내용은 옳습니다.\"\n",
    "        elif actual_label == \"부정\":\n",
    "            ground_truth = f\"아니요, 그렇지 않습니다! {summary}에 의하면 상충되는 내용이 있으므로 질문하신 내용은 옳지 않습니다.\"\n",
    "        else:\n",
    "            ground_truth = f\"확실하지 않습니다만, {summary}에 적힌 내용을 근거로 판단해 볼 수 있을 것 같습니다.\"\n",
    "\n",
    "        # 모델 답변 생성\n",
    "        generated_answer = generate_legal_answer(question)\n",
    "\n",
    "        actual_idx = label_map.get(actual_label, 3)\n",
    "        if \"네\" in generated_answer[:10]: pred_idx = 0\n",
    "        elif \"아니요\" in generated_answer[:10]: pred_idx = 1\n",
    "        elif \"확실하지\" in generated_answer[:10]: pred_idx = 2\n",
    "        else: pred_idx = 3 # 분류 실패\n",
    "\n",
    "        y_true_idx.append(actual_idx)\n",
    "        y_pred_idx.append(pred_idx)\n",
    "        if actual_idx == pred_idx: correct_labels += 1\n",
    "\n",
    "        all_preds_text.append(generated_answer)\n",
    "        all_refs_text.append(ground_truth)\n",
    "\n",
    "        similarity = SequenceMatcher(None, ground_truth, generated_answer).ratio()\n",
    "\n",
    "        # 로그 기록\n",
    "        f.write(f\"[{i+1}번 데이터] | Label 일치: {'O' if actual_idx == pred_idx else 'X'} | 유사도: {similarity:.2f}\\n\")\n",
    "        f.write(f\"질문: {question}\\n\")\n",
    "        f.write(f\"실제 정답: {ground_truth}\\n\")\n",
    "        f.write(f\"모델 답변: {generated_answer}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    rouge_results = rouge_metric.compute(predictions=all_preds_text, references=all_refs_text)\n",
    "    bleu_results = bleu_metric.compute(predictions=all_preds_text, references=all_refs_text)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_true_idx, y_pred_idx, labels=[0, 1, 2, 3])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='RdPu', \n",
    "                xticklabels=[\"pos\", \"neg\", \"non\", \"fail\"], \n",
    "                yticklabels=[\"pos\", \"neg\", \"non\", \"fail\"])\n",
    "    plt.title(\"Without Context\")\n",
    "    plt.savefig(\"./result/confusion_matrix_without_context.png\")\n",
    "\n",
    "    # 5. 최종 통계 기록\n",
    "    accuracy = (correct_labels / total_samples) * 100\n",
    "    report = classification_report(y_true_idx, y_pred_idx, \n",
    "                                   target_names=['긍정', '부정', '불명', '실패'], labels=[0, 1, 2, 3])\n",
    "    summary_msg = (\n",
    "        f\"\\n[최종 검증 요약]\\n\"\n",
    "        f\"- Label Accuracy: {accuracy:.2f}%\\n\"\n",
    "        f\"- ROUGE-L: {rouge_results['rougeL']:.4f}\\n\"\n",
    "        f\"- BLEU: {bleu_results['bleu']:.4f}\\n\"\n",
    "        f\"\\n[상세 분류 리포트]\\n{report}\"\n",
    "    )\n",
    "    \n",
    "    print(summary_msg)\n",
    "    f.write(summary_msg)\n",
    "\n",
    "print(f\"검증 완료! 로그 파일: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84135781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_legal_answer_with_context(question, context):\n",
    "    # 학습 시와 동일한 system_message\n",
    "    system_message = \"당신은 법률 및 규정 관련 전문가입니다. 사용자의 질문에 대해 '긍정'및 '부정', '불명' 여부를 판단한 후, 그에 대한 구체적인 근거를 문맥(context)에서 추출해서 설명하세요.\"\n",
    "    \n",
    "    # 학습 시의 user content와 완벽히 일치 (조사, 띄어쓰기 포함)\n",
    "    user_content = f\"사용자의 질문인 {question}에 대해 {context}를 참조하여 3문단 이내로 답변하세요.\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False,\n",
    "            repetition_penalty=1.1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
    "    return response.strip()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab16fdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 및 비교 시작... 총 200개 데이터\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████████████| 200/200 [15:12<00:00,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[최종 검증 요약]\n",
      "- Label Accuracy: 88.50%\n",
      "- ROUGE-L: 0.1913\n",
      "- BLEU: 0.4310\n",
      "\n",
      "[상세 분류 리포트]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          긍정       0.90      0.93      0.92       119\n",
      "          부정       0.86      0.89      0.87        74\n",
      "          불명       0.00      0.00      0.00         7\n",
      "          실패       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.44      0.46      0.45       200\n",
      "weighted avg       0.85      0.89      0.87       200\n",
      "\n",
      "검증 완료! 로그 파일: ./result/log_with_context.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 유저가 Context를 주는 경우\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher # 텍스트간 유사도 측정 라이브러리\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import evaluate  # Hugging Face evaluate 라이브러리\n",
    "\n",
    "# 1. 지표 로더\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "\n",
    "# 2. 결과 파일 및 통계 초기화\n",
    "output_file_path = \"./result/log_with_context.txt\"\n",
    "os.makedirs(\"./result\", exist_ok=True)\n",
    "\n",
    "all_preds_text = []    # ROUGE/BLEU용 모델 답변\n",
    "all_refs_text = []     # ROUGE/BLEU용 실제 정답\n",
    "y_true_idx = []        # 혼동행렬용 실제 라벨\n",
    "y_pred_idx = []        # 혼동행렬용 예측 라벨\n",
    "\n",
    "label_map = {\"긍정\": 0, \"부정\": 1, \"불명\": 2}\n",
    "correct_labels = 0\n",
    "total_samples = len(test_subset)\n",
    "\n",
    "print(f\"검증 및 비교 시작... 총 {total_samples}개 데이터\")\n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== EXAONE 법률 QA 정답 비교 검증 로그 ===\\n\\n\")\n",
    "\n",
    "    for i, data in enumerate(tqdm(test_subset, desc=\"Evaluating\")):\n",
    "        question = data[\"question\"]\n",
    "        context = data[\"context\"]\n",
    "        actual_label = str(data[\"answer\"]).strip() # 실제 정답 (긍정/부정/불명)\n",
    "        summary = data[\"summary\"]\n",
    "        \n",
    "        if actual_label == \"긍정\":\n",
    "            ground_truth = f\"네 그렇습니다! {summary}에 의하여 질문하신 내용은 옳습니다.\"\n",
    "        elif actual_label == \"부정\":\n",
    "            ground_truth = f\"아니요, 그렇지 않습니다! {summary}에 의하면 상충되는 내용이 있으므로 질문하신 내용은 옳지 않습니다.\"\n",
    "        else:\n",
    "            ground_truth = f\"확실하지 않습니다만, {summary}에 적힌 내용을 근거로 판단해 볼 수 있을 것 같습니다.\"\n",
    "\n",
    "        # 모델 답변 생성\n",
    "        generated_answer = generate_legal_answer_with_context(question, context)\n",
    "\n",
    "        actual_idx = label_map.get(actual_label, 3)\n",
    "        if \"네\" in generated_answer[:10]: pred_idx = 0\n",
    "        elif \"아니요\" in generated_answer[:10]: pred_idx = 1\n",
    "        elif \"확실하지\" in generated_answer[:10]: pred_idx = 2\n",
    "        else: pred_idx = 3 # 분류 실패\n",
    "\n",
    "        y_true_idx.append(actual_idx)\n",
    "        y_pred_idx.append(pred_idx)\n",
    "        if actual_idx == pred_idx: correct_labels += 1\n",
    "\n",
    "        all_preds_text.append(generated_answer)\n",
    "        all_refs_text.append(ground_truth)\n",
    "\n",
    "        similarity = SequenceMatcher(None, ground_truth, generated_answer).ratio()\n",
    "\n",
    "        # 로그 기록\n",
    "        f.write(f\"[{i+1}번 데이터] | Label 일치: {'O' if actual_idx == pred_idx else 'X'} | 유사도: {similarity:.2f}\\n\")\n",
    "        f.write(f\"질문: {question}\\n\")\n",
    "        f.write(f\"실제 정답: {ground_truth}\\n\")\n",
    "        f.write(f\"모델 답변: {generated_answer}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    rouge_results = rouge_metric.compute(predictions=all_preds_text, references=all_refs_text)\n",
    "    bleu_results = bleu_metric.compute(predictions=all_preds_text, references=all_refs_text)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_true_idx, y_pred_idx, labels=[0, 1, 2, 3])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='RdPu', \n",
    "                xticklabels=[\"pos\", \"neg\", \"non\", \"fail\"], \n",
    "                yticklabels=[\"pos\", \"neg\", \"non\", \"fail\"])\n",
    "    plt.title(\"With Context\")\n",
    "    plt.savefig(\"./result/confusion_matrix_with_context.png\")\n",
    "\n",
    "    # 5. 최종 통계 기록\n",
    "    accuracy = (correct_labels / total_samples) * 100\n",
    "    report = classification_report(y_true_idx, y_pred_idx, \n",
    "                                   target_names=['긍정', '부정', '불명', '실패'], labels=[0, 1, 2, 3])\n",
    "    summary_msg = (\n",
    "        f\"\\n[최종 검증 요약]\\n\"\n",
    "        f\"- Label Accuracy: {accuracy:.2f}%\\n\"\n",
    "        f\"- ROUGE-L: {rouge_results['rougeL']:.4f}\\n\"\n",
    "        f\"- BLEU: {bleu_results['bleu']:.4f}\\n\"\n",
    "        f\"\\n[상세 분류 리포트]\\n{report}\"\n",
    "    )\n",
    "    \n",
    "    print(summary_msg)\n",
    "    f.write(summary_msg)\n",
    "\n",
    "print(f\"검증 완료! 로그 파일: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62898087-f28f-46ce-815d-37849b2e0d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 검증 결과 리포트\n",
      "----------------------\n",
      "✅ 전체 모델 답변 수: 200개\n",
      "⚠️ 지시 사항 누수 발생: 65개\n",
      "📈 누수 발생률: 32.50%\n",
      "\n",
      "📊 검증 결과 리포트\n",
      "----------------------\n",
      "✅ 전체 모델 답변 수: 200개\n",
      "⚠️ 지시 사항 누수 발생: 0개\n",
      "📈 누수 발생률: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_instruction_leakage(file_path):    \n",
    "    leakage_count = 0\n",
    "    total_answers = 0\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "            # '모델 답변:' 이후부터 다음 구분선(---) 혹은 파일 끝까지의 텍스트를 추출\n",
    "            model_answers = re.findall(r\"모델 답변:\\s*(.*?)(?=\\n-{10,}|\\n===|\\Z)\", content, re.DOTALL)\n",
    "            \n",
    "            total_answers = len(model_answers)\n",
    "            \n",
    "            for answer in model_answers:\n",
    "                # 앞뒤 공백 제거 후 타겟 문구로 끝나는지 확인\n",
    "                clean_answer = answer.strip()\n",
    "                if re.search(r\"를 참조하여 \\d+문단 이내로 답변하세요\\.\\s*$\", clean_answer):\n",
    "                    leakage_count += 1\n",
    "                    \n",
    "        print(f\"📊 검증 결과 리포트\")\n",
    "        print(f\"----------------------\")\n",
    "        print(f\"✅ 전체 모델 답변 수: {total_answers}개\")\n",
    "        print(f\"⚠️ 지시 사항 누수 발생: {leakage_count}개\")\n",
    "        \n",
    "        if total_answers > 0:\n",
    "            leakage_rate = (leakage_count / total_answers) * 100\n",
    "            print(f\"📈 누수 발생률: {leakage_rate:.2f}%\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 파일을 찾을 수 없습니다: {file_path}\")\n",
    "\n",
    "# 파일 경로를 넣고 실행하세요\n",
    "count_instruction_leakage(\"./result/log_without_context.txt\")\n",
    "print()\n",
    "count_instruction_leakage(\"./result/log_with_context.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a910c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace에 Model, Tokenizer 및 LoRA 가중치 load / unload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5327ca35-1ca9-4aa4-972c-7523d7d8c822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  queued_call()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e5a1d9e63045288ace4ab4b89253e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9817ee91f54b6fb9d1e4d16ae2f3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504bed9af33b444fb4947af369b9c732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/JungSeong2/QA-Law-Adapter/commit/b9e87128a6b8196943b8bd1541a4249f33c072ab', commit_message='v1.0: 토크나이저 설정 업로드', commit_description='', oid='b9e87128a6b8196943b8bd1541a4249f33c072ab', pr_url=None, repo_url=RepoUrl('https://huggingface.co/JungSeong2/QA-Law-Adapter', endpoint='https://huggingface.co', repo_type='model', repo_id='JungSeong2/QA-Law-Adapter'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LoRA 가중치만 upload\n",
    "from peft import PeftModel\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments,\n",
    ")\n",
    "import torch\n",
    "\n",
    "model_id = \"/home/vsc/LLM/model/EXAONE-3.5-7.8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 4bit 할 것이냐\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, #bfloat16 or float16\n",
    "    bnb_4bit_quant_type=\"nf4\", # nf4 or fp4\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# 1. 학습 완료 후 저장된 어댑터 경로\n",
    "adapter_path = \"/home/vsc/LLM_TUNE/115.법률-규정 텍스트 분석 데이터_고도화_상황에 따른 판례 데이터/SFT/final\"\n",
    "repo_id = \"JungSeong2/QA-Law-Adapter\" # 허깅페이스 저장소 이름\n",
    "\n",
    "# 2. 토크나이저와 어댑터 모델 로드 (또는 학습 중인 trainer.model 사용)\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "\n",
    "# 3. 어댑터 가중치만 업로드\n",
    "model.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    commit_message=\"v1.0: First FineTuned\",\n",
    "    revision=\"v1.0\" # v1.0 브랜치에 해당 어댑터를 업로드\n",
    ")\n",
    "\n",
    "tokenizer.push_to_hub(\n",
    "    repo_id,\n",
    "    commit_message=\"v1.0: 토크나이저 설정 업로드\",\n",
    "    revision=\"v1.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e40768a-af54-4360-8c0b-d00dd2d040de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\n",
      "' }}{% endif %}{{ '[|' + message['role'] + '|]' + message['content'] }}{% if message['role'] == 'user' %}{{ '\n",
      "' }}{% else %}{{ '[|endofturn|]\n",
      "' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '[|assistant|]' }}{% endif %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "863a77e4-9a09-4c56-b5d3-131cebfa1ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0cb80fe7daa412e9f9661c662dfa864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082adb4fc06141f79b8a515e63c7ffb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/700 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee60203537a44bcbcb090cf590c4bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/54.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 업로드한 모델 불러오기\n",
    "model_id = \"/home/vsc/LLM/model/EXAONE-3.5-7.8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 4bit 할 것이냐\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, #bfloat16 or float16\n",
    "    bnb_4bit_quant_type=\"nf4\", # nf4 or fp4\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "repo_id = \"JungSeong2/QA-Law-Adapter\"\n",
    "model = PeftModel.from_pretrained(\n",
    "    model, \n",
    "    repo_id, \n",
    "    revision=\"v1.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec40dcc4-ad01-4a46-8544-79dfd4c1b0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): ExaoneForCausalLM(\n",
      "      (transformer): ExaoneModel(\n",
      "        (wte): Embedding(102400, 4096, padding_idx=0)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-31): 32 x ExaoneBlock(\n",
      "            (ln_1): ExaoneRMSNorm()\n",
      "            (attn): ExaoneAttention(\n",
      "              (attention): ExaoneSdpaAttention(\n",
      "                (rotary): ExaoneRotaryEmbedding()\n",
      "                (k_proj): lora.Linear4bit(\n",
      "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.05, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (v_proj): lora.Linear4bit(\n",
      "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.05, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (q_proj): lora.Linear4bit(\n",
      "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.05, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (out_proj): lora.Linear4bit(\n",
      "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.05, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (ln_2): ExaoneRMSNorm()\n",
      "            (mlp): ExaoneGatedMLP(\n",
      "              (c_fc_0): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (c_fc_1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (c_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "              (act): SiLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): ExaoneRMSNorm()\n",
      "        (rotary): ExaoneRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0babcf18-a72d-4430-adc4-25b0583f0ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68470e8bdc134db19e9961e4d3f26ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d825a38ddf1c4d0fa14c7861d3b4676c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6cdbcb04b994d42aa64d9e54cf40e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f4a29fd6fb437ab0e2ac2c309f01ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/JungSeong2/QA_Law_Test/commit/0eece6eab2e65b6efbce93dffbf72d7b81659873', commit_message='Upload tokenizer', commit_description='', oid='0eece6eab2e65b6efbce93dffbf72d7b81659873', pr_url=None, repo_url=RepoUrl('https://huggingface.co/JungSeong2/QA_Law_Test', endpoint='https://huggingface.co', repo_type='model', repo_id='JungSeong2/QA_Law_Test'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습된 LoRA 가중치를 모델에 합친 채로 배포하고 싶을 경우 (파인튜닝이 끝났을 때)\n",
    "\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_id = \"/home/vsc/LLM/model/EXAONE-3.5-7.8B-Instruct\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 4bit 할 것이냐\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, #bfloat16 or float16\n",
    "    bnb_4bit_quant_type=\"nf4\", # nf4 or fp4\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "adapter_path = \"/home/vsc/LLM_TUNE/115.법률-규정 텍스트 분석 데이터_고도화_상황에 따른 판례 데이터/SFT/final\"\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "\n",
    "merged_model = model.merge_and_unload()\n",
    "\n",
    "repo_id = \"JungSeong2/QA_Law_Test\"\n",
    "merged_model.push_to_hub(repo_id)\n",
    "tokenizer.push_to_hub(repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d028f3e-be9e-4c32-a57f-ffe3ef17c4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QA",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
