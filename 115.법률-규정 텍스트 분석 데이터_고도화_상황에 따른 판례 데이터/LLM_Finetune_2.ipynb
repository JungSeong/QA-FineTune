{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63df3b4",
   "metadata": {},
   "source": [
    "참고 : https://zero-ai.tistory.com/62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eceafe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능 여부: True\n",
      "GPU 이름: NVIDIA GB10\n",
      "CUDA 버전: 13.0\n",
      "PyTorch 버전: <module 'torch.version' from '/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/version.py'>\n",
      "bf16 지원 여부: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA 사용 가능 여부: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "print(f\"PyTorch 버전: {torch.version}\")\n",
    "print(f\"bf16 지원 여부: {torch.cuda.is_bf16_supported()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6440e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O : 성공 : TL_10.개인정보.ICT.zip\n",
      "O : 성공 : TL_05.행정.zip\n",
      "X : 실패 (파일 깨짐): TL_01.민사.zip (크기: 18409624 bytes)\n",
      "O : 성공 : TL_06.기업.zip\n",
      "O : 성공 : TL_02.가사.zip\n",
      "O : 성공 : TL_04.형사B(일반형).zip\n",
      "O : 성공 : TL_08.특허.저작권.zip\n",
      "O : 성공 : TL_07.근로자.zip\n",
      "O : 성공 : TL_09.금융조세.zip\n",
      "O : 성공 : TL_03.형사A(생활형).zip\n",
      "O : 성공 : VL_02.가사.zip\n",
      "O : 성공 : VL_10.개인정보.ICT.zip\n",
      "O : 성공 : VL_07.근로자.zip\n",
      "O : 성공 : VL_09.금융조세.zip\n",
      "O : 성공 : VL_05.행정.zip\n",
      "O : 성공 : VL_08.특허.저작권.zip\n",
      "O : 성공 : VL_03.형사A(생활형).zip\n",
      "O : 성공 : VL_01.민사.zip\n",
      "O : 성공 : VL_04.형사B(일반형).zip\n",
      "O : 성공 : VL_06.기업.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "target_dir_list = [\"./3.개방데이터/1.데이터/Training/02.라벨링데이터\", \"./3.개방데이터/1.데이터/Validation/02.라벨링데이터\"]\n",
    "extract_dir_list = [\"./3.개방데이터/1.데이터/extract/Training/02.라벨링데이터\", \"./3.개방데이터/1.데이터/extract/Validation/02.라벨링데이터\", \"./3.개방데이터/1.데이터/raw/Training/0.1.원천데이터\"]\n",
    "\n",
    "if not os.path.exists(extract_dir_list[0]):\n",
    "    os.makedirs(extract_dir_list[0])\n",
    "if not os.path.exists(extract_dir_list[1]):\n",
    "    os.makedirs(extract_dir_list[1])\n",
    "\n",
    "for target_dir, extract_dir in zip(target_dir_list, extract_dir_list):\n",
    "    for file in os.listdir(target_dir):\n",
    "        if file.endswith(\".zip\"):\n",
    "            file_path = os.path.join(target_dir, file)\n",
    "\n",
    "            try :\n",
    "                with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "                    zip_ref.extractall(extract_dir)\n",
    "                    print(f\"O : 성공 : {file}\")\n",
    "            except zipfile.BadZipFile :\n",
    "                file_size = os.path.getsize(file_path)\n",
    "                print(f\"X : 실패 (파일 깨짐): {file} (크기: {file_size} bytes)\")\n",
    "        \n",
    "            except Exception as e:\n",
    "                print(f\"기타 에러 ({file}): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7b9f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O : 성공 : 01.원천데이터\\TS_1.판례_10.개인정보.ICT.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_10.개인정보.ICT.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_06.기업.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_05.행정.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_05.행정.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_09.금융조세.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_04.형사B(일반형).zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_02.가사.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_07.근로자.zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_08.특허.저작권.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_09.금융조세.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_07.근로자.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_08.특허.저작권.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_03.형사A(생활형).zip\n",
      "O : 성공 : 01.원천데이터\\TS_2.심결례_01.민사.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_06.기업.zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_04.형사B(일반형).zip\n",
      "O : 성공 : 01.원천데이터\\TS_1.판례_01.민사.zip\n"
     ]
    }
   ],
   "source": [
    "raw_dir_list = [\"./3.개방데이터/1.데이터/Training/01.원천데이터\"]\n",
    "\n",
    "if not os.path.exists(raw_dir_list[0]):\n",
    "    os.makedirs(raw_dir_list[0])\n",
    "\n",
    "for file in os.listdir(raw_dir_list[0]):\n",
    "    if file.endswith(\".zip\"):\n",
    "        file_path = os.path.join(raw_dir_list[0], file)\n",
    "\n",
    "        try :\n",
    "            with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(extract_dir_list[2])\n",
    "                print(f\"O : 성공 : {file}\")\n",
    "        except zipfile.BadZipFile :\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"X : 실패 (파일 깨짐): {file} (크기: {file_size} bytes)\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"기타 에러 ({file}): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f912885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 셋 전처리\n",
    "\n",
    "import json, os\n",
    "from datasets import Dataset\n",
    "\n",
    "def load_json_files(dir) :\n",
    "    loaded_data = []\n",
    "    for filename in os.listdir(dir) :\n",
    "        if filename.endswith('.json') :\n",
    "            with open(os.path.join(dir, filename), 'r', encoding='utf-8') as f :\n",
    "                loaded_data.append(json.load(f))\n",
    "    \n",
    "    return loaded_data\n",
    "\n",
    "def create_dataset(data) :\n",
    "    dataset_dict = {\n",
    "        \"id\": [],\n",
    "        \"question\": [],\n",
    "        \"context\": [],\n",
    "        \"summary\": [],\n",
    "        \"answer\" : [],\n",
    "    }\n",
    "\n",
    "    for item in data:\n",
    "        dataset_dict[\"id\"].append(item[\"info\"][\"id\"])\n",
    "        dataset_dict[\"question\"].append(item[\"jdgmnInfo\"][0][\"question\"])\n",
    "        dataset_dict[\"context\"].append(item[\"Summary\"][0][\"summ_contxt\"])\n",
    "        dataset_dict[\"summary\"].append(item[\"Summary\"][0][\"summ_pass\"])\n",
    "        dataset_dict[\"answer\"].append(item[\"jdgmnInfo\"][0][\"answer\"])\n",
    "\n",
    "    return Dataset.from_dict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9ff410",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dir_list = [\"./3.개방데이터/1.데이터/extract/Training/02.라벨링데이터\", \"./3.개방데이터/1.데이터/extract/Validation/02.라벨링데이터\", \"./3.개방데이터/1.데이터/raw/Training/0.1.원천데이터\"]\n",
    "train_data, val_data = load_json_files(extract_dir_list[0]), load_json_files(extract_dir_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "498262bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 || 400 || 200\n"
     ]
    }
   ],
   "source": [
    "# 일부 데이터 셋으로 테스트\n",
    "train_dataset = create_dataset(train_data)\n",
    "val_dataset = create_dataset(val_data)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "train_subset = train_dataset.shuffle(seed=seed).select(range(1000))\n",
    "val_subset = val_dataset.shuffle(seed=seed).select(range(400))\n",
    "test_subset = val_dataset.shuffle(seed=seed).select(range(401, 601))\n",
    "\n",
    "print(f\"{len(train_subset)} || {len(val_subset)} || {len(test_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074a3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 학습 시킬 모델 불러오기\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import os, torch, json, wandb, subprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig, \n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b232b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양자화 설정\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 모델 가중치를 4bit로 불러오기\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, #bfloat16 or float16\n",
    "    bnb_4bit_quant_type=\"nf4\", # nf4 or fp4d\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a33ff38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41462dd64164e659d14cbf6435fc80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExaoneForCausalLM(\n",
      "  (transformer): ExaoneModel(\n",
      "    (wte): Embedding(102400, 4096, padding_idx=0)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-31): 32 x ExaoneBlock(\n",
      "        (ln_1): ExaoneRMSNorm()\n",
      "        (attn): ExaoneAttention(\n",
      "          (attention): ExaoneSdpaAttention(\n",
      "            (rotary): ExaoneRotaryEmbedding()\n",
      "            (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "            (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "            (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "            (out_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "        )\n",
      "        (ln_2): ExaoneRMSNorm()\n",
      "        (mlp): ExaoneGatedMLP(\n",
      "          (c_fc_0): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (c_fc_1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (c_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): ExaoneRMSNorm()\n",
      "    (rotary): ExaoneRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 및 토크나이저 불러오기\n",
    "\n",
    "model_id = \"/home/vsc/LLM/model/EXAONE-3.5-7.8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map={\"\": torch.cuda.current_device()}\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de923173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k_proj', 'c_fc_1', 'c_fc_0', 'out_proj', 'q_proj', 'v_proj', 'c_proj']\n"
     ]
    }
   ],
   "source": [
    "# LoRA를 붙힐 레이어의 명칭을 찾아주는 코드\n",
    "\n",
    "def find_all_linear_names(model):\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)\n",
    " \n",
    "modules = find_all_linear_names(model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dabce7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules={'out_proj', 'k_proj', 'q_proj', 'v_proj'}, lora_alpha=16, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False))\n"
     ]
    }
   ],
   "source": [
    "# 어떤 부분을 학습하냐에 따라서도 결과 값이 달라짐\n",
    "modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"]\n",
    "\n",
    "# 변경 가능한 파라미터들\n",
    "peft_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\", #CAUSAL_LM, FEATURE_EXTRACTION, QUESTION_ANS, SEQ_2_SEQ_LM, SEQ_CLS, TOKEN_CLS.\n",
    "    inference_mode=False, # 학습 중에는 False로 두어야 가중치 업데이트 가능\n",
    "    r=16, # r은 보통 2의 배수로 두는데, r이 클수록 학습 가능한 파라미터의 수가 더 많아짐\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=modules\n",
    ")\n",
    "\n",
    "print(peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce8e3fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13,631,488 || all params: 7,832,080,384 || trainable%: 0.1740\n"
     ]
    }
   ],
   "source": [
    "# 전체 파라미터 중 일부만 업데이트 되는 것을 확인할 수 있음\n",
    "\n",
    "model = prepare_model_for_kbit_training(model) # 양자화된 모델을 학습 가능한 상태로 준비시킴\n",
    "model = get_peft_model(model, peft_config) # 실제 PEFT 구조를 모델에 입힘\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2cd6e48-9b99-43f6-a601-08987e7dd1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 41000982, 'question': '입찰에서 관련 시장은 각 입찰별로 특정 상품·용역에 대한 구매 물량·금액이 정해져 있고 해당 상품·용역은 낙찰사로 결정된 특정 사업자만이 공급을 담당하게 된다는 점에서 각 개별 입찰 건을 하나의 시장으로 보는 것이 타당한가?', 'context': '<!--각주-->18) 입찰 시장은 각 입찰별로 특정 상품·용역에 대한 구매 물량·금액이 정해져 있고 해당 상품·용역은 낙찰사로 결정된 특정 사업자만이 공급을 담당하게 되므로, 입찰에서 관련시장은 각 개별 입찰 건을 하나의 시장으로 보는 것이 타당하다.\\n19) 피심인 한진의 석○○ 차장은 “적격심사제의 특성상 합의에 참여하지 않은 경쟁자들의 존재로 인해 낙찰은 담보되어 있지 않았지만, 최대한 협조사들을 동원하여 당사 판단 하에 낙찰 가능성이 가장 높은 투찰가격을 당사에게 배분하고 당사보다는 높은 가격이지만 그 다음으로 낙찰가능성이 있는 가격을 순차적으로 다른 들러리사에게 배분하여 투찰하도록 함으로써 당사의 낙찰 확률을 높일 목적으로 합의를 하였습니다.”라고 진술하였다(소갑 제7호증 참조).', 'summary': '입찰 시장은 각 입찰별로 특정 상품·용역에 대한 구매 물량·금액이 정해져 있고 해당 상품·용역은 낙찰사로 결정된 특정 사업자만이 공급을 담당하게 되므로, 입찰에서 관련시장은 각 개별 입찰 건을 하나의 시장으로 보는 것이 타당하다.', 'answer': '긍정'}\n",
      "{'id': 43014283, 'question': '미성년자를 약취한 후 강간 목적으로 상해 등을 가하고 나아가 강간 및 살인미수를 범한 경우, 약취한 미성년자에 대한 상해 등으로 인한 특정범죄 가중처벌 등에 관한 법률 위반죄와 미성년자에 대한 강간 및 살인미수행위로 인한 성폭력범죄의 처벌 등에 관한 특례법 위반죄는 서로 실체적 경합범 관계에 있는가?', 'context': '미성년자인 피해자를 약취한 후에 강간을 목적으로 피해자에게 가혹한 행위 및 상해를 가하고 나아가 그 피해자에 대한 강간 및 살인미수를 범하였다면, 이에 대하여는 약취한 미성년자에 대한 상해 등으로 인한 특정범죄 가중처벌 등에 관한 법률 위반죄 및 미성년자인 피해자에 대한 강간 및 살인미수행위로 인한 성폭력범죄의 처벌 등에 관한 특례법 위반죄가 각 성립하고, 설령 상해의 결과가 피해자에 대한 강간 및 살인미수행위 과정에서 발생한 것이라 하더라도 위 각 죄는 서로 형법 제37조 전단의 실체적 경합범 관계에 있다.', 'summary': '미성년자를 약취한 후 강간 목적으로 상해 등을 가하고 나아가 강간 및 살인미수를 범한 경우, 특정범죄 가중처벌 등에 관한 법률 위반죄와 성폭력범죄의 처벌 등에 관한 특례법 위반죄는 각 성립하여, 각 죄는 실체적 경합범 관계에 있다.', 'answer': '긍정'}\n",
      "{'id': 42031401, 'question': '행정소송에 관하여 고등법원이 아닌 제1심 법원이 선고한 종국판결에 대하여는 종국판결 뒤에 양쪽 당사자가 상고할 권리를 유보하고 항소를 하지 않기로 합의한 때에 한하여 비약적 상고를 할 수 있는가?', 'context': '행정소송법 제8조 제2항에 의하여 준용되는 민사소송법 제422조 제2항, 제390조 제1항 단서에 의하면, 행정소송에 관하여 고등법원이 아닌 제1심 법원이 선고한 종국판결에 대하여는 종국판결 뒤에 양쪽 당사자가 상고할 권리를 유보하고 항소를 하지 아니하기로 합의한 때에 한하여 비약적 상고를 할 수 있다(대법원 2003. 2. 11. 선고 2002두9582 판결 참조). 그리고 이 경우 위 합의에는 민사소송법 제390조 제2항에 의하여 같은 법 제29조 제2항의 규정이 준용되는 결과 그 합의는 반드시 서면으로 하도록 되어 있다(대법원 2013. 12. 12. 선고 2013다67921 판결 참조). 그런데 이 사건에서 원고(선정당사자)는 제1심 판결에 대하여 비약적 상고를 하면서 민사소송법 제390조 제1항 단서의 합의에 관한 서면을 제출한 바 없으므로 이 사건 비약적 상고는 부적법한 것으로서 그 흠결을 보정할 수 없는 경우라고 할 것이다.', 'summary': '행정소송에 관하여 고등법원이 아닌 제1심 법원이 선고한 종국판결에 대하여는 종국판결 뒤에 양쪽 당사자가 상고할 권리를 유보하고 항소를 하지 아니하기로 합의한 때에 한하여 비약적 상고를 할 수 있다. 그리고 이 경우 위 합의는 민사소송법에 의하여 반드시 서면으로 하도록 되어 있다.', 'answer': '긍정'}\n"
     ]
    }
   ],
   "source": [
    "print(train_subset[0])\n",
    "print(train_subset[1])\n",
    "print(train_subset[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6942527f-b97e-4571-9fef-8fec269ad9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompts(examples):\n",
    "    prompt_list = []\n",
    "    system_message = (\n",
    "        \"당신은 법률 전문가입니다. 주어진 [근거 문맥]만을 바탕으로 사용자의 질문에 답하십시오. \"\n",
    "        \"답변은 반드시 '긍정', '부정', '불명' 중 하나로 결론을 내린 뒤, 그 이유를 설명해야 합니다.\"\n",
    "    )\n",
    "\n",
    "    for i in range(len(examples['question'])):\n",
    "        # 각 리스트에서 i번째 데이터를 추출합니다.\n",
    "        answer = str(examples[\"answer\"][i]).strip()\n",
    "        question = examples[\"question\"][i]\n",
    "        context = examples[\"context\"][i]\n",
    "        summary = examples[\"summary\"][i]\n",
    "\n",
    "        # 사용자님의 정답 생성 로직\n",
    "        if answer == \"긍정\":\n",
    "            target_answer = f\"네 그렇습니다! {summary}에 의하여 질문하신 내용은 옳습니다.\"\n",
    "        elif answer == \"부정\":\n",
    "            target_answer = f\"아니요, 그렇지 않습니다! {summary}에 의하면 상충되는 내용이 있으므로 질문하신 내용은 옳지 않습니다.\"\n",
    "        elif answer == \"불명\":\n",
    "            target_answer = f\"확실하지 않습니다만, {summary}에 적힌 내용을 근거로 판단해 볼 수 있을 것 같습니다.\"\n",
    "        else:\n",
    "            target_answer = f\"해당 사안에 대해서는 제공된 근거({summary})를 바탕으로 판단이 필요합니다.\"\n",
    "\n",
    "        user_content = (\n",
    "            f\"### [근거 문맥]\\n{context}\\n\\n\"\n",
    "            f\"### [사용자 질문]\\n{question}\\n\\n\"\n",
    "            f\"### [지시 사항]\\n\"\n",
    "            f\"1. 문맥을 바탕으로 긍정/부정/불명을 판단할 것.\\n\"\n",
    "            f\"2. 3문단 이내로 답변할 것.\\n\"\n",
    "            f\"3. 답변 끝에 지시 사항을 반복하지 말 것.\"\n",
    "        )\n",
    "\n",
    "        # 채팅 템플릿 구성\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "            {\"role\": \"assistant\", \"content\": target_answer}\n",
    "        ]\n",
    "\n",
    "        full_prompt = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        \n",
    "        prompt_list.append(full_prompt)\n",
    "    \n",
    "    return prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ce8f6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0680a2182e4a5789a756884875dd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305ca58441364925a52f3299c668734e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 토큰 길이: 1282\n",
      "평균 토큰 길이: 575.02\n",
      "95번째 백분위수 (P95): 875.0\n",
      "99번째 백분위수 (P99): 1027.02\n"
     ]
    }
   ],
   "source": [
    "# max_length 결정 (GPU Util을 최적화 하기 위함)\n",
    "\n",
    "def generate_prompts_test(example) :\n",
    "    system_message = (\n",
    "        \"당신은 법률 전문가입니다. 주어진 [근거 문맥]만을 바탕으로 사용자의 질문에 답하십시오. \"\n",
    "        \"답변은 반드시 '긍정', '부정', '불명' 중 하나로 결론을 내린 뒤, 그 이유를 설명해야 합니다.\"\n",
    "    )\n",
    "\n",
    "    answer = str(example[\"answer\"]).strip()\n",
    "    question = example[\"question\"]\n",
    "    context = example[\"context\"]\n",
    "    summary = example[\"summary\"]\n",
    "\n",
    "    if answer == \"긍정\" :\n",
    "        target_answer = f\"네 그렇습니다! {summary}에 의하여 질문하신 내용은 옳습니다.\"\n",
    "    elif answer == \"부정\" :\n",
    "        target_answer = f\"아니요, 그렇지 않습니다! {summary}에 의하면 상충되는 내용이 있으므로 질문하신 내용은 옳지 않습니다.\"\n",
    "    elif answer == \"불명\" :\n",
    "        target_answer = f\"확실하지 않습니다만, {summary}에 적힌 내용을 근거로 판단해 볼 수 있을 것 같습니다.\"\n",
    "    else :\n",
    "        target_answer = f\"해당 사안에 대해서는 제공된 근거({summary})를 바탕으로 판단이 필요합니다.\"\n",
    "\n",
    "    user_content = (\n",
    "            f\"### [근거 문맥]\\n{context}\\n\\n\"\n",
    "            f\"### [사용자 질문]\\n{question}\\n\\n\"\n",
    "            f\"### [지시 사항]\\n\"\n",
    "            f\"1. 문맥을 바탕으로 긍정/부정/불명을 판단할 것.\\n\"\n",
    "            f\"2. 3문단 이내로 답변할 것.\\n\"\n",
    "            f\"3. 답변 끝에 지시 사항을 반복하지 말 것.\"\n",
    "        )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "        {\"role\": \"assistant\", \"content\": target_answer}\n",
    "    ]\n",
    "\n",
    "    full_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "    \n",
    "    return {\"text\": full_prompt}\n",
    "\n",
    "train_prompts, val_prompts = train_subset.map(generate_prompts_test), val_subset.map(generate_prompts_test)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "token_lengths = [len(tokenizer.encode(p[\"text\"])) for p in train_prompts] + [len(tokenizer.encode(p[\"text\"])) for p in val_prompts]\n",
    "\n",
    "print(f\"최대 토큰 길이: {np.max(token_lengths)}\")\n",
    "print(f\"평균 토큰 길이: {np.mean(token_lengths):.2f}\")\n",
    "print(f\"95번째 백분위수 (P95): {np.percentile(token_lengths, 95)}\")\n",
    "print(f\"99번째 백분위수 (P99): {np.percentile(token_lengths, 99)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14e0cf8d-41c3-4d2b-a1f0-3df1374bc7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.09055</td></tr><tr><td>eval/runtime</td><td>136.9999</td></tr><tr><td>eval/samples_per_second</td><td>2.92</td></tr><tr><td>eval/steps_per_second</td><td>1.46</td></tr><tr><td>total_flos</td><td>254149880146624500</td></tr><tr><td>train/epoch</td><td>9.96</td></tr><tr><td>train/global_step</td><td>620</td></tr><tr><td>train/grad_norm</td><td>0.48529</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0677</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2026-02-04 17:37:04</strong> at: <a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4</a><br> View project at: <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260204_173704-legal_testv4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vsc/LLM_TUNE/115.법률-규정 텍스트 분석 데이터_고도화_상황에 따른 판례 데이터/wandb/run-20260204_173759-legal_testv4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4' target=\"_blank\">2026-02-04 17:37:58</a></strong> to <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uailab-unist_/PromptTuning' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4' target=\"_blank\">https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/uailab-unist_/PromptTuning/runs/legal_testv4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0xef17540df1a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습을 기록할 wanDB notebook 설정\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"PromptTuning\" # 프로젝트 이름\n",
    "os.environ[\"WANDB_RUN_ID\"] = \"legal_testv4\" # 노트북 고유 ID\n",
    "os.environ[\"WANDB_RESUME\"] = \"allow\" # 해당 노트북에서 학습을 이어서 진행할 것인지\n",
    "\n",
    "wandb.init(\n",
    "    project=os.environ[\"WANDB_PROJECT\"],\n",
    "    id=os.environ[\"WANDB_RUN_ID\"],\n",
    "    resume=os.environ[\"WANDB_RESUME\"],\n",
    "    name=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") # 대시보드에 표시될 이름\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14760be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72279ff7abac4db08919d6096d4f8d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573b26689d8643c9815a379d697fc0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 먼저 1 epoch로 훈련 -> 추론이 잘 이루어지는지 확인\n",
    "# 이후 epoch를 늘려 과적합이 일어날 때 까지 학습하는 것이 좋음\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig, DataCollatorForCompletionOnlyLM # 오직 답변 부분에 대해서만 손실 계산\n",
    "from datetime import datetime\n",
    "\n",
    "response_template = \"[|assistant|]\" # EXAONE 기준 response_template\n",
    "data_collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template=response_template, \n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./SFT2\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    max_seq_length=1024,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    load_best_model_at_end=True,\n",
    "    optim=\"paged_adamw_32bit\", # 일반적으로 adam 계열 사용, paged_adamw_32bit는 GPU 메모리 부담을 줄이기 위해 CPU 메모리르 확장 사용 기법\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=11,\n",
    "    warmup_steps=10, # 0부터 목표 lr까지 선형적으로 늘리는 steps 기간 결정 (학습 초기에 큰 lr을 사용하면 발산할 수 있기 때문)\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=5e-5,\n",
    "    group_by_length=True, # 길이가 비슷한 샘플을 함께 배치 함으로써 메모리 사용 최적화\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=f\"{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\"\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=val_subset,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    formatting_func=generate_prompts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e672dbac-5f70-4149-a708-4ba39536b45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1227: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m final_save_path = \u001b[33m\"\u001b[39m\u001b[33m./SFT2/final\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m os.makedirs(final_save_path, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# trainer.train(resume_from_checkpoint=True) # 이어서 학습을 진행하고 싶은 경우, 가장 마지막 checkpoint-XX를 불러와서 학습이 진행된다\u001b[39;00m\n\u001b[32m     13\u001b[39m trainer.save_model(final_save_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:434\u001b[39m, in \u001b[36mSFTTrainer.train\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.neftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._trainer_supports_neftune:\n\u001b[32m    432\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m._trl_activate_neftune(\u001b[38;5;28mself\u001b[39m.model)\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m output = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[32m    437\u001b[39m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.neftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._trainer_supports_neftune:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/transformers/trainer.py:2052\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2050\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2051\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2052\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2053\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2054\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2055\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2056\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2057\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/transformers/trainer.py:2388\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2385\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_begin(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m   2387\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.accumulate(model):\n\u001b[32m-> \u001b[39m\u001b[32m2388\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2391\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2392\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2393\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2394\u001b[39m ):\n\u001b[32m   2395\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2396\u001b[39m     tr_loss += tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/transformers/trainer.py:3518\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3516\u001b[39m         scaled_loss.backward()\n\u001b[32m   3517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3518\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3520\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach() / \u001b[38;5;28mself\u001b[39m.args.gradient_accumulation_steps\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/accelerate/accelerator.py:2196\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2194\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2196\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/_tensor.py:631\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    623\u001b[39m         Tensor.backward,\n\u001b[32m    624\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    629\u001b[39m         inputs=inputs,\n\u001b[32m    630\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/autograd/__init__.py:381\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    376\u001b[39m     retain_graph = create_graph\n\u001b[32m    378\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    379\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    380\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/autograd/graph.py:865\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    863\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    864\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "# PyTorch 2.6 이상 버전에서 trainer.train(resume_from_checkpoint=True)을 하고 싶다면 해주어야 함\n",
    "# torch.load의 기본값을 weights_only=False로 수정\n",
    "torch.load = partial(torch.load, weights_only=False)\n",
    "\n",
    "final_save_path = \"./SFT2/final\"\n",
    "os.makedirs(final_save_path, exist_ok=True)\n",
    "trainer.train()\n",
    "# trainer.train(resume_from_checkpoint=True) # 이어서 학습을 진행하고 싶은 경우, 가장 마지막 checkpoint-XX를 불러와서 학습이 진행된다\n",
    "\n",
    "trainer.save_model(final_save_path)\n",
    "tokenizer.save_pretrained(final_save_path)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6f9ed-12a8-46b9-891a-1d6d4f7566cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 추론된 모델 확인\n",
    "# 중요!!! 학습 이후 커널을 내리고 다시 올려야 파인튜닝된 가중치를 모델에 올릴 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f960ed74-2364-4466-9c56-9d699b5915ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import os, torch, json, wandb, subprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig, \n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7ea6a2-5ef9-4d84-9766-fc7f33d9a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 4bit 할 것이냐\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, #bfloat16 or float16\n",
    "    bnb_4bit_quant_type=\"nf4\", # nf4 or fp4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0950899f-4b1c-4ae8-b14e-f6235d6793d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  queued_call()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcef1a979ae43f09da3117b90f30b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 및 토크나이저 불러오기\n",
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "model_id = \"/home/vsc/LLM/model/EXAONE-3.5-7.8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "672d9e5e-2a0e-4488-a811-02fdfef93271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): ExaoneForCausalLM(\n",
       "      (transformer): ExaoneModel(\n",
       "        (wte): Embedding(102400, 4096, padding_idx=0)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-31): 32 x ExaoneBlock(\n",
       "            (ln_1): ExaoneRMSNorm()\n",
       "            (attn): ExaoneAttention(\n",
       "              (attention): ExaoneSdpaAttention(\n",
       "                (rotary): ExaoneRotaryEmbedding()\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (ln_2): ExaoneRMSNorm()\n",
       "            (mlp): ExaoneGatedMLP(\n",
       "              (c_fc_0): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (c_fc_1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (c_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): ExaoneRMSNorm()\n",
       "        (rotary): ExaoneRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=102400, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_path = \"./SFT2/final\"\n",
    "model = PeftModel.from_pretrained(model, adapter_path) # 학습된 LoRA Config를 씌운다\n",
    "model.eval() # 추론 모드로 모델을 바꾼다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcae29ae-d7a0-425b-83cd-6a6699f38c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 || 400 || 200\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "from datasets import Dataset\n",
    "\n",
    "def load_json_files(dir) :\n",
    "    loaded_data = []\n",
    "    for filename in os.listdir(dir) :\n",
    "        if filename.endswith('.json') :\n",
    "            with open(os.path.join(dir, filename), 'r', encoding='utf-8') as f :\n",
    "                loaded_data.append(json.load(f))\n",
    "    \n",
    "    return loaded_data\n",
    "\n",
    "def create_dataset(data) :\n",
    "    dataset_dict = {\n",
    "        \"id\": [],\n",
    "        \"question\": [],\n",
    "        \"context\": [],\n",
    "        \"summary\": [],\n",
    "        \"answer\" : [],\n",
    "    }\n",
    "\n",
    "    for item in data:\n",
    "        dataset_dict[\"id\"].append(item[\"info\"][\"id\"])\n",
    "        dataset_dict[\"question\"].append(item[\"jdgmnInfo\"][0][\"question\"])\n",
    "        dataset_dict[\"context\"].append(item[\"Summary\"][0][\"summ_contxt\"])\n",
    "        dataset_dict[\"summary\"].append(item[\"Summary\"][0][\"summ_pass\"])\n",
    "        dataset_dict[\"answer\"].append(item[\"jdgmnInfo\"][0][\"answer\"])\n",
    "\n",
    "    return Dataset.from_dict(dataset_dict)\n",
    "    \n",
    "extract_dir_list = [\"./3.개방데이터/1.데이터/extract/Training/02.라벨링데이터\", \"./3.개방데이터/1.데이터/extract/Validation/02.라벨링데이터\", \"./3.개방데이터/1.데이터/raw/Training/0.1.원천데이터\"]\n",
    "train_data, val_data = load_json_files(extract_dir_list[0]), load_json_files(extract_dir_list[1])\n",
    "\n",
    "train_dataset = create_dataset(train_data)\n",
    "val_dataset = create_dataset(val_data)\n",
    "\n",
    "seed = 42\n",
    "\n",
    "train_subset = train_dataset.shuffle(seed=seed).select(range(1000))\n",
    "val_subset = val_dataset.shuffle(seed=seed).select(range(400))\n",
    "test_subset = val_dataset.shuffle(seed=seed).select(range(401, 601))\n",
    "\n",
    "print(f\"{len(train_subset)} || {len(val_subset)} || {len(test_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a166fd-4188-4c83-a838-92ef9b23d50c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 41036985, 'question': '피신청인들이 제출한 자료만으로, 이 사건 처분의 효력을 정지시킬 경우 위와 같이 공익에 중대한 해를 입힐 우려가 있다고 보기 부족하고, 더욱이 국정교과서 교육의 위헌·위법성 또는 이 사건 처분의 위법성이 추후 확인될 경우, 잘못된 국정교과서로 한국사를 배운 학생들 및 그들의 학부모가 침해당할 학습권, 자녀교육권과 비교형량하여 볼 때, 피신청인이 내세우는 공공의 복리란 것이 더 중대하다고도 볼 수 있는가?', 'context': '피신청인은 이 사건 처분이 이 사건 학교를 연구학교로 지정하여 이 사건 국정교과서의 교육효과를 연구·개발·검증하기 위한 것이고, 이 사건 학교는 전국에 유일한 이 사건 국정교과서의 연구학교로서 이 사건 처분의 효력이 정지되는 경우 국가의 교육정책에 막대한 장애가 발생하여 공공의 복리에 중대한 영향이 있다고 주장한다. 그러나 집행정지의 장애사유로서의 ‘공공복리에 대한 중대한 영향을 미칠 우려’란 그와 같은 일반적·추상적인 공익에 대한 침해의 우려가 아니라 당해 처분의 효력정지로 말미암아 구체적이고도 개별적으로 공익에 중대한 해를 입힐 우려가 높은 경우를 말하는바, 피신청인들이 제출한 자료만으로, 이 사건 처분의 효력을 정지시킬 경우 위와 같이 공익에 중대한 해를 입힐 우려가 있다고 보기 부족하다. 더욱이 국정교과서 교육의 위헌·위법성 또는 이 사건 처분의 위법성이 추후 확인될 경우, 잘못된 국정교과서로 한국사를 배운 학생들 및 그들의 학부모가 침해당할 학습권, 자녀교육권과 비교형량하여 보더라도 피신청인이 내세우는 공공의 복리란 것이 더 중대하다고도 볼 수 없다.', 'summary': '집행정지의 장애사유로서의 ‘공공복리에 대한 중대한 영향을 미칠 우려’란 그와 같은 일반적·추상적인 공익에 대한 침해의 우려가 아니라 당해 처분의 효력정지로 말미암아 구체적이고도 개별적으로 공익에 중대한 해를 입힐 우려가 높은 경우를 말하는바, 피신청인들이 제출한 자료만으로, 이 사건 처분의 효력을 정지시킬 경우 위와 같이 공익에 중대한 해를 입힐 우려가 있다고 보기 부족하다. 더욱이 국정교과서 교육의 위헌·위법성 또는 이 사건 처분의 위법성이 추후 확인될 경우, 잘못된 국정교과서로 한국사를 배운 학생들 및 그들의 학부모가 침해당할 학습권, 자녀교육권과 비교형량하여 보더라도 피신청인이 내세우는 공공의 복리란 것이 더 중대하다고도 볼 수 없다.', 'answer': '부정'}\n"
     ]
    }
   ],
   "source": [
    "print(test_subset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791e331d-da49-4468-9196-7a39411f4e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_legal_answer(question):\n",
    "    system_message = (\n",
    "        \"당신은 법률 전문가입니다. 주어진 [근거 문맥]만을 바탕으로 사용자의 질문에 답하십시오. \"\n",
    "        \"답변은 반드시 '긍정', '부정', '불명' 중 하나로 결론을 내린 뒤, 그 이유를 설명해야 합니다.\"\n",
    "    )\n",
    "    # 학습 때와 동일한 구조를 유지하되 문맥 부분만 비웁니다.\n",
    "    user_content = (\n",
    "        f\"### [근거 문맥]\\n(제공된 문맥이 없습니다.)\\n\\n\"\n",
    "        f\"### [사용자 질문]\\n{question}\\n\\n\"\n",
    "        f\"### [지시 사항]\\n\"\n",
    "        f\"1. 문맥을 바탕으로 긍정/부정/불명을 판단할 것.\\n\"\n",
    "        f\"2. 3문단 이내로 답변할 것.\\n\"\n",
    "        f\"3. 답변 끝에 지시 사항을 반복하지 말 것.\"\n",
    "    )\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False, # 비교를 위해 결정론적 생성\n",
    "            repetition_penalty=1.1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d48eefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 및 비교 시작... 총 200개 데이터\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 200/200 [09:17<00:00,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[최종 검증 요약]\n",
      "- Label Accuracy: 67.50%\n",
      "- ROUGE-L: 0.1204\n",
      "- BLEU: 0.1901\n",
      "\n",
      "[상세 분류 리포트]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          긍정       0.72      0.77      0.74       119\n",
      "          부정       0.60      0.58      0.59        74\n",
      "          불명       0.00      0.00      0.00         7\n",
      "          실패       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.33      0.34      0.33       200\n",
      "weighted avg       0.65      0.68      0.66       200\n",
      "\n",
      "검증 완료! 로그 파일: ./result2/log_without_context.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 유저가 Context를 주지 않을 경우\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher # 텍스트간 유사도 측정 라이브러리\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import evaluate  # Hugging Face evaluate 라이브러리\n",
    "\n",
    "# 1. 지표 로더\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "\n",
    "# 2. 결과 파일 및 통계 초기화\n",
    "output_file_path = \"./result2/log_without_context.txt\"\n",
    "os.makedirs(\"./result2\", exist_ok=True)\n",
    "\n",
    "all_preds_text = []    # ROUGE/BLEU용 모델 답변\n",
    "all_refs_text = []     # ROUGE/BLEU용 실제 정답\n",
    "y_true_idx = []        # 혼동행렬용 실제 라벨\n",
    "y_pred_idx = []        # 혼동행렬용 예측 라벨\n",
    "\n",
    "label_map = {\"긍정\": 0, \"부정\": 1, \"불명\": 2}\n",
    "correct_labels = 0\n",
    "total_samples = len(test_subset)\n",
    "\n",
    "print(f\"검증 및 비교 시작... 총 {total_samples}개 데이터\")\n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== EXAONE 법률 QA 정답 비교 검증 로그 ===\\n\\n\")\n",
    "\n",
    "    for i, data in enumerate(tqdm(test_subset, desc=\"Evaluating\")):\n",
    "        question = data[\"question\"]\n",
    "        context = data[\"context\"]\n",
    "        actual_label = str(data[\"answer\"]).strip() # 실제 정답 (긍정/부정/불명)\n",
    "        summary = data[\"summary\"]\n",
    "        \n",
    "        if actual_label == \"긍정\":\n",
    "            ground_truth = f\"네 그렇습니다! {summary}에 의하여 질문하신 내용은 옳습니다.\"\n",
    "        elif actual_label == \"부정\":\n",
    "            ground_truth = f\"아니요, 그렇지 않습니다! {summary}에 의하면 상충되는 내용이 있으므로 질문하신 내용은 옳지 않습니다.\"\n",
    "        else:\n",
    "            ground_truth = f\"확실하지 않습니다만, {summary}에 적힌 내용을 근거로 판단해 볼 수 있을 것 같습니다.\"\n",
    "\n",
    "        # 모델 답변 생성\n",
    "        generated_answer = generate_legal_answer(question)\n",
    "\n",
    "        actual_idx = label_map.get(actual_label, 3)\n",
    "        if \"네\" in generated_answer[:10]: pred_idx = 0\n",
    "        elif \"아니요\" in generated_answer[:10]: pred_idx = 1\n",
    "        elif \"확실하지\" in generated_answer[:10]: pred_idx = 2\n",
    "        else: pred_idx = 3 # 분류 실패\n",
    "\n",
    "        y_true_idx.append(actual_idx)\n",
    "        y_pred_idx.append(pred_idx)\n",
    "        if actual_idx == pred_idx: correct_labels += 1\n",
    "\n",
    "        all_preds_text.append(generated_answer)\n",
    "        all_refs_text.append(ground_truth)\n",
    "\n",
    "        similarity = SequenceMatcher(None, ground_truth, generated_answer).ratio()\n",
    "\n",
    "        # 로그 기록\n",
    "        f.write(f\"[{i+1}번 데이터] | Label 일치: {'O' if actual_idx == pred_idx else 'X'} | 유사도: {similarity:.2f}\\n\")\n",
    "        f.write(f\"질문: {question}\\n\")\n",
    "        f.write(f\"실제 정답: {ground_truth}\\n\")\n",
    "        f.write(f\"모델 답변: {generated_answer}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    rouge_results = rouge_metric.compute(predictions=all_preds_text, references=all_refs_text)\n",
    "    bleu_results = bleu_metric.compute(predictions=all_preds_text, references=all_refs_text)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_true_idx, y_pred_idx, labels=[0, 1, 2, 3])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='RdPu', \n",
    "                xticklabels=[\"pos\", \"neg\", \"non\", \"fail\"], \n",
    "                yticklabels=[\"pos\", \"neg\", \"non\", \"fail\"])\n",
    "    plt.title(\"Without Context\")\n",
    "    plt.savefig(\"./result2/confusion_matrix_without_context.png\")\n",
    "\n",
    "    # 5. 최종 통계 기록\n",
    "    accuracy = (correct_labels / total_samples) * 100\n",
    "    report = classification_report(y_true_idx, y_pred_idx, \n",
    "                                   target_names=['긍정', '부정', '불명', '실패'], labels=[0, 1, 2, 3])\n",
    "    summary_msg = (\n",
    "        f\"\\n[최종 검증 요약]\\n\"\n",
    "        f\"- Label Accuracy: {accuracy:.2f}%\\n\"\n",
    "        f\"- ROUGE-L: {rouge_results['rougeL']:.4f}\\n\"\n",
    "        f\"- BLEU: {bleu_results['bleu']:.4f}\\n\"\n",
    "        f\"\\n[상세 분류 리포트]\\n{report}\"\n",
    "    )\n",
    "    \n",
    "    print(summary_msg)\n",
    "    f.write(summary_msg)\n",
    "\n",
    "print(f\"검증 완료! 로그 파일: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84135781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_legal_answer_with_context(question, context):\n",
    "    system_message = (\n",
    "        \"당신은 법률 전문가입니다. 주어진 [근거 문맥]만을 바탕으로 사용자의 질문에 답하십시오. \"\n",
    "        \"답변은 반드시 '긍정', '부정', '불명' 중 하나로 결론을 내린 뒤, 그 이유를 설명해야 합니다.\"\n",
    "    )\n",
    "    # 학습 시의 user_content와 완벽히 일치해야 합니다.\n",
    "    user_content = (\n",
    "        f\"### [근거 문맥]\\n{context}\\n\\n\"\n",
    "        f\"### [사용자 질문]\\n{question}\\n\\n\"\n",
    "        f\"### [지시 사항]\\n\"\n",
    "        f\"1. 문맥을 바탕으로 긍정/부정/불명을 판단할 것.\\n\"\n",
    "        f\"2. 3문단 이내로 답변할 것.\\n\"\n",
    "        f\"3. 답변 끝에 지시 사항을 반복하지 말 것.\"\n",
    "    )\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False,\n",
    "            repetition_penalty=1.1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
    "    return response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab16fdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 및 비교 시작... 총 200개 데이터\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|███████████████████████████████████████████| 200/200 [13:52<00:00,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[최종 검증 요약]\n",
      "- Label Accuracy: 92.50%\n",
      "- ROUGE-L: 0.2036\n",
      "- BLEU: 0.4561\n",
      "\n",
      "[상세 분류 리포트]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          긍정       0.93      0.97      0.95       119\n",
      "          부정       0.91      0.95      0.93        74\n",
      "          불명       0.00      0.00      0.00         7\n",
      "          실패       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.46      0.48      0.47       200\n",
      "weighted avg       0.89      0.93      0.91       200\n",
      "\n",
      "검증 완료! 로그 파일: ./result2/log_with_context.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/vsc/LLM_TUNE/myenv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAIQCAYAAADnzpi9AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQixJREFUeJzt3Xl0FGXa/vGrO0ACgSQQIIACYRPCJvsSEEQzgqCCOo4oso2I+rIa3OKwL0YYBWQRhFGJbAo64CiIQFgcIYZVdpAlAq8akJAQ2UJM6veHP/q1DEvSdKdTle/nnDoneaq6+u4qwZurnqp2GIZhCAAAAJbm9HUBAAAAuHU0dQAAADZAUwcAAGADNHUAAAA2QFMHAABgAzR1AAAANkBTBwAAYAM0dQAAADZAUwcAAGADNHWAzWzYsEEOh0MbNmzI9baffPKJ9wsDAHgVTR1QgCxZskQOh0PLli3Lse7OO++Uw+HQ+vXrc6yrUqWKIiMjr7vfRYsWaerUqZ4s1eTo0aN69tlnVb16dQUEBCgoKEht2rTR22+/rUuXLnntfffv36/Ro0frhx9+8Np7XPX6669r+fLlXn8fAHAXTR1QgLRt21aS9M0335jG09PTtXfvXhUpUkSbNm0yrTt58qROnjzpem27du106dIltWvXzrWNN5u6FStWqEGDBlqyZIkefPBBTZ8+XbGxsapSpYpeeuklDRkyxCvvK/3e1I0ZM4amDgAkFfF1AQD+T6VKlVStWrUcTV1CQoIMw9Bjjz2WY93V3682dU6nUwEBAflSb1JSkrp3766qVatq3bp1qlixomvdgAEDdOTIEa1YsSJfagGAwo6kDihg2rZtq507d5ouW27atEn16tXT/fffr2+//VbZ2dmmdQ6HQ23atJGUc07d3XffrRUrVuj48eNyOBxyOBwKDw83vWd2drYmTJig22+/XQEBAbr33nt15MiRm9Y6adIknT9/Xu+9956pobuqZs2apqTut99+07hx41SjRg35+/srPDxcr732mjIyMkyvCw8P1wMPPKBvvvlGLVq0UEBAgKpXr64PP/zQtc28efP02GOPSZI6dOjg+mx/nEv45Zdf6q677lJgYKBKlSqlLl26aN++fa7169atk9Pp1MiRI03vv2jRIjkcDs2aNUuS5HA4dOHCBcXFxbnep0+fPjc9PgCQrwwABcq7775rSDLWr1/vGrvnnnuM/v37G0eOHDEkGbt27XKta9SokREREeH6ff369abXr1692mjUqJFRtmxZY/78+cb8+fONZcuWmbZt3Lix0bRpU2PKlCnG6NGjjRIlShgtWrS4aa233XabUb169Vx/tt69exuSjL/+9a/GzJkzjV69ehmSjG7dupm2q1q1qlG7dm0jLCzMeO2114wZM2YYTZo0MRwOh7F3717DMAzj6NGjxuDBgw1Jxmuvveb6bMnJyYZhGMaHH35oOBwOo1OnTsb06dONiRMnGuHh4UZISIiRlJTkeq8BAwYYRYoUMbZv324YhmH89NNPRpkyZYyoqCgjOzvbMAzDmD9/vuHv72/cddddrvfZvHlzrj83AOQHmjqggNm3b58hyRg3bpxhGIaRmZlpBAYGGnFxcYZhGEZYWJgxc+ZMwzAMIz093fDz8zOeeeYZ1+v/3NQZhmF06dLFqFq1ao73urptRESEkZGR4Rp/++23DUnGnj17rlvnuXPnDElG165dc/W5vvvuO0OS0a9fP9P4iy++aEgy1q1b5xqrWrWqIcn4+uuvXWOnT582/P39jWHDhrnGli5dmuOzGoZh/Prrr0ZISIjpuBiGYSQnJxvBwcGm8QsXLhg1a9Y06tWrZ1y+fNno0qWLERQUZBw/ftz02sDAQKN37965+qwA4AtcfgUKmIiICIWGhrrmyu3atUsXLlxw3d0aGRnpulkiISFBWVlZrvl07urbt6+KFSvm+v2uu+6SJB07duy6r0lPT5cklSpVKlfvsXLlSklSdHS0aXzYsGGSlGPuXd26dV11SFK5cuVUu3btG9Z01Zo1a5SWlqYnnnhCZ86ccS1+fn5q2bKl6Q7iEiVKaN68eTpw4IDatWunFStWaMqUKapSpUquPhcAFBTcKAEUMA6HQ5GRkfr666+VnZ2tTZs2qXz58qpZs6ak35u6GTNmSJKrubvVpu7PDUzp0qUlSampqdd9TVBQkCTp119/zdV7HD9+XE6n0/U5rqpQoYJCQkJ0/PjxG9Z0ta4b1XTV4cOHJUn33HPPDWu/qk2bNnr++ec1c+ZMdezYUX//+99v+h4AUNDQ1AEFUNu2bfX5559rz5492rRpk+kZdJGRkXrppZf0448/6ptvvlGlSpVUvXr1W3o/Pz+/a44bhnHd1wQFBalSpUrau3dvnt7L4XB4raarrt5IMn/+fFWoUCHH+iJFzH/1ZWRkuG6wOHr0qC5evKgSJUrkqk4AKCi4/AoUQH98Xt2mTZtcd7ZKUtOmTeXv768NGzYoMTHRtO56cttI5dUDDzygo0ePKiEh4abbVq1aVdnZ2a4U7apTp04pLS1NVatWzfP7X+9z1ahRQ5JUvnx5RUVF5Vjuvvtu0/ajRo3SgQMH9OabbyopKUmvvvpqrt8LAAoKmjqgAGrWrJkCAgK0cOFC/fjjj6akzt/fX02aNNHMmTN14cKFXF16DQwM1Llz5zxe58svv6zAwED169dPp06dyrH+6NGjevvttyVJnTt3lqQcD0GePHmyJKlLly55fv/AwEBJUlpammm8Y8eOCgoK0uuvv67MzMwcr/vll19cPycmJurNN9/U0KFDNWzYML300kuaMWOGNm7cmOO9/vw+AFCQcPkVKICKFSum5s2b67///a/8/f3VtGlT0/rIyEi99dZbknI3n65p06b6+OOPFR0drebNm6tkyZJ68MEHb7nOGjVqaNGiRXr88ccVERGhXr16qX79+rpy5Yo2b96spUuXup7nduedd6p3796aM2eO0tLS1L59e23ZskVxcXHq1q2bOnTokOf3b9Sokfz8/DRx4kSdO3dO/v7+uueee1S+fHnNmjVLPXv2VJMmTdS9e3eVK1dOJ06c0IoVK9SmTRvNmDFDly9fVu/evVWrVi1NmDBBkjRmzBh9/vnn6tu3r/bs2eNqHJs2baq1a9dq8uTJrodEt2zZ8paPIQB4jK9vvwVwbTExMYYkIzIyMse6f//734Yko1SpUsZvv/1mWnetR5qcP3/eePLJJ42QkBBDkuvxJle3Xbp0qWkfSUlJhiTjgw8+yFWt33//vfHMM88Y4eHhRrFixYxSpUoZbdq0MaZPn25cvnzZtV1mZqYxZswYo1q1akbRokWNypUrGzExMaZtDOP3R5p06dIlx/u0b9/eaN++vWls7ty5RvXq1Q0/P78cn3v9+vVGx44djeDgYCMgIMCoUaOG0adPH2Pbtm2GYRjGCy+8YPj5+RmJiYmmfW7bts0oUqSI8fzzz7vGDh48aLRr184oXry4IYnHmwAocByGkYtZxwAAACjQmFMHAABgAzR1AAAANkBTBwAAYAM0dQAAADZAUwcAAGADNHUAAAA2QFMHAABgAwXmGyU6Owb4ugTkoxXnxvm6BOQjR7Fivi4BgLcElPTZW3uzd1hpzPTavr2FpA4AAMAGCkxSBwAAkBckU2YcDwAAABsgqQMAAJbkkMPXJRQoJHUAAAA2QFIHAAAsiWTKjKYOAABYEpdfzWhyAQAAbICkDgAAWBLJlBnHAwAAwAZI6gAAgCUxo86MpA4AAMAGSOoAAIAlOcnqTEjqAAAAbICkDgAAWBI5nRlJHQAAgA2Q1AEAAEtiTp0ZTR0AALAkWjozLr8CAADYAEkdAACwJJIpM44HAACADZDUAQAAS3Iwq86EpA4AAMAGSOoAAIAlkUyZcTwAAABsgKQOAABYEg8fNqOpAwAAlkRLZ8blVwAAABsgqQMAAJbkdJDV/RFJHQAAgA2Q1AEAAEsipzMjqQMAALABkjoAAGBJJFNmHA8AAAAbIKkDAACW5GBWnQlNHQAAsCQuN5pxPAAAAGyApA4AAFgSl1/NSOoAAABsgKQOAABYEsmUGccDAADABkjqAACAJTGjzoykDgAAwAZI6gAAgCU5yepMaOoAAIAl0dKZcfkVAADABkjqAACAJXH51YykDgAAwAbcaupWrVqlb775xvX7zJkz1ahRIz355JNKTU31WHEAAADX4/TiYkVu1f3SSy8pPT1dkrRnzx4NGzZMnTt3VlJSkqKjoz1aIAAAAG7OrTl1SUlJqlu3riTp008/1QMPPKDXX39dO3bsUOfOnT1aIAAAwLUwo87MraSuWLFiunjxoiRp7dq1uu+++yRJZcqUcSV4hVX9u2pq1H+e0/wfJ2ilMVOtuzY0rY98+E6N/2qgPjozUSuNmap+5+059vHG+iFaacw0LQNndc+vjwAvmjPvQ9Vp3lqvvzXF16XAixZ+tET33P+AGjRvrcd69NLuPXt9XRK8iPONgsKtpq5t27aKjo7WuHHjtGXLFnXp0kWS9P333+v223M2KYVJQGAxJe36X70zYMl11vtr3zdH9cErn91wP1/O+UY9KsS4lvdeXu6FapGf9uzbr4+XLVftWjV9XQq8aOWq1Yp9c7IGPNtfyz5aqDq179DTzw9USspZX5cGL+B8+5ZTDq8tVuRWUzdjxgwVKVJEn3zyiWbNmqXbbrtNkvTll1+qU6dOHi3Qarat2q8PR3yhhOW7rrl+3YItWjzuS+1ce/CG+8m4eEWpp9Jdy6VfL3ujXOSTCxcv6sWRozXutVcVVKqUr8uBF30wf4H+9sjDerTbQ6pZo7rGDH9NAQEB+nT5jf8hB2vifPuWw4uLFbk1p65KlSr64osvcoxPmcIlJU/p0KO5OjzVQqnJ6dry+R4tHvelMi5l+rosuGnspDd1d5tIRbZsoVnvz/N1OfCSK5mZ2nfgoJ59uq9rzOl0KrJVC+3cvceHlcEbON8oaNy+azcrK0uffvqpxo8fr/Hjx2vZsmXKysryZG2F1oZF2/TPp+IU0+FtLYldrXt6ttCLC/r4uiy4acXqNdp/8JCiBzzv61LgZampacrKylJoaKhpPDQ0VGfOnPFRVfAWzrfvFZTLr19//bUefPBBVapUSQ6HQ8uXLzetNwxDI0eOVMWKFVW8eHFFRUXp8OHDpm3Onj2rHj16KCgoSCEhIXr66ad1/vz5PNXhVlJ35MgRde7cWT/++KNq164tSYqNjVXlypW1YsUK1ahR44avz8jIUEZGhmksS1nyk5875djOqrmbXD//sPcnpf58TrHrhqhC9bJKPsZfFFbyc/Ipvf7WFL0/Y5r8/f19XQ4AwAsuXLigO++8U3//+9/1yCOP5Fg/adIkTZs2TXFxcapWrZpGjBihjh07av/+/QoICJAk9ejRQz///LPWrFmjzMxM9e3bV/3799eiRYtyXYdbTd3gwYNVo0YNffvttypTpowkKSUlRU899ZQGDx6sFStW3PD1sbGxGjNmjGmsppqpllq4U47tHUz8QZJUqWY5mjqL2XfwoFLOpuqRnn1cY1lZWdq28zstXPqpdm/aKD8//jFjF6VLh8jPz08pKSmm8ZSUFJUtW9ZHVcFbON++V1Dmvt1///26//77r7nOMAxNnTpVw4cPV9euXSVJH374ocLCwrR8+XJ1795dBw4c0KpVq7R161Y1a9ZMkjR9+nR17txZb775pipVqpSrOty6/Lpx40ZNmjTJ1dBJv8fNb7zxhjZu3HjT18fExOjcuXOmpbqaulNKoVCj0e93FJ/9+ZyPK0FetWreTP9ZvEDLFsS5lvoREXqwU0ctWxBHQ2czxYoWVb2IOkpI3Ooay87OVkLiVjVu2MCHlcEbON/IjaSkJCUnJysqKso1FhwcrJYtWyohIUGSlJCQoJCQEFdDJ0lRUVFyOp1KTEzM9Xu5ldT5+/vr119/zTF+/vx5FStWLFev//OlKLtceg0I9FelmuVcv4dVC1X1O2/Xr2cv6JeTqSpZuoTKVymjMpWCJUm31y4vSUpN/v0u1wrVy6rDk820deU+padcULWGt6n/lEe1Z+Nh/bDnJ598JrivZGCg7qhpno5QvHiAQoKDcozDHvr2fEqvjBil+vUi1LB+fcUtWKRLly7pkW4P+bo0eAHn27e8+XVe15oqdq3+5WaSk5MlSWFhYabxsLAw17rk5GSVL1/etL5IkSIqU6aMa5vccKupe+CBB9S/f3+99957atHi90umiYmJeu655/TQQ4X7P+Razapo4oahrt/7T/mrJGnNvG81pe98tXqooaLn9XStf/XjpyVJC0ev0MIxK/Xbld/UKKqOug7toIBAf/1yMlWbPv1Oi8evytfPAcA9nTvdp7OpqZr2zmz9ciZFEbXv0L/ema6yf5pMD3vgfNvXtaaKjRo1SqNHj/ZNQbngMAzDyOuL0tLS1Lt3b33++ecqWrSoJCkzM1Ndu3bVvHnzFBwcnOdCOjsG5Pk1sK4V58b5ugTkI0cuEnwAFhVQ0mdvPdL5qtf2/Y9LY9xK6hwOh5YtW6Zu3bpJko4dO6YaNWpo586datSokWu79u3bq1GjRnr77bf1/vvva9iwYUpNTXWt/+233xQQEKClS5fq4YcfzlXNbiV1ISEh+uyzz3TkyBHt379fklS3bl3VrMmT8gEAQP7w5jc/uHOp9VqqVaumChUqKD4+3tXUpaenKzExUc8///ujrlq3bq20tDRt375dTZv+fo/BunXrlJ2drZYtW+b6vdxq6iTpvffe05QpU1zPWalVq5aGDh2qfv36ubtLAAAAyzl//ryOHDni+j0pKUnfffedypQpoypVqmjo0KEaP368atWq5XqkSaVKlVxpXkREhDp16qRnnnlGs2fPVmZmpgYOHKju3bvn+s5Xyc2mbuTIkZo8ebIGDRqk1q1bS/r9zo0XXnhBJ06c0NixY93ZLQAAQK5580aJvNi2bZs6dOjg+j06OlqS1Lt3b82bN08vv/yyLly4oP79+ystLU1t27bVqlWrXM+ok6SFCxdq4MCBuvfee+V0OvXoo49q2rRpearDrTl15cqV07Rp0/TEE0+YxhcvXqxBgwa59SRt5tQVLsypK1yYUwfYmA/n1I11xnht3yOzY722b29xK6nLzMw0PUvlqqZNm+q333675aIAAABupqA8fLigcCu57Nmzp2bNmpVjfM6cOerRo8ctFwUAAIC8uaUbJVavXq1WrVpJ+v05dSdOnFCvXr1c15IlafLkybdeJQAAwJ8UlDl1BYVbTd3evXvVpEkTSdLRo0clSWXLllXZsmW1d+9e13YOB8EoAABAfnCrqVu/fr2n6wAAAMgTbz6nzorcvvwKAADgS7R0ZlyOBgAAsAGSOgAAYEkkU2YcDwAAABsgqQMAAJZEMmXG8QAAALABkjoAAGBJ3P1qRlIHAABgAyR1AADAknj4sBlNHQAAsCRaOjMuvwIAANgASR0AALAkkikzjgcAAIANkNQBAABLIpky43gAAADYAEkdAACwJAf3v5qQ1AEAANgASR0AALAkkikzjgcAAIANkNQBAABLIpkyo6kDAACWxG0SZjS5AAAANkBSBwAALIlkyozjAQAAYAMkdQAAwJJ4+LAZSR0AAIANkNQBAABLIpky43gAAADYAEkdAACwJJIpM5o6AABgSdwmYUaTCwAAYAMkdQAAwJKcZHUmJHUAAAA2QFIHAAAsiWTKjOMBAABgAyR1AADAkphRZ0ZSBwAAYAMkdQAAwJJIpsxo6gAAgCXR1JlxPAAAAGyApA4AAFiSg1slTEjqAAAAbICkDgAAWBLJlBnHAwAAwAYKTFK34tw4X5eAfHSy81Jfl4B8VGVtD1+XAMCGmFFnRlIHAABgAwUmqQMAAMgLp5Os7o9o6gAAgCU5aOpMuPwKAABgAyR1AADAkpwOkro/IqkDAACwAZI6AABgSQ6iKRMOBwAAgA2Q1AEAAEtiTp0ZSR0AAIANkNQBAABL4jl1ZjR1AADAkvhGCTMuvwIAANgASR0AALAk7pMwI6kDAACwAZI6AABgScypMyOpAwAAsAGSOgAAYEkOJtWZkNQBAADYAE0dAACwJKfT4bUlL7KysjRixAhVq1ZNxYsXV40aNTRu3DgZhuHaxjAMjRw5UhUrVlTx4sUVFRWlw4cPe/Z4eHRvAAAA+cThdHhtyYuJEydq1qxZmjFjhg4cOKCJEydq0qRJmj59umubSZMmadq0aZo9e7YSExMVGBiojh076vLlyx47HsypAwAAuAWbN29W165d1aVLF0lSeHi4Fi9erC1btkj6PaWbOnWqhg8frq5du0qSPvzwQ4WFhWn58uXq3r27R+ogqQMAAJbkdHhvyYvIyEjFx8fr+++/lyTt2rVL33zzje6//35JUlJSkpKTkxUVFeV6TXBwsFq2bKmEhASPHQ+SOgAAgD/JyMhQRkaGaczf31/+/v45tn311VeVnp6uOnXqyM/PT1lZWZowYYJ69OghSUpOTpYkhYWFmV4XFhbmWucJJHUAAMCSvDmnLjY2VsHBwaYlNjb2mnUsWbJECxcu1KJFi7Rjxw7FxcXpzTffVFxcXL4eD5I6AACAP4mJiVF0dLRp7FopnSS99NJLevXVV11z4xo0aKDjx48rNjZWvXv3VoUKFSRJp06dUsWKFV2vO3XqlBo1auSxmknqAACAJTkcDq8t/v7+CgoKMi3Xa+ouXrwop9PcUvn5+Sk7O1uSVK1aNVWoUEHx8fGu9enp6UpMTFTr1q09djxI6gAAAG7Bgw8+qAkTJqhKlSqqV6+edu7cqcmTJ+vvf/+7pN+bz6FDh2r8+PGqVauWqlWrphEjRqhSpUrq1q2bx+qgqQMAAJaU14cEe8v06dM1YsQI/c///I9Onz6tSpUq6dlnn9XIkSNd27z88su6cOGC+vfvr7S0NLVt21arVq1SQECAx+pwGH983LEPGelnfV0C8tHJzkt9XQLyUZW1PXxdAgBvCSjps7f+tspbXtt3qxPDvLZvb2FOHQAAgA1w+RUAAFhSAbn6WmCQ1AEAANgASR0AALAkB1GdCUkdAACADZDUAQAAS3I6SOr+iKQOAADABkjqAACAJTGnzoymDgAAWJKT640mHA4AAAAbIKkDAACW5OBGCROSOgAAABsgqQMAAJbk5EYJE5I6AAAAGyCpAwAAlsScOjOSOgAAABsgqQMAAJbEnDozkjoAAAAbcCupa9y48TWvYzscDgUEBKhmzZrq06ePOnTocMsFAgAAXIuDaMrErcPRqVMnHTt2TIGBgerQoYM6dOigkiVL6ujRo2revLl+/vlnRUVF6bPPPvN0vQAAAJIkp8PhtcWK3Erqzpw5o2HDhmnEiBGm8fHjx+v48eNavXq1Ro0apXHjxqlr164eKRQAAADX51ZSt2TJEj3xxBM5xrt3764lS5ZIkp544gkdOnTo1qorBObM+1B1mrfW629N8XUp8IBKS59UlW+ezbGUjm77+wbF/FQ6uq1uW9Fbt6/+u8qO/4ucpYv7tmh43MKPluie+x9Qg+at9ViPXtq9Z6+vS4IXcb59x+F0eG2xIreauoCAAG3evDnH+ObNmxUQECBJys7Odv2Ma9uzb78+XrZctWvV9HUp8JDkZ/6t/33oQ9dyaugXkqSL649KkkoPaq3ibarozIg1OjXoP/IrG6hyE+7zZcnwsJWrViv2zcka8Gx/LftooerUvkNPPz9QKSlnfV0avIDzjYLEraZu0KBBeu655zRkyBAtWLBACxYs0JAhQ/T8889r8ODBkqSvvvpKjRo18mSttnLh4kW9OHK0xr32qoJKlfJ1OfCQ7LTLyj57ybUUj6yqzP89p4ydP8sRWEwlH6ij1OkJytjxkzIPnVHK6xvk37CCitUr7+vS4SEfzF+gvz3ysB7t9pBq1qiuMcNfU0BAgD5dzhxjO+J8+xZz6szcauqGDx+uuXPnasuWLRo8eLAGDx6sLVu2aO7cufrHP/4hSXruuef0+eefe7RYOxk76U3d3SZSkS1b+LoUeEsRpwLvq6kLK36fhlCsdlk5ivrp8rYfXZv8diJNvyX/Kv96Yb6qEh50JTNT+w4cVGSr//tz7XQ6FdmqhXbu3uPDyuANnG8UNG4/fLhHjx7q0aPHddcXL848oetZsXqN9h88pE/i3vd1KfCiEu3C5Szprwsrf2/q/EJLyLiSJeP8FdN2WWcvyS+0hC9KhIelpqYpKytLoaGhpvHQ0FAdS/rBN0XBazjfvmfVuW/e4nZTl5aWpk8++UTHjh3Tiy++qDJlymjHjh0KCwvTbbfddsPXZmRkKCMjwzRWLCND/v7+7pZjGT8nn9Lrb03R+zOmFYrPW5gFdqmjy4knlZVy0delAAAKAbcuv+7evVt33HGHJk6cqH/+859KS0uTJP373/9WTEzMTV8fGxur4OBg0xI7eao7pVjOvoMHlXI2VY/07KN6rdqqXqu22rpjp+Z/vFT1WrVVVlaWr0uEB/iFlVRAs9t0/vMDrrGslItyFPOTo2Qx87ZlitP42UTp0iHy8/NTSkqKaTwlJUVly5b1UVXwFs637zmc3lusyK2yo6Oj1adPHx0+fNh0h2vnzp319ddf3/T1MTExOnfunGmJiR7qTimW06p5M/1n8QItWxDnWupHROjBTh21bEGc/Pz8fF0iPKBkl9rKTr2kSwknXGNXDp2RkZmlgKb/l2QXqRysIhVKKWPfKV+UCQ8rVrSo6kXUUULiVtdYdna2EhK3qnHDBj6sDN7A+fY9h8N7ixW5dfl169atevfdd3OM33bbbUpOTr7p6/39/XNcejTSf3OnFMspGRioO2rWMI0VLx6gkOCgHOOwKIcU2Lm2zq/6XsoyXMPGhSs6/8VBlR7UWtnpGcq+eEVlhrZRxp5kXdl32ocFw5P69nxKr4wYpfr1ItSwfn3FLVikS5cu6ZFuD/m6NHgB5xsFiVtNnb+/v9LT03OMf//99ypXrtwtFwVYWUCz21WkQinXXa9/lDo9QTKkshP+8vudsFv+V2ff+q8PqoS3dO50n86mpmraO7P1y5kURdS+Q/96Z7rK/mkyPeyB8+1b3Chh5jAMw7j5Zmb9+vVTSkqKlixZojJlymj37t3y8/NTt27d1K5dO02dOjXPhRjpPKixMDnZeamvS0A+qrL2+nfKA7C4gJI+e+sfWue8augp4QnPem3f3uLWnLq33npL58+fV/ny5XXp0iW1b99eNWvWVMmSJTVhwgRP1wgAAJADN0qYuXX5NTg4WGvWrNGmTZu0a9cunT9/Xk2aNFFUVJSn6wMAAEAuuP2cuvj4eMXHx+v06dPKzs7WwYMHtWjRIknS++/zUF0AAOBdVr1L1VvcaurGjBmjsWPHqlmzZqpYsaIcHFUAAACfcqupmz17tubNm6eePXt6uh4AAIDc4e5XE7eauitXrigyMtLTtQAAAOQaFwrN3Lq/o1+/fq75cwAAAPA9t5K6y5cva86cOVq7dq0aNmyookWLmtZPnjzZI8UBAABcj1UfPeItbjV1u3fvVqNGjSRJe/fuNa3jpgkAAID851ZTt379ek/XAQAAkCd8TZgZwSUAAIANuP3wYQAAAF9ixpcZSR0AAIANkNQBAABrIpoyoakDAACWxI0SZvS4AAAANkBSBwAALIkbJcxI6gAAAGyApA4AAFgSXxNmxuEAAACwAZI6AABgSXzfvBlJHQAAgA2Q1AEAAEtiTp0ZTR0AALAmmjoTDgcAAIANkNQBAABL4j4JM5I6AAAAGyCpAwAAluRwEtX9EUkdAACADZDUAQAAS+KRJmYcDgAAABsgqQMAAJbE3a9mNHUAAMCauFHChMuvAAAANkBSBwAALIkbJcw4HAAAADZAUgcAACyJGyXMSOoAAABsgKYOAABYksPp8NqSVz/++KOeeuophYaGqnjx4mrQoIG2bdvmWm8YhkaOHKmKFSuqePHiioqK0uHDhz15OGjqAAAAbkVqaqratGmjokWL6ssvv9T+/fv11ltvqXTp0q5tJk2apGnTpmn27NlKTExUYGCgOnbsqMuXL3usDubUAQAASyooc+omTpyoypUr64MPPnCNVatWzfWzYRiaOnWqhg8frq5du0qSPvzwQ4WFhWn58uXq3r27R+ogqQMAAJbkcHpvycjIUHp6umnJyMi4Zh3/+c9/1KxZMz322GMqX768GjdurLlz57rWJyUlKTk5WVFRUa6x4OBgtWzZUgkJCR47HjR1AAAAfxIbG6vg4GDTEhsbe81tjx07plmzZqlWrVr66quv9Pzzz2vw4MGKi4uTJCUnJ0uSwsLCTK8LCwtzrfMELr8CAABr8uLXhMXExCg6Oto05u/vf81ts7Oz1axZM73++uuSpMaNG2vv3r2aPXu2evfu7bUa/4ykDgAA4E/8/f0VFBRkWq7X1FWsWFF169Y1jUVEROjEiROSpAoVKkiSTp06Zdrm1KlTrnWeQFMHAAAsyeHw3pIXbdq00aFDh0xj33//vapWrSrp95smKlSooPj4eNf69PR0JSYmqnXr1rd8HK7i8isAAMAteOGFFxQZGanXX39df/vb37RlyxbNmTNHc+bMkSQ5HA4NHTpU48ePV61atVStWjWNGDFClSpVUrdu3TxWB00dAACwJEcBud7YvHlzLVu2TDExMRo7dqyqVaumqVOnqkePHq5tXn75ZV24cEH9+/dXWlqa2rZtq1WrVikgIMBjdTgMwzA8trdbYKSf9XUJyEcnOy/1dQnIR1XW9rj5RgCsKaCkz9764jNxXtt3ibn5d4ODp5DUAQAAS3Ln67zsjKYOAABYUkH5RomCooBcjQYAAMCtIKmDT1RZ9bivSwAAWB3RlAmHAwAAwAZI6gAAgDVxo4QJSR0AAIANkNQBAABr4vZXE5I6AAAAGyCpAwAA1kQ0ZUJTBwAArIkbJUzocQEAAGyApA4AAFgS90mYkdQBAADYAEkdAACwJubUmZDUAQAA2ABJHQAAsCaSOhOSOgAAABsgqQMAANZENGXC4QAAALABkjoAAGBNPKjOhKYOAABYEzdKmHD5FQAAwAZI6gAAgDURTZlwOAAAAGyApA4AAFgTc+pMSOoAAABsgKQOAABYE0GdCUkdAACADZDUAQAAa2JOnQlNHQAAsCaaOhMuvwIAANgASR0AALAkvvrVjKQOAADABkjqAACANTGnzoSkDgAAwAZI6gAAgDWR1JmQ1AEAANgASR0AALAmoikTmjoAAGBNPNPEhB4XAADABkjqAACANRFNmXA4AAAAbICkDgAAWBOPNDEhqQMAALABkjoAAGBNJHUmJHUAAAA2QFIHAACsiaDOhKYOAABYE5dfTbj8CgAAYAMkdQAAwJpI6kxI6gAAAGzAraTuwoULeuONNxQfH6/Tp08rOzvbtP7YsWMeKQ4AAOB6HAR1Jm41df369dPGjRvVs2dPVaxYUQ6OKgAAgE+51dR9+eWXWrFihdq0aePpegAAAHKHOXUmbs2pK126tMqUKePpWgqlOfM+VJ3mrfX6W1N8XQq8YNHST/Xg4z3UpF0HNWnXQY/3eVobN232dVnwsoUfLdE99z+gBs1b67EevbR7z15flwQv4nyjoHCrqRs3bpxGjhypixcverqeQmXPvv36eNly1a5V09elwEsqhJXXi4P+R/9eEKdP58epVfNmGhD9kg4fZd6pXa1ctVqxb07WgGf7a9lHC1Wn9h16+vmBSkk56+vS4AWcbx9zOry3WJDDMAwjry9q3Lixjh49KsMwFB4erqJFi5rW79ixI8+FGOmF6w/AhYsX9UjPPhr18oua9f48RdxRS68Ne8HXZeUbh7Pw3njdosNf9NKQQXqs20O+LiX/FCk8T096rEcvNahXTyNfe0WSlJ2drfb3dVbPJx5X/6f7+rg6eBrnW1JASZ+9deb7K7y276J/7+K1fXuLW3/TduvWzcNlFD5jJ72pu9tEKrJlC816f56vy0E+yMrK0qq18bp46ZIaN6zv63LgBVcyM7XvwEE9+4f/mTudTkW2aqGdu/f4sDJ4A+cbBY1bTd2oUaM8XUehsmL1Gu0/eEifxL3v61KQDw4dPqLuffsp48oVlSheXDPfnKia1av7uix4QWpqmrKyshQaGmoaDw0N1bGkH3xTFLyG810A8PQNk1u6JrJ9+3YdOHBAklSvXj01btw4V6/LyMhQRkaGaaxYRob8/f1vpRxL+Dn5lF5/a4renzGtUHxeSNXCq2r54vn69fx5fbV2nV4ZNVYL5s6isQMAeJRbTd3p06fVvXt3bdiwQSEhIZKktLQ0dejQQR999JHKlSt3w9fHxsZqzJgxprGRr76s0TGvuFOOpew7eFApZ1P1SM8+rrGsrCxt2/mdFi79VLs3bZSfn5/vCoTHFStaVFUrV5Yk1Y+I0J79B/Th4o819h8xPq4Mnla6dIj8/PyUkpJiGk9JSVHZsmV9VBW8hfNdABTe6dnX5NbhGDRokH799Vft27dPZ8+e1dmzZ7V3716lp6dr8ODBN319TEyMzp07Z1piooe6U4rltGreTP9ZvEDLFsS5lvoREXqwU0ctWxBHQ1cIZGdn68qVTF+XAS8oVrSo6kXUUULiVtdYdna2EhK3qnHDBj6sDN7A+UZB41ZSt2rVKq1du1YRERGusbp162rmzJm67777bvp6f3//HJcejfTf3CnFckoGBuqOmjVMY8WLBygkOCjHOKzvrekz1a5NpCpWCNOFCxf1xaqvtGX7Dr03421flwYv6dvzKb0yYpTq14tQw/r1FbdgkS5duqRHCtPdzoUI59vHmFNn4lZTl52dneMxJpJUtGjRHN8DCxRmKampemXkGJ0+c0alSpZU7Vo19d6Mt9WmVUtflwYv6dzpPp1NTdW0d2brlzMpiqh9h/71znSV/dNketgD5xsFiVvPqevatavS0tK0ePFiVapUSZL0448/qkePHipdurSWLVuW50IK23PqCrvC/Jy6QqkQPacOKHR8+Zy6+V96bd9Fe97vtX17i1v/Z50xY4bS09MVHh6uGjVqqEaNGgoPD1d6erqmT5/u6RoBAABycnhxsSC3/vlcuXJl7dixQ/Hx8a5HmkRERCgqKsqjxQEAACB33Lr8Kknx8fGKj4/X6dOnc8yje//9vD9Ul8uvhQuXXwsZLr8C9uXLy6+LVnlt30Wf7OS1fXuLW/9nHTNmjO677z7Fx8frzJkzSk1NNS0AAACF0RtvvCGHw6GhQ4e6xi5fvqwBAwYoNDRUJUuW1KOPPqpTp055/L3d+ufz7NmzNW/ePPXs2dPT9QAAAOROAZv7tnXrVr377rtq2LChafyFF17QihUrtHTpUgUHB2vgwIF65JFHtGnTJo++v1tJ3ZUrVxQZGenRQgAAAKzq/Pnz6tGjh+bOnavSpUu7xs+dO6f33ntPkydP1j333KOmTZvqgw8+0ObNm/Xtt996tAa3mrp+/fpp0aJFHi0EAAAgTwrQ3a8DBgxQly5dctw0un37dmVmZprG69SpoypVqighISHvb3QDbl1+vXz5subMmaO1a9eqYcOGOR5EPHnyZI8UBwAA4AsZGRnKyMgwjV3rG7Ek6aOPPtKOHTu0devWHOuSk5NVrFgxhYSEmMbDwsKUnJzs0Zrdaup2796tRo0aSZL27t1rWufgKzsAAEB+8GLPERsbqzFjxpjGRo0apdGjR5vGTp48qSFDhmjNmjUKCAjwWj254fYjTTyNR5oULjzSpJDhkSaAffnwkSa/LfnKa/vO6np3rpK65cuX6+GHH5afn9//vTYrSw6HQ06nU1999ZWioqKUmppqSuuqVq2qoUOH6oUXXvBYzfxNCwAA8CfXu9T6Z/fee6/27NljGuvbt6/q1KmjV155RZUrV1bRokUVHx+vRx99VJJ06NAhnThxQq1bt/ZozTR1AADAmgrAjK9SpUqpfv36prHAwECFhoa6xp9++mlFR0erTJkyCgoK0qBBg9S6dWu1atXKo7XQ1AEAAHjRlClT5HQ69eijjyojI0MdO3bUO++84/H3YU4dfII5dYUMc+oA+/LlnLpPV3tt30Uevc9r+/YW/s8KAABgA/zzGQAAWFMBmFNXkJDUAQAA2ABJHQAAsCaSOhOaOgAAYE18i5UJl18BAABsgKQOAABYE0GdCUkdAACADZDUAQAAayKaMuFwAAAA2ABJHQAAsCbufjUhqQMAALABkjoAAGBNBHUmJHUAAAA2QFIHAACsiaTOhKYOAABYEzdKmHD5FQAAwAZI6gAAgDURTZlwOAAAAGyApA4AAFgTU+pMSOoAAABsgKQOAABYE3e/mpDUAQAA2ABJHQAAsCaCOhOaOgAAYElcfTXj8isAAIANkNQBAABrchLV/RFJHQAAgA2Q1AEAAGsiqDMhqQMAALABkjoAAGBN3P5qQlIHAABgAyR1AADAmgjqTGjqAACANdHUmXD5FQAAwAZI6gAAgDXx8GETkjoAAAAbIKkDAADWRFBnQlIHAABgAwUmqXMUK+brEgAAgJXw8GETkjoAAAAbKDBJHQAAQN6Q1P0RTR0AALAmLr+acPkVAADABkjqAACANRHUmZDUAQAA2ABJHQAAsCbm1JmQ1AEAANgASR0AALAmkjoTkjoAAAAbIKkDAADWRFJnQlMHAACsiabOhMuvAAAANkBSBwAALIqk7o9I6gAAAGyApA4AAFgTc+pMSOoAAABsgKQOAABYE0mdCUkdAACADZDUAQAAayKpM6GpAwAA1kRTZ8LlVwAAABsgqQMAANZEUmdCUgcAAGADNHUAAAA2QFMHAABgA8ypAwAA1sScOhOSOgAAABsgqQMAAJbkIKkzIakDAADW5HB4b8mD2NhYNW/eXKVKlVL58uXVrVs3HTp0yLTN5cuXNWDAAIWGhqpkyZJ69NFHderUKU8eDZo6AACAW7Fx40YNGDBA3377rdasWaPMzEzdd999unDhgmubF154QZ9//rmWLl2qjRs36qefftIjjzzi0TochmEYHt2juy6f93UFAAAgrwJK+uyts/fv9tq+nXUbuv3aX375ReXLl9fGjRvVrl07nTt3TuXKldOiRYv017/+VZJ08OBBRUREKCEhQa1atfJMzR7ZCwAAACRJ586dkySVKVNGkrR9+3ZlZmYqKirKtU2dOnVUpUoVJSQkeOx9uVECAABYkxdvlMjIyFBGRoZpzN/fX/7+/jd8XXZ2toYOHao2bdqofv36kqTk5GQVK1ZMISEhpm3DwsKUnJzssZpJ6gAAAP4kNjZWwcHBpiU2NvamrxswYID27t2rjz76KB+qNCOpAwAA1uTFpC4mJkbR0dGmsZuldAMHDtQXX3yhr7/+WrfffrtrvEKFCrpy5YrS0tJMad2pU6dUoUIFj9VMUgcAAPAn/v7+CgoKMi3Xa+oMw9DAgQO1bNkyrVu3TtWqVTOtb9q0qYoWLar4+HjX2KFDh3TixAm1bt3aYzWT1AEAAIsqGA8fHjBggBYtWqTPPvtMpUqVcs2TCw4OVvHixRUcHKynn35a0dHRKlOmjIKCgjRo0CC1bt3aY3e+SjzSBAAA3ApfPtLk0H6v7dtZu26ut73eN1t88MEH6tOnj6TfHz48bNgwLV68WBkZGerYsaPeeecdj15+pakDAADuo6krMLj8CgAArInvfjXhRgkAAAAbIKkDAADWRFJnQlIHAABgAyR1AADAmgjqTEjqAAAAbICkDgAAWBNz6kxI6gAAAGwgV0ldenp6rncYFBTkdjEAAAC5RlJnkqumLiQk5LpfgXGVYRhyOBzKysrySGEAAAA3RlP3R7lq6tavX+/tOgAAAHAL+O5XH1n40RK9F/ehfjmTojp31NKIV19Wwwb1fV0WvITzXbhwvguXQn++ffndr0lHvLZvZ7WaXtu3t+TqRondu3crOzvb9fONFtzcylWrFfvmZA14tr+WfbRQdWrfoaefH6iUlLO+Lg1ewPkuXDjfhQvnGwVJrpI6p9Op5ORklS9fXk6nUw6HQ9d62S3NqStESd1jPXqpQb16GvnaK5Kk7Oxstb+vs3o+8bj6P93Xx9XB0zjfhQvnu3DhfMu3Sd0PR722b2d4Da/t21tyNacuKSlJ5cqVc/0M913JzNS+Awf17B/+sDudTkW2aqGdu/f4sDJ4A+e7cOF8Fy6cbxQ0uWrqqlates2fkXepqWnKyspSaGioaTw0NFTHkn7wTVHwGs534cL5Llw43wUAjzQxcfsbJfbv368TJ07oypUrpvGHHnropq/NyMhQRkaGaczfyJS/v7+75QAAABRqeW7qjh07pocfflh79uwxza27+hy73Mypi42N1ZgxY0xjo/4Ro9HDX8trOZZTunSI/Pz8lJKSYhpPSUlR2bJlfVQVvIXzXbhwvgsXzncBQFJnkuevCRsyZIiqVaum06dPq0SJEtq3b5++/vprNWvWTBs2bMjVPmJiYnTu3DnTEvPSsLyWYknFihZVvYg6Skjc6hrLzs5WQuJWNW7YwIeVwRs434UL57tw4XyjoMlzUpeQkKB169apbNmycjqdcjqdatu2rWJjYzV48GDt3Lnzpvvw9/fPeam1EN392rfnU3plxCjVrxehhvXrK27BIl26dEmPdLv5pWtYD+e7cOF8Fy6cbxQkeW7qsrKyVKpUKUlS2bJl9dNPP6l27dqqWrWqDh065PEC7ahzp/t0NjVV096ZrV/OpCii9h361zvTVfZPk21hD5zvwoXzXbhwvn2My68mef5GibvuukvDhg1Tt27d9OSTTyo1NVXDhw/XnDlztH37du3du9e9SgpRUgcAgG348jl1J3/w2r6dlcO9tm9vyfM3SgwfPtx1c8TYsWOVlJSku+66SytXrtS0adO8VykAAMAfORzeWywoV0mdn5+ffv75Z5UvX17Vq1fX1q1bTc/lOXv2rEqXLu26A9YtJHUAAFiPL5O6/z3utX07b7fec3lzldSFhIS4vknihx9+cKV2V5UpU+bWGjoAAIC8cnhxsaBc3Sjx6KOPqn379qpYsaIcDoeaNWsmPz+/a2577NgxjxYIAACAm8tVUzdnzhw98sgjOnLkiAYPHqxnnnnGdQcsAACAb1g0UvOSXD/SpFOnTpKk7du3a8iQITR1AADAt5j6ZZLnR5p4DTdKAABgPb68UeKnk17bt7NSZa/t21vy/PBhAACAAoGgziTP3/0KAACAgoekDgAAWJKDqM6EpA4AAMAGSOoAAIA1cferCUkdAACADZDUAQAAayKpM6GpAwAA1kRPZ8LlVwAAABsgqQMAABZFVPdHJHUAAAA2QFIHAACsiRslTEjqAAAAbICkDgAAWBNBnQlJHQAAgA2Q1AEAAIsiqvsjmjoAAGBN3ChhwuVXAAAAGyCpAwAA1kRQZ0JSBwAAYAMkdQAAwJqYU2dCUgcAAGADJHUAAMCiSOr+iKQOAADABkjqAACANRHUmdDUAQAAa+JGCRMuvwIAANgASR0AALAmkjoTkjoAAAAboKkDAACwAZo6AAAAG2BOHQAAsCQHc+pMSOoAAABsgKQOAABYE0mdCU0dAACwKJq6P+LyKwAAgA2Q1AEAAGsiqDMhqQMAALABkjoAAGBN3ChhQlIHAABgAyR1AADAmkjqTEjqAAAAbtHMmTMVHh6ugIAAtWzZUlu2bMn3GmjqAAAAbsHHH3+s6OhojRo1Sjt27NCdd96pjh076vTp0/lah8MwDCNf3/F6Lp/3dQUAACCvAkr67r292Tvk4XO1bNlSzZs314wZMyRJ2dnZqly5sgYNGqRXX33VWxXmQFIHAADwJxkZGUpPTzctGRkZOba7cuWKtm/frqioKNeY0+lUVFSUEhIS8rPkAnSjhC87fR/JyMhQbGysYmJi5O/v7+ty4GWc78KF8124cL59xIu9Q+zo0RozZoxpbNSoURo9erRp7MyZM8rKylJYWJhpPCwsTAcPHvRafddScC6/FkLp6ekKDg7WuXPnFBQU5Oty4GWc78KF8124cL7tJyMjI0cy5+/vn6Np/+mnn3Tbbbdp8+bNat26tWv85Zdf1saNG5WYmJgv9UoFKakDAAAoIK7VwF1L2bJl5efnp1OnTpnGT506pQoVKnirvGtiTh0AAICbihUrpqZNmyo+Pt41lp2drfj4eFNylx9I6gAAAG5BdHS0evfurWbNmqlFixaaOnWqLly4oL59++ZrHTR1PuTv769Ro0YxqbaQ4HwXLpzvwoXzXbg9/vjj+uWXXzRy5EglJyerUaNGWrVqVY6bJ7yNGyUAAABsgDl1AAAANkBTBwAAYAM0dQAAADZAUwcAwA0YhqH+/furTJkycjgc+u677264/Q8//GDabsOGDXI4HEpLS/N6rSjcuPsVAIAbWLVqlebNm6cNGzaoevXqKlu27A23r1y5sn7++eebbgd4Gk0dAAA3cPToUVWsWFGRkZG52t7Pzy/fv0kAkLj86hV33323Bg4cqIEDByo4OFhly5bViBEjdPXpMampqerVq5dKly6tEiVK6P7779fhw4ddrz9+/LgefPBBlS5dWoGBgapXr55Wrlzpq4+DG7j77rs1ePBgvfzyyypTpowqVKhg+rLntLQ09evXT+XKlVNQUJDuuece7dq1y7SP8ePHq3z58ipVqpT69eunV199VY0aNcrfD4Jcudn5PnHihLp27aqSJUsqKChIf/vb30xfHTR69Gg1atRI8+fPV3h4uIKDg9W9e3f9+uuvPvg0yI0+ffpo0KBBOnHihBwOh8LDw7Vq1Sq1bdtWISEhCg0N1QMPPKCjR4+6XvPny69AfqGp85K4uDgVKVJEW7Zs0dtvv63JkyfrX//6l6Tf/5LYtm2b/vOf/yghIUGGYahz587KzMyUJA0YMEAZGRn6+uuvtWfPHk2cOFElS5b05cfBDcTFxSkwMFCJiYmaNGmSxo4dqzVr1kiSHnvsMZ0+fVpffvmltm/friZNmujee+/V2bNnJUkLFy7UhAkTNHHiRG3fvl1VqlTRrFmzfPlxcBPXO9/Z2dnq2rWrzp49q40bN2rNmjU6duyYHn/8cdPrjx49quXLl+uLL77QF198oY0bN+qNN97w0afBzbz99tsaO3asbr/9dv3888/aunWrLly4oOjoaG3btk3x8fFyOp16+OGHlZ2d7etyUdgZ8Lj27dsbERERRnZ2tmvslVdeMSIiIozvv//ekGRs2rTJte7MmTNG8eLFjSVLlhiGYRgNGjQwRo8ene91I+/at29vtG3b1jTWvHlz45VXXjH++9//GkFBQcbly5dN62vUqGG8++67hmEYRsuWLY0BAwaY1rdp08a48847vVo33HOj87169WrDz8/POHHihGvdvn37DEnGli1bDMMwjFGjRhklSpQw0tPTXdu89NJLRsuWLfPnA8AtU6ZMMapWrXrd9b/88oshydizZ49hGIaRlJRkSDJ27txpGIZhrF+/3pBkpKamer9YFGokdV7SqlUrORwO1++tW7fW4cOHtX//fhUpUkQtW7Z0rQsNDVXt2rV14MABSdLgwYM1fvx4tWnTRqNGjdLu3bvzvX7kXsOGDU2/V6xYUadPn9auXbt0/vx5hYaGqmTJkq4lKSnJdanm0KFDatGihen1f/4dBcv1zveBAwdUuXJlVa5c2bWubt26CgkJcf3ZlqTw8HCVKlUqx+thHYcPH9YTTzyh6tWrKygoSOHh4ZJ+v/wO+BI3ShRA/fr1U8eOHbVixQqtXr1asbGxeuuttzRo0CBfl4ZrKFq0qOl3h8Oh7OxsnT9/XhUrVtSGDRtyvCYkJCR/ioPHXe9859fr4XsPPvigqlatqrlz56pSpUrKzs5W/fr1deXKFV+XhkKOpM5LEhMTTb9/++23qlWrlurWravffvvNtD4lJUWHDh1S3bp1XWOVK1fWc889p3//+98aNmyY5s6dm2+1wzOaNGmi5ORkFSlSRDVr1jQtVx91ULt2bW3dutX0uj//DmuIiIjQyZMndfLkSdfY/v37lZaWZvqzDWu7+vf18OHDde+99yoiIkKpqam+LguQRFPnNSdOnFB0dLQOHTqkxYsXa/r06RoyZIhq1aqlrl276plnntE333yjXbt26amnntJtt92mrl27SpKGDh2qr776SklJSdqxY4fWr1+viIgIH38i5FVUVJRat26tbt26afXq1frhhx+0efNm/eMf/9C2bdskSYMGDdJ7772nuLg4HT58WOPHj9fu3btNl+5hDVFRUWrQoIF69OihHTt2aMuWLerVq5fat2+vZs2a+bo8eEjp0qUVGhqqOXPm6MiRI1q3bp2io6N9XRYgiabOa3r16qVLly6pRYsWGjBggIYMGaL+/ftLkj744AM1bdpUDzzwgFq3bi3DMLRy5UrXZZmsrCwNGDBAERER6tSpk+644w698847vvw4cIPD4dDKlSvVrl079e3bV3fccYe6d++u48ePKywsTJLUo0cPxcTE6MUXX1STJk2UlJSkPn36KCAgwMfVI68cDoc+++wzlS5dWu3atVNUVJSqV6+ujz/+2NelwYOcTqc++ugjbd++XfXr19cLL7ygf/7zn74uC5AkOQzj/z88DR5z9913q1GjRpo6daqvS4EF/eUvf1GFChU0f/58X5cCALAQbpQAfOjixYuaPXu2OnbsKD8/Py1evFhr1651PecOAIDcoqkDfOjqJdoJEybo8uXLql27tj799FNFRUX5ujQAgMVw+RUAAMAGuFECAADABmjqAAAAbICmDgAAwAZo6gAAAGyApg4AAMAGaOoAAABsgKYOAADABmjqAAAAbICmDgAAwAb+H6D/uzvmTWvHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 유저가 Context를 주는 경우\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher # 텍스트간 유사도 측정 라이브러리\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import evaluate  # Hugging Face evaluate 라이브러리\n",
    "\n",
    "# 1. 지표 로더\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "\n",
    "# 2. 결과 파일 및 통계 초기화\n",
    "output_file_path = \"./result2/log_with_context.txt\"\n",
    "os.makedirs(\"./result2\", exist_ok=True)\n",
    "\n",
    "all_preds_text = []    # ROUGE/BLEU용 모델 답변\n",
    "all_refs_text = []     # ROUGE/BLEU용 실제 정답\n",
    "y_true_idx = []        # 혼동행렬용 실제 라벨\n",
    "y_pred_idx = []        # 혼동행렬용 예측 라벨\n",
    "\n",
    "label_map = {\"긍정\": 0, \"부정\": 1, \"불명\": 2}\n",
    "correct_labels = 0\n",
    "total_samples = len(test_subset)\n",
    "\n",
    "print(f\"검증 및 비교 시작... 총 {total_samples}개 데이터\")\n",
    "\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== EXAONE 법률 QA 정답 비교 검증 로그 ===\\n\\n\")\n",
    "\n",
    "    for i, data in enumerate(tqdm(test_subset, desc=\"Evaluating\")):\n",
    "        question = data[\"question\"]\n",
    "        context = data[\"context\"]\n",
    "        actual_label = str(data[\"answer\"]).strip() # 실제 정답 (긍정/부정/불명)\n",
    "        summary = data[\"summary\"]\n",
    "        \n",
    "        if actual_label == \"긍정\":\n",
    "            ground_truth = f\"네 그렇습니다! {summary}에 의하여 질문하신 내용은 옳습니다.\"\n",
    "        elif actual_label == \"부정\":\n",
    "            ground_truth = f\"아니요, 그렇지 않습니다! {summary}에 의하면 상충되는 내용이 있으므로 질문하신 내용은 옳지 않습니다.\"\n",
    "        else:\n",
    "            ground_truth = f\"확실하지 않습니다만, {summary}에 적힌 내용을 근거로 판단해 볼 수 있을 것 같습니다.\"\n",
    "\n",
    "        # 모델 답변 생성\n",
    "        generated_answer = generate_legal_answer_with_context(question, context)\n",
    "\n",
    "        actual_idx = label_map.get(actual_label, 3)\n",
    "        if \"네\" in generated_answer[:10]: pred_idx = 0\n",
    "        elif \"아니요\" in generated_answer[:10]: pred_idx = 1\n",
    "        elif \"확실하지\" in generated_answer[:10]: pred_idx = 2\n",
    "        else: pred_idx = 3 # 분류 실패\n",
    "\n",
    "        y_true_idx.append(actual_idx)\n",
    "        y_pred_idx.append(pred_idx)\n",
    "        if actual_idx == pred_idx: correct_labels += 1\n",
    "\n",
    "        all_preds_text.append(generated_answer)\n",
    "        all_refs_text.append(ground_truth)\n",
    "\n",
    "        similarity = SequenceMatcher(None, ground_truth, generated_answer).ratio()\n",
    "\n",
    "        # 로그 기록\n",
    "        f.write(f\"[{i+1}번 데이터] | Label 일치: {'O' if actual_idx == pred_idx else 'X'} | 유사도: {similarity:.2f}\\n\")\n",
    "        f.write(f\"질문: {question}\\n\")\n",
    "        f.write(f\"실제 정답: {ground_truth}\\n\")\n",
    "        f.write(f\"모델 답변: {generated_answer}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    rouge_results = rouge_metric.compute(predictions=all_preds_text, references=all_refs_text)\n",
    "    bleu_results = bleu_metric.compute(predictions=all_preds_text, references=all_refs_text)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_true_idx, y_pred_idx, labels=[0, 1, 2, 3])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='RdPu', \n",
    "                xticklabels=[\"pos\", \"neg\", \"non\", \"fail\"], \n",
    "                yticklabels=[\"pos\", \"neg\", \"non\", \"fail\"])\n",
    "    plt.title(\"With Context\")\n",
    "    plt.savefig(\"./result2/confusion_matrix_with_context.png\")\n",
    "\n",
    "    # 5. 최종 통계 기록\n",
    "    accuracy = (correct_labels / total_samples) * 100\n",
    "    report = classification_report(y_true_idx, y_pred_idx, \n",
    "                                   target_names=['긍정', '부정', '불명', '실패'], labels=[0, 1, 2, 3])\n",
    "    summary_msg = (\n",
    "        f\"\\n[최종 검증 요약]\\n\"\n",
    "        f\"- Label Accuracy: {accuracy:.2f}%\\n\"\n",
    "        f\"- ROUGE-L: {rouge_results['rougeL']:.4f}\\n\"\n",
    "        f\"- BLEU: {bleu_results['bleu']:.4f}\\n\"\n",
    "        f\"\\n[상세 분류 리포트]\\n{report}\"\n",
    "    )\n",
    "    \n",
    "    print(summary_msg)\n",
    "    f.write(summary_msg)\n",
    "\n",
    "print(f\"검증 완료! 로그 파일: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c60f0aa4-f42c-4b3e-87bd-aa738118c770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 검증 결과 리포트\n",
      "----------------------\n",
      "✅ 전체 모델 답변 수: 200개\n",
      "⚠️ 지시 사항 누수 발생: 0개\n",
      "📈 누수 발생률: 0.00%\n",
      "\n",
      "📊 검증 결과 리포트\n",
      "----------------------\n",
      "✅ 전체 모델 답변 수: 200개\n",
      "⚠️ 지시 사항 누수 발생: 0개\n",
      "📈 누수 발생률: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def count_instruction_leakage(file_path):    \n",
    "    leakage_count = 0\n",
    "    total_answers = 0\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "            # '모델 답변:' 이후부터 다음 구분선(---) 혹은 파일 끝까지의 텍스트를 추출\n",
    "            model_answers = re.findall(r\"모델 답변:\\s*(.*?)(?=\\n-{10,}|\\n===|\\Z)\", content, re.DOTALL)\n",
    "            \n",
    "            total_answers = len(model_answers)\n",
    "            \n",
    "            for answer in model_answers:\n",
    "                # 앞뒤 공백 제거 후 타겟 문구로 끝나는지 확인\n",
    "                clean_answer = answer.strip()\n",
    "                if re.search(r\"를 참조하여 \\d+문단 이내로 답변하세요\\.\\s*$\", clean_answer):\n",
    "                    leakage_count += 1\n",
    "                    \n",
    "        print(f\"📊 검증 결과 리포트\")\n",
    "        print(f\"----------------------\")\n",
    "        print(f\"✅ 전체 모델 답변 수: {total_answers}개\")\n",
    "        print(f\"⚠️ 지시 사항 누수 발생: {leakage_count}개\")\n",
    "        \n",
    "        if total_answers > 0:\n",
    "            leakage_rate = (leakage_count / total_answers) * 100\n",
    "            print(f\"📈 누수 발생률: {leakage_rate:.2f}%\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 파일을 찾을 수 없습니다: {file_path}\")\n",
    "\n",
    "count_instruction_leakage(\"./result2/log_without_context.txt\")\n",
    "print()\n",
    "count_instruction_leakage(\"./result2/log_with_context.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a910c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA 가중치만 upload\n",
    "from peft import PeftModel\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    TrainingArguments,\n",
    ")\n",
    "import torch\n",
    "\n",
    "model_id = \"/home/vsc/LLM/model/EXAONE-3.5-7.8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 4bit 할 것이냐\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, #bfloat16 or float16\n",
    "    bnb_4bit_quant_type=\"nf4\", # nf4 or fp4\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# 1. 학습 완료 후 저장된 어댑터 경로\n",
    "adapter_path = \"/home/vsc/LLM_TUNE/115.법률-규정 텍스트 분석 데이터_고도화_상황에 따른 판례 데이터/SFT/final\"\n",
    "repo_id = \"JungSeong2/QA-Law-Adapter\" # 허깅페이스 저장소 이름\n",
    "\n",
    "# 2. 토크나이저와 어댑터 모델 로드 (또는 학습 중인 trainer.model 사용)\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "\n",
    "# 3. 어댑터 가중치만 업로드\n",
    "model.push_to_hub(\n",
    "    repo_id=repo_id,\n",
    "    commit_message=\"v2.0: DataCollatorForCompletionOnlyLM + Prompt Engineered\",\n",
    "    revision=\"v2.0\" # v2.0 브랜치에 해당 어댑터를 업로드\n",
    ")\n",
    "\n",
    "tokenizer.push_to_hub(\n",
    "    repo_id,\n",
    "    commit_message=\"v2.0: DataCollatorForCompletionOnlyLM + Prompt Engineered\",\n",
    "    revision=\"v2.0\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QA2",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
